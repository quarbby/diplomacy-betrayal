{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referenced from https://github.com/amaiya/ktrain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example notebook for BERT text classification using ktrain package. \n",
    "Example task: predict deception (\"Straightforward\" or \"Cassandra\") using input text.\n",
    "\n",
    "### Notes:\n",
    "- BERT model takes extremely long to train, even the supposedly faster method (DistillBERT, which is implemented in this notebook) also takes quite some time.\n",
    "- However, validation accuracy looks promising. In the event that we use this BERT methods for individual models, need to save models and load them each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\";\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "import ktrain\n",
    "from ktrain import text\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, f1_score\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import LSTM, Input, InputLayer, Dropout, Dense, Flatten, Embedding, Add, Concatenate\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import tensorflow as tf\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import import_ipynb\n",
    "import metadata_options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######\n",
    "# KTRAIN MODEL OPTIONS: #\n",
    "#distilbert-base-uncased, bert-base-uncased, albert-base-v2, roberta-base\n",
    "######\n",
    "k_train_model = 'distilbert-base-uncased'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data with Throughput & WorkTime\n",
    "df = pd.read_csv('./data/kokil dec 6 reprepare/conf_pc_worker_sem.csv')\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP1: weighted by 1 average per set of OHE, i.e. (a, b, c, d) -> (w*a, w*b, w*c, w*d)\n",
      "WT1: weighted by 1 average per set of OHE, i.e. (a, b, c, d) -> (w*a, w*b, w*c, w*d)\n",
      "PC1: weighted by 1 average per set of OHE, i.e. (a, b, c, d) -> (w*a, w*b, w*c, w*d)\n",
      "TL1: weighted by 1 normalised number of characters per set of OHE, i.e. (a, b, c, d) -> (w*a, w*b, w*c, w*d)\n",
      "SP1: weighted by average of TP1 and TP2 per set of OHE, i.e. (a, b, c, d) -> (w*a, w*b, w*c, w*d)\n"
     ]
    }
   ],
   "source": [
    "######################################\n",
    "## Weighted Onehot Encoding options ##\n",
    "######################################\n",
    "throughput_option = 'TP1'\n",
    "worktime_option = 'WT1'\n",
    "pc_agreement_option = 'PC1'\n",
    "textlength_option = 'TL1'\n",
    "special_option = 'SP1'\n",
    "k_option_for_tp = 3\n",
    "\n",
    "df_throughput, df_worktime, df_agreement, df_textlength, df_special = metadata_options.set_OHE_pipeline_options(df, throughput_option, worktime_option, pc_agreement_option, textlength_option, special_option, k_option_for_tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_test_split using Stratified Shaffled Splits\n",
    "y = df[\"Input.deception_quadrant\"].copy()\n",
    "X = df.drop([\"Input.deception_quadrant\"], axis=1)\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=0)\n",
    "splits_generator = sss.split(X, y)\n",
    "\n",
    "for train_idx, test_idx in splits_generator:\n",
    "    indices_train = train_idx\n",
    "    indices_test = test_idx\n",
    "\n",
    "train = df.take(indices_train)\n",
    "test = df.take(indices_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_deception = train[\"Input.deception_quadrant\"].tolist()\n",
    "y_train_rapport = train['Answer.3rapport.yes_label'].tolist()\n",
    "y_train_share_information = train['Answer.4shareinformation.yes_label'].tolist()\n",
    "y_train_reasoning = train['Answer.2reasoning.yes_label'].tolist()\n",
    "y_train_gamemove = train['Answer.1gamemove.yes_label'].tolist()\n",
    "\n",
    "y_test_deception = test['Input.deception_quadrant'].tolist()\n",
    "\n",
    "y_test_rapport = test['Answer.3rapport.yes_label'].tolist()\n",
    "y_test_share_information = test['Answer.4shareinformation.yes_label'].tolist()\n",
    "y_test_reasoning = test['Answer.2reasoning.yes_label'].tolist()\n",
    "y_test_gamemove = test['Answer.1gamemove.yes_label'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train['Input.full_text'].tolist()\n",
    "x_test = test['Input.full_text'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Individual Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Game move classifier\n",
    "t_gamemove_label = list(set(y_train_gamemove))\n",
    "t_gamemove = text.Transformer(k_train_model, maxlen=500, classes=t_gamemove_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing train...\n",
      "language: en\n",
      "train sequence lengths:\n",
      "\tmean : 16\n",
      "\t95percentile : 32\n",
      "\t99percentile : 44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lynne\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ktrain\\utils.py:605: UserWarning: class_names implies classification but targets array contains float(s) instead of integers or strings\n",
      "  warnings.warn('class_names implies classification but targets array contains float(s) instead of integers or strings')\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Multi-Label? False\n",
      "preprocessing test...\n",
      "language: en\n",
      "test sequence lengths:\n",
      "\tmean : 17\n",
      "\t95percentile : 33\n",
      "\t99percentile : 44\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "begin training using onecycle policy with max lr of 3e-05...\n",
      "1516/1516 [==============================] - 506s 334ms/step - loss: 0.2704 - accuracy: 0.9287 - val_loss: 0.2325 - val_accuracy: 0.9376\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       142\n",
      "         1.0       0.94      1.00      0.97      2132\n",
      "\n",
      "    accuracy                           0.94      2274\n",
      "   macro avg       0.47      0.50      0.48      2274\n",
      "weighted avg       0.88      0.94      0.91      2274\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lynne\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[   0,  142],\n",
       "       [   0, 2132]], dtype=int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_gamemove = t_gamemove.preprocess_train(x_train, y_train_gamemove)\n",
    "val_gamemove = t_gamemove.preprocess_test(x_test, y_test_gamemove)\n",
    "\n",
    "gamemove_model = t_gamemove.get_classifier()\n",
    "learner_gamemove = ktrain.get_learner(gamemove_model, \n",
    "                                      train_data=trn_gamemove, \n",
    "                                      val_data=val_gamemove, batch_size=6)\n",
    "learner_gamemove.fit_onecycle(3e-5, 1)\n",
    "learner_gamemove.validate(class_names=t_gamemove.get_classes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_gamemove = ktrain.get_predictor(gamemove_model, preproc=t_gamemove)\n",
    "y_pred_test_gamemove = pred_gamemove.predict(x_test)\n",
    "y_pred_train_gamemove = pred_gamemove.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reasoning Classifier \n",
    "t_reasoning_label = list(set(y_train_reasoning))\n",
    "t_reasoning = text.Transformer(k_train_model, maxlen=500, classes=t_reasoning_label)\n",
    "\n",
    "trn_reasoning = t_reasoning.preprocess_train(x_train, y_train_reasoning)\n",
    "val_reasoning = t_reasoning.preprocess_test(x_test, y_test_reasoning)\n",
    "\n",
    "reasoning_model = t_reasoning.get_classifier()\n",
    "learner_reasoning = ktrain.get_learner(reasoning_model, \n",
    "                                      train_data=trn_reasoning, \n",
    "                                      val_data=val_reasoning, batch_size=6)\n",
    "learner_reasoning.fit_onecycle(3e-5, 1)\n",
    "learner_reasoning.validate(class_names=t_reasoning.get_classes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_reasoning = ktrain.get_predictor(reasoning_model, preproc=t_reasoning)\n",
    "y_pred_test_reasoning = pred_reasoning.predict(x_test)\n",
    "y_pred_train_reasoning = pred_reasoning.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Share info classifier \n",
    "t_share_information_label = list(set(y_train_share_information))\n",
    "t_share_information = text.Transformer(k_train_model, maxlen=500, classes=t_reasoning_label)\n",
    "\n",
    "trn_share_information = t_share_information.preprocess_train(x_train, y_train_share_information)\n",
    "val_share_information = t_share_information.preprocess_test(x_test, y_test_share_information)\n",
    "\n",
    "share_information_model = t_share_information.get_classifier()\n",
    "learner_share_information = ktrain.get_learner(share_information_model, \n",
    "                                      train_data=trn_share_information, \n",
    "                                      val_data=val_share_information, batch_size=6)\n",
    "learner_share_information.fit_onecycle(3e-5, 1)\n",
    "learner_share_information.validate(class_names=t_share_information.get_classes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_share_information = ktrain.get_predictor(share_information_model, preproc=t_share_information)\n",
    "y_pred_test_share_information = pred_share_information.predict(x_test)\n",
    "y_pred_train_share_information = pred_share_information.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rapport classifier \n",
    "t_rapport_label = list(set(y_train_rapport))\n",
    "t_rapport = text.Transformer(k_train_model, maxlen=500, classes=t_rapport_label)\n",
    "\n",
    "trn_rapport = t_rapport.preprocess_train(x_train, y_train_rapport)\n",
    "val_rapport = t_rapport.preprocess_test(x_test, y_test_rapport)\n",
    "\n",
    "rapport_model = t_rapport.get_classifier()\n",
    "learner_rapport = ktrain.get_learner(rapport_model, \n",
    "                                      train_data=trn_rapport, \n",
    "                                      val_data=val_rapport, batch_size=6)\n",
    "learner_rapport.fit_onecycle(3e-5, 1)\n",
    "learner_rapport.validate(class_names=t_rapport.get_classes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_rapport = ktrain.get_predictor(rapport_model, preproc=t_rapport)\n",
    "y_pred_test_rapport = pred_rapport.predict(x_test)\n",
    "y_pred_train_rapport = pred_rapport.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deception classifier \n",
    "t_deception_label = list(set(y_train_deception))\n",
    "t_deception = text.Transformer(k_train_model, maxlen=500, classes=t_deception_label)\n",
    "\n",
    "trn_deception = t_deception.preprocess_train(x_train, y_train_deception)\n",
    "val_deception = t_deception.preprocess_test(x_test, y_test_deception)\n",
    "\n",
    "deception_model = t_rapport.get_classifier()\n",
    "learner_deception = ktrain.get_learner(deception_model, \n",
    "                                      train_data=trn_deception, \n",
    "                                      val_data=val_deception, batch_size=6)\n",
    "learner_deception.fit_onecycle(3e-5, 1)\n",
    "learner_deception.validate(class_names=t_deception.get_classes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_deception = ktrain.get_predictor(deception_model, preproc=t_deception)\n",
    "y_pred_test_deception = pred_deception.predict(x_test)\n",
    "y_pred_train_deception = pred_deception.predict(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One hot encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train encodings\n",
    "pred_df_arr_full = []\n",
    "pred_df_arr = []\n",
    "for i in range(0, len(y_pred_train_reasoning)):\n",
    "    pred_obj_1 = {}\n",
    "    pred_obj_1['gamemove'] = y_pred_train_gamemove[i]\n",
    "    pred_obj_1['reasoning'] = y_pred_train_reasoning[i]\n",
    "    pred_obj_1['shareinfo'] = y_pred_train_share_information[i]\n",
    "    pred_df_arr.append(pred_obj_1)\n",
    "    \n",
    "    pred_obj_2 = pred_obj_1.copy()\n",
    "    pred_obj_2['rapport'] = y_pred_train_rapport[i]\n",
    "    pred_df_arr_full.append(pred_obj_2)\n",
    "    \n",
    "pred_df_full = pd.DataFrame(pred_df_arr_full)\n",
    "pred_df = pd.DataFrame(pred_df_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test encodings\n",
    "pred_test_df_arr_full = []\n",
    "pred_test_df_arr = []\n",
    "\n",
    "for i in range(0, len(y_pred_test_reasoning)):\n",
    "    pred_obj_1 = {}\n",
    "    pred_obj_1['gamemove'] = y_pred_test_gamemove[i][0]\n",
    "    pred_obj_1['reasoning'] = y_pred_test_reasoning[i][0]\n",
    "    pred_obj_1['shareinfo'] = y_pred_test_share_information[i][0]\n",
    "    pred_test_df_arr.append(pred_obj_1)\n",
    "    \n",
    "    pred_obj_2 = pred_obj_1.copy()\n",
    "    pred_obj_2['rapport'] = y_pred_test_rapport[i][0]\n",
    "    pred_test_df_arr_full.append(pred_obj_2)\n",
    "    \n",
    "pred_test_df_full = pd.DataFrame(pred_test_df_arr_full)\n",
    "pred_test_df = pd.DataFrame(pred_test_df_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joint model with one hot encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_deception_test = test[\"Input.deception_quadrant\"].copy()\n",
    "new_deception_test['Input.deception_quadrant'] = test[\"Input.deception_quadrant\"].apply(lambda x : 1 if x == \"Straightforward\" else 0)\n",
    "y_test_deception = new_deception_test['Input.deception_quadrant'].tolist()\n",
    "\n",
    "new_deception_train = train[\"Input.deception_quadrant\"].copy()\n",
    "new_deception_train['Input.deception_quadrant'] = train[\"Input.deception_quadrant\"].apply(lambda x : 1 if x == \"Straightforward\" else 0)\n",
    "y_train_deception = new_deception_train['Input.deception_quadrant'].tolist()\n",
    "\n",
    "y_test_rapport = np.asarray(y_test_rapport)\n",
    "y_train_rapport = np.asarray(y_train_rapport)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Joint full model with one hot encoding, predicting deception')\n",
    "joint_full_model = models_nn.create_joint_model(pred_df_full)\n",
    "joint_full_model.summary()\n",
    "history = joint_full_model.fit(x=pred_df_full, \n",
    "                               y=y_train_deception, \n",
    "                               epochs=32, \n",
    "                               batch_size=64, \n",
    "                               validation_data=(pred_test_df_full, y_test_deception))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_predict = joint_full_model.predict(pred_test_df_full)\n",
    "joint_predict_round = joint_predict.round()\n",
    "precision_recall_fscore_support(y_test_deception, np.array(joint_predict_round), average='macro')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfgpu",
   "language": "python",
   "name": "tfgpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
