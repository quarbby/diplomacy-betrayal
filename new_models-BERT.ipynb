{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referenced from https://github.com/amaiya/ktrain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example notebook for BERT text classification using ktrain package. \n",
    "Example task: predict deception (\"Straightforward\" or \"Cassandra\") using input text.\n",
    "\n",
    "### Notes:\n",
    "- BERT model takes extremely long to train, even the supposedly faster method (DistillBERT, which is implemented in this notebook) also takes quite some time.\n",
    "- However, validation accuracy looks promising. In the event that we use this BERT methods for individual models, need to save models and load them each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\";\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "import ktrain\n",
    "from ktrain import text\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, f1_score, precision_recall_fscore_support\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import LSTM, Input, InputLayer, Dropout, Dense, Flatten, Embedding, Add, Concatenate\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import tensorflow as tf\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import import_ipynb\n",
    "import metadata_options\n",
    "import models_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######\n",
    "# KTRAIN MODEL OPTIONS: #\n",
    "#distilbert-base-uncased, bert-base-uncased, albert-base-v2, roberta-base\n",
    "######\n",
    "k_train_model = 'distilbert-base-uncased'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data with Throughput & WorkTime\n",
    "df = pd.read_csv('./data/kokil dec 6 reprepare/conf_pc_worker_sem_test.csv')\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP1: weighted by 1 average per set of OHE, i.e. (a, b, c, d) -> (w*a, w*b, w*c, w*d)\n",
      "WT1: weighted by 1 average per set of OHE, i.e. (a, b, c, d) -> (w*a, w*b, w*c, w*d)\n",
      "PC1: weighted by 1 average per set of OHE, i.e. (a, b, c, d) -> (w*a, w*b, w*c, w*d)\n",
      "TL1: weighted by 1 normalised number of characters per set of OHE, i.e. (a, b, c, d) -> (w*a, w*b, w*c, w*d)\n",
      "SP1: weighted by average of TP1 and TP2 per set of OHE, i.e. (a, b, c, d) -> (w*a, w*b, w*c, w*d)\n"
     ]
    }
   ],
   "source": [
    "######################################\n",
    "## Weighted Onehot Encoding options ##\n",
    "######################################\n",
    "throughput_option = 'TP1'\n",
    "worktime_option = 'WT1'\n",
    "pc_agreement_option = 'PC1'\n",
    "textlength_option = 'TL1'\n",
    "special_option = 'SP1'\n",
    "k_option_for_tp = 3\n",
    "\n",
    "df_throughput, df_worktime, df_agreement, df_textlength, df_special = metadata_options.set_OHE_pipeline_options(df, throughput_option, worktime_option, pc_agreement_option, textlength_option, special_option, k_option_for_tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_test_split using Stratified Shaffled Splits\n",
    "y = df[\"Input.deception_quadrant\"].copy()\n",
    "X = df.drop([\"Input.deception_quadrant\"], axis=1)\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=0)\n",
    "splits_generator = sss.split(X, y)\n",
    "\n",
    "for train_idx, test_idx in splits_generator:\n",
    "    indices_train = train_idx\n",
    "    indices_test = test_idx\n",
    "\n",
    "train = df.take(indices_train)\n",
    "test = df.take(indices_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_deception = train[\"Input.deception_quadrant\"].tolist()\n",
    "y_train_rapport = train['Answer.3rapport.yes_label'].tolist()\n",
    "y_train_share_information = train['Answer.4shareinformation.yes_label'].tolist()\n",
    "y_train_reasoning = train['Answer.2reasoning.yes_label'].tolist()\n",
    "y_train_gamemove = train['Answer.1gamemove.yes_label'].tolist()\n",
    "\n",
    "y_test_deception = test['Input.deception_quadrant'].tolist()\n",
    "\n",
    "y_test_rapport = test['Answer.3rapport.yes_label'].tolist()\n",
    "y_test_share_information = test['Answer.4shareinformation.yes_label'].tolist()\n",
    "y_test_reasoning = test['Answer.2reasoning.yes_label'].tolist()\n",
    "y_test_gamemove = test['Answer.1gamemove.yes_label'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train['Input.full_text'].tolist()\n",
    "x_test = test['Input.full_text'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Individual Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lynne\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ktrain\\text\\preprocessor.py:414: UserWarning: The class_names argument is replacing the classes argument. Please update your code.\n",
      "  warnings.warn('The class_names argument is replacing the classes argument. Please update your code.')\n"
     ]
    }
   ],
   "source": [
    "# Game move classifier\n",
    "t_gamemove_label = list(set(y_train_gamemove))\n",
    "t_gamemove = text.Transformer(k_train_model, maxlen=500, classes=t_gamemove_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing train...\n",
      "language: en\n",
      "train sequence lengths:\n",
      "\tmean : 18\n",
      "\t95percentile : 29\n",
      "\t99percentile : 31\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Multi-Label? False\n",
      "preprocessing test...\n",
      "language: en\n",
      "test sequence lengths:\n",
      "\tmean : 18\n",
      "\t95percentile : 19\n",
      "\t99percentile : 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lynne\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ktrain\\text\\preprocessor.py:215: UserWarning: List or array of two texts supplied, so task being treated as text classification. If this is a sentence pair classification task, please cast to tuple.\n",
      "  warnings.warn('List or array of two texts supplied, so task being treated as text classification. ' +\\\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "begin training using onecycle policy with max lr of 3e-05...\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6632 - accuracy: 0.7500 - val_loss: 0.6800 - val_accuracy: 0.5000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.50         2\n",
      "   macro avg       0.50      0.25      0.33         2\n",
      "weighted avg       1.00      0.50      0.67         2\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lynne\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0],\n",
       "       [1, 1]], dtype=int64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_gamemove = t_gamemove.preprocess_train(x_train, y_train_gamemove)\n",
    "val_gamemove = t_gamemove.preprocess_test(x_test, y_test_gamemove)\n",
    "\n",
    "gamemove_model = t_gamemove.get_classifier()\n",
    "learner_gamemove = ktrain.get_learner(gamemove_model, \n",
    "                                      train_data=trn_gamemove, \n",
    "                                      val_data=val_gamemove, batch_size=6)\n",
    "learner_gamemove.fit_onecycle(3e-5, 1)\n",
    "learner_gamemove.validate(class_names=t_gamemove.get_classes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lynne\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ktrain\\text\\preprocessor.py:215: UserWarning: List or array of two texts supplied, so task being treated as text classification. If this is a sentence pair classification task, please cast to tuple.\n",
      "  warnings.warn('List or array of two texts supplied, so task being treated as text classification. ' +\\\n"
     ]
    }
   ],
   "source": [
    "pred_gamemove = ktrain.get_predictor(gamemove_model, preproc=t_gamemove)\n",
    "y_pred_test_gamemove = pred_gamemove.predict(x_test)\n",
    "y_pred_train_gamemove = pred_gamemove.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lynne\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ktrain\\text\\preprocessor.py:414: UserWarning: The class_names argument is replacing the classes argument. Please update your code.\n",
      "  warnings.warn('The class_names argument is replacing the classes argument. Please update your code.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing train...\n",
      "language: en\n",
      "train sequence lengths:\n",
      "\tmean : 18\n",
      "\t95percentile : 29\n",
      "\t99percentile : 31\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Multi-Label? False\n",
      "preprocessing test...\n",
      "language: en\n",
      "test sequence lengths:\n",
      "\tmean : 18\n",
      "\t95percentile : 19\n",
      "\t99percentile : 19\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "begin training using onecycle policy with max lr of 3e-05...\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6897 - accuracy: 0.2500 - val_loss: 0.6999 - val_accuracy: 0.5000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67         1\n",
      "           1       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.50         2\n",
      "   macro avg       0.25      0.50      0.33         2\n",
      "weighted avg       0.25      0.50      0.33         2\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lynne\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 0],\n",
       "       [1, 0]], dtype=int64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reasoning Classifier \n",
    "t_reasoning_label = list(set(y_train_reasoning))\n",
    "t_reasoning = text.Transformer(k_train_model, maxlen=500, classes=t_reasoning_label)\n",
    "\n",
    "trn_reasoning = t_reasoning.preprocess_train(x_train, y_train_reasoning)\n",
    "val_reasoning = t_reasoning.preprocess_test(x_test, y_test_reasoning)\n",
    "\n",
    "reasoning_model = t_reasoning.get_classifier()\n",
    "learner_reasoning = ktrain.get_learner(reasoning_model, \n",
    "                                      train_data=trn_reasoning, \n",
    "                                      val_data=val_reasoning, batch_size=6)\n",
    "learner_reasoning.fit_onecycle(3e-5, 1)\n",
    "learner_reasoning.validate(class_names=t_reasoning.get_classes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_reasoning = ktrain.get_predictor(reasoning_model, preproc=t_reasoning)\n",
    "y_pred_test_reasoning = pred_reasoning.predict(x_test)\n",
    "y_pred_train_reasoning = pred_reasoning.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Share info classifier \n",
    "t_share_information_label = list(set(y_train_share_information))\n",
    "t_share_information = text.Transformer(k_train_model, maxlen=500, classes=t_reasoning_label)\n",
    "\n",
    "trn_share_information = t_share_information.preprocess_train(x_train, y_train_share_information)\n",
    "val_share_information = t_share_information.preprocess_test(x_test, y_test_share_information)\n",
    "\n",
    "share_information_model = t_share_information.get_classifier()\n",
    "learner_share_information = ktrain.get_learner(share_information_model, \n",
    "                                      train_data=trn_share_information, \n",
    "                                      val_data=val_share_information, batch_size=6)\n",
    "learner_share_information.fit_onecycle(3e-5, 1)\n",
    "learner_share_information.validate(class_names=t_share_information.get_classes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lynne\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ktrain\\text\\preprocessor.py:215: UserWarning: List or array of two texts supplied, so task being treated as text classification. If this is a sentence pair classification task, please cast to tuple.\n",
      "  warnings.warn('List or array of two texts supplied, so task being treated as text classification. ' +\\\n"
     ]
    }
   ],
   "source": [
    "pred_share_information = ktrain.get_predictor(share_information_model, preproc=t_share_information)\n",
    "y_pred_test_share_information = pred_share_information.predict(x_test)\n",
    "y_pred_train_share_information = pred_share_information.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lynne\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ktrain\\text\\preprocessor.py:414: UserWarning: The class_names argument is replacing the classes argument. Please update your code.\n",
      "  warnings.warn('The class_names argument is replacing the classes argument. Please update your code.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing train...\n",
      "language: en\n",
      "train sequence lengths:\n",
      "\tmean : 18\n",
      "\t95percentile : 29\n",
      "\t99percentile : 31\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Multi-Label? False\n",
      "preprocessing test...\n",
      "language: en\n",
      "test sequence lengths:\n",
      "\tmean : 18\n",
      "\t95percentile : 19\n",
      "\t99percentile : 19\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "begin training using onecycle policy with max lr of 3e-05...\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6885 - accuracy: 0.5000 - val_loss: 0.6866 - val_accuracy: 0.5000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.50      1.00      0.67         1\n",
      "\n",
      "    accuracy                           0.50         2\n",
      "   macro avg       0.25      0.50      0.33         2\n",
      "weighted avg       0.25      0.50      0.33         2\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lynne\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [0, 1]], dtype=int64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rapport classifier \n",
    "t_rapport_label = list(set(y_train_rapport))\n",
    "t_rapport = text.Transformer(k_train_model, maxlen=500, classes=t_rapport_label)\n",
    "\n",
    "trn_rapport = t_rapport.preprocess_train(x_train, y_train_rapport)\n",
    "val_rapport = t_rapport.preprocess_test(x_test, y_test_rapport)\n",
    "\n",
    "rapport_model = t_rapport.get_classifier()\n",
    "learner_rapport = ktrain.get_learner(rapport_model, \n",
    "                                      train_data=trn_rapport, \n",
    "                                      val_data=val_rapport, batch_size=6)\n",
    "learner_rapport.fit_onecycle(3e-5, 1)\n",
    "learner_rapport.validate(class_names=t_rapport.get_classes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lynne\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ktrain\\text\\preprocessor.py:215: UserWarning: List or array of two texts supplied, so task being treated as text classification. If this is a sentence pair classification task, please cast to tuple.\n",
      "  warnings.warn('List or array of two texts supplied, so task being treated as text classification. ' +\\\n"
     ]
    }
   ],
   "source": [
    "pred_rapport = ktrain.get_predictor(rapport_model, preproc=t_rapport)\n",
    "y_pred_test_rapport = pred_rapport.predict(x_test)\n",
    "y_pred_train_rapport = pred_rapport.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lynne\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ktrain\\text\\preprocessor.py:414: UserWarning: The class_names argument is replacing the classes argument. Please update your code.\n",
      "  warnings.warn('The class_names argument is replacing the classes argument. Please update your code.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing train...\n",
      "language: en\n",
      "train sequence lengths:\n",
      "\tmean : 18\n",
      "\t95percentile : 29\n",
      "\t99percentile : 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lynne\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ktrain\\utils.py:589: UserWarning: class_names argument was ignored, as they were extracted from string labels in dataset\n",
      "  if self.get_classes(): warnings.warn('class_names argument was ignored, as they were extracted from string labels in dataset')\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Multi-Label? False\n",
      "preprocessing test...\n",
      "language: en\n",
      "test sequence lengths:\n",
      "\tmean : 18\n",
      "\t95percentile : 19\n",
      "\t99percentile : 19\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "begin training using onecycle policy with max lr of 3e-05...\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7387 - accuracy: 0.2500 - val_loss: 0.7175 - val_accuracy: 0.5000\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "      Cassandra       0.50      1.00      0.67         1\n",
      "Straightforward       0.00      0.00      0.00         1\n",
      "\n",
      "       accuracy                           0.50         2\n",
      "      macro avg       0.25      0.50      0.33         2\n",
      "   weighted avg       0.25      0.50      0.33         2\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lynne\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 0],\n",
       "       [1, 0]], dtype=int64)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Deception classifier \n",
    "t_deception_label = list(set(y_train_deception))\n",
    "t_deception = text.Transformer(k_train_model, maxlen=500, classes=t_deception_label)\n",
    "\n",
    "trn_deception = t_deception.preprocess_train(x_train, y_train_deception)\n",
    "val_deception = t_deception.preprocess_test(x_test, y_test_deception)\n",
    "\n",
    "deception_model = t_rapport.get_classifier()\n",
    "learner_deception = ktrain.get_learner(deception_model, \n",
    "                                      train_data=trn_deception, \n",
    "                                      val_data=val_deception, batch_size=6)\n",
    "learner_deception.fit_onecycle(3e-5, 1)\n",
    "learner_deception.validate(class_names=t_deception.get_classes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lynne\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ktrain\\text\\preprocessor.py:215: UserWarning: List or array of two texts supplied, so task being treated as text classification. If this is a sentence pair classification task, please cast to tuple.\n",
      "  warnings.warn('List or array of two texts supplied, so task being treated as text classification. ' +\\\n"
     ]
    }
   ],
   "source": [
    "pred_deception = ktrain.get_predictor(deception_model, preproc=t_deception)\n",
    "y_pred_test_deception = pred_deception.predict(x_test)\n",
    "y_pred_train_deception = pred_deception.predict(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One hot encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train encodings\n",
    "pred_df_arr_full = []\n",
    "pred_df_arr = []\n",
    "for i in range(0, len(y_pred_train_reasoning)):\n",
    "    pred_obj_1 = {}\n",
    "    pred_obj_1['gamemove'] = y_pred_train_gamemove[i]\n",
    "    pred_obj_1['reasoning'] = y_pred_train_reasoning[i]\n",
    "    pred_obj_1['shareinfo'] = y_pred_train_share_information[i]\n",
    "    pred_df_arr.append(pred_obj_1)\n",
    "    \n",
    "    pred_obj_2 = pred_obj_1.copy()\n",
    "    pred_obj_2['rapport'] = y_pred_train_rapport[i]\n",
    "    pred_df_arr_full.append(pred_obj_2)\n",
    "    \n",
    "pred_df_full = pd.DataFrame(pred_df_arr_full)\n",
    "pred_df = pd.DataFrame(pred_df_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test encodings\n",
    "pred_test_df_arr_full = []\n",
    "pred_test_df_arr = []\n",
    "\n",
    "for i in range(0, len(y_pred_test_reasoning)):\n",
    "    pred_obj_1 = {}\n",
    "    pred_obj_1['gamemove'] = y_pred_test_gamemove[i]\n",
    "    pred_obj_1['reasoning'] = y_pred_test_reasoning[i]\n",
    "    pred_obj_1['shareinfo'] = y_pred_test_share_information[i]\n",
    "    pred_test_df_arr.append(pred_obj_1)\n",
    "    \n",
    "    pred_obj_2 = pred_obj_1.copy()\n",
    "    pred_obj_2['rapport'] = y_pred_test_rapport[i]\n",
    "    pred_test_df_arr_full.append(pred_obj_2)\n",
    "    \n",
    "pred_test_df_full = pd.DataFrame(pred_test_df_arr_full)\n",
    "pred_test_df = pd.DataFrame(pred_test_df_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joint model with one hot encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_deception_test = test[\"Input.deception_quadrant\"].copy()\n",
    "new_deception_test['Input.deception_quadrant'] = test[\"Input.deception_quadrant\"].apply(lambda x : 1 if x == \"Straightforward\" else 0)\n",
    "y_test_deception = new_deception_test['Input.deception_quadrant'].tolist()\n",
    "\n",
    "new_deception_train = train[\"Input.deception_quadrant\"].copy()\n",
    "new_deception_train['Input.deception_quadrant'] = train[\"Input.deception_quadrant\"].apply(lambda x : 1 if x == \"Straightforward\" else 0)\n",
    "y_train_deception = new_deception_train['Input.deception_quadrant'].tolist()\n",
    "\n",
    "y_test_rapport = np.asarray(y_test_rapport)\n",
    "y_train_rapport = np.asarray(y_train_rapport)\n",
    "\n",
    "y_test_deception = np.asarray(y_test_deception)\n",
    "y_train_deception = np.asarray(y_train_deception)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joint full model with one hot encoding, predicting deception\n",
      "Model: \"functional_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 4)]               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 4)                 12        \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 27\n",
      "Trainable params: 27\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/32\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.6952 - acc: 0.2500 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: 0.6893 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000\n",
      "Epoch 2/32\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6948 - acc: 0.5000 - f1_m: 0.6667 - precision_m: 0.6667 - recall_m: 0.6667 - val_loss: 0.6895 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000\n",
      "Epoch 3/32\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6945 - acc: 0.5000 - f1_m: 0.6667 - precision_m: 0.6667 - recall_m: 0.6667 - val_loss: 0.6898 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000\n",
      "Epoch 4/32\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6941 - acc: 0.5000 - f1_m: 0.6667 - precision_m: 0.6667 - recall_m: 0.6667 - val_loss: 0.6900 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000\n",
      "Epoch 5/32\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6937 - acc: 0.5000 - f1_m: 0.6667 - precision_m: 0.6667 - recall_m: 0.6667 - val_loss: 0.6903 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000\n",
      "Epoch 6/32\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6933 - acc: 0.5000 - f1_m: 0.6667 - precision_m: 0.6667 - recall_m: 0.6667 - val_loss: 0.6905 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000\n",
      "Epoch 7/32\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6930 - acc: 0.5000 - f1_m: 0.6667 - precision_m: 0.6667 - recall_m: 0.6667 - val_loss: 0.6907 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000\n",
      "Epoch 8/32\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6926 - acc: 0.5000 - f1_m: 0.6667 - precision_m: 0.6667 - recall_m: 0.6667 - val_loss: 0.6910 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000\n",
      "Epoch 9/32\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6922 - acc: 0.5000 - f1_m: 0.6667 - precision_m: 0.6667 - recall_m: 0.6667 - val_loss: 0.6912 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 10/32\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6919 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6914 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 11/32\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6915 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6916 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 12/32\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6912 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6919 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 13/32\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6908 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6921 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 14/32\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6905 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6923 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 15/32\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6901 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6925 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 16/32\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6898 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6927 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 17/32\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6894 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6929 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 18/32\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6891 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6931 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 19/32\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6887 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6932 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 20/32\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6884 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6932 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 21/32\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6882 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6932 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 22/32\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6880 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6932 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 23/32\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6877 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6932 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 24/32\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6875 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6932 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 25/32\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6872 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6932 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 26/32\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6870 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6932 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 27/32\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6867 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6932 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 28/32\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6865 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6932 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 29/32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6863 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6933 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 30/32\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6860 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6933 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 31/32\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6858 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6933 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 32/32\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6855 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6933 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n"
     ]
    }
   ],
   "source": [
    "print('Joint full model with one hot encoding, predicting deception')\n",
    "joint_full_model = models_nn.create_joint_model(pred_df_full)\n",
    "joint_full_model.summary()\n",
    "history = joint_full_model.fit(x=pred_df_full, \n",
    "                               y=y_train_deception, \n",
    "                               epochs=32, \n",
    "                               batch_size=64, \n",
    "                               validation_data=(pred_test_df_full, y_test_deception))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lynne\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.25, 0.5, 0.3333333333333333, None)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joint_predict = joint_full_model.predict(pred_test_df_full)\n",
    "joint_predict_round = joint_predict.round()\n",
    "precision_recall_fscore_support(y_test_deception, np.array(joint_predict_round), average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Joint full model with one hot encoding, predicting rapport')\n",
    "joint_full_model = models_nn.create_joint_model(pred_df)\n",
    "joint_full_model.summary()\n",
    "history = joint_full_model.fit(x=pred_df, \n",
    "                               y=y_train_rapport, \n",
    "                               epochs=32, \n",
    "                               batch_size=64, \n",
    "                               validation_data=(pred_test_df,y_test_rapport))\n",
    "\n",
    "joint_predict = joint_full_model.predict(pred_test_df)\n",
    "joint_predict_round = joint_predict.round()\n",
    "print(precision_recall_fscore_support(y_test_rapport, np.array(joint_predict_round), average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighted against Throughput, WorkTime, PC Agreement & Text Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train weighted encodings\n",
    "pred_df_full_throughput, pred_df_throughput, pred_df_full_worktime, pred_df_worktime, pred_df_full_agreement, pred_df_agreement, pred_df_full_textlength, pred_df_textlength, pred_df_full_special, pred_df_special = metadata_options.construct_weighted_dataframe(indices_train, df_throughput, df_worktime, df_agreement, df_textlength, df_special, pred_df, pred_df_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test weighted encodings\n",
    "pred_df_full_throughput_test, pred_df_throughput_test, pred_df_full_worktime_test, pred_df_worktime_test, pred_df_full_agreement_test, pred_df_agreement_test, pred_df_full_textlength_test, pred_df_textlength_test, pred_df_full_special_test, pred_df_special_test = metadata_options.construct_weighted_dataframe(indices_test, df_throughput, df_worktime, df_agreement, df_textlength, df_special, pred_test_df, pred_test_df_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Throughput only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joint full model with one hot encoding, predicting deception, weighted by throughput\n",
      "Model: \"functional_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 4)]               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 4)                 12        \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 27\n",
      "Trainable params: 27\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/32\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6931 - acc: 0.2500 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: 0.6931 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 2/32\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6929 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6931 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 3/32\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6926 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6931 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 4/32\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6924 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6931 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 5/32\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6921 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6932 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 6/32\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6919 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6932 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 7/32\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6917 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6932 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 8/32\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6914 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6932 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 9/32\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6912 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6932 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 10/32\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6909 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6932 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 11/32\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6907 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6932 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 12/32\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6904 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6932 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 13/32\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6902 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6932 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 14/32\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6899 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6932 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 15/32\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6897 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6932 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 16/32\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6894 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6932 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 17/32\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6892 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6932 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 18/32\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6889 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6932 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 19/32\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6887 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6932 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 20/32\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6884 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6932 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 21/32\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6882 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6932 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 22/32\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6880 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6932 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 23/32\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6877 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6932 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 24/32\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6875 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6932 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 25/32\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6872 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6932 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 26/32\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6870 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6932 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 27/32\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6867 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6932 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 28/32\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6865 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6932 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 29/32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6863 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6933 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 30/32\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6860 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6933 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 31/32\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6858 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6933 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 32/32\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6855 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6933 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "(0.25, 0.5, 0.3333333333333333, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lynne\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print('Joint full model with one hot encoding, predicting deception, weighted by throughput')\n",
    "joint_full_model = models_nn.create_joint_model(pred_df_full_throughput)\n",
    "joint_full_model.summary()\n",
    "history = joint_full_model.fit(x=pred_df_full_throughput, \n",
    "                               y=y_train_deception, \n",
    "                               epochs=32, \n",
    "                               batch_size=64, \n",
    "                               validation_data=(pred_df_full_throughput_test,y_test_deception))\n",
    "\n",
    "joint_predict = joint_full_model.predict(pred_df_full_throughput_test)\n",
    "joint_predict_round = joint_predict.round()\n",
    "print(precision_recall_fscore_support(y_test_deception, np.array(joint_predict_round), average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joint full model with one hot encoding, predicting rapport, weighted by throughput\n",
      "Model: \"functional_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         [(None, 3)]               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 2)                 8         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 4)                 12        \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 25\n",
      "Trainable params: 25\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/32\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.7004 - acc: 0.2500 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: 0.6990 - val_acc: 0.0000e+00 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 2/32\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.7000 - acc: 0.7500 - f1_m: 0.8000 - precision_m: 1.0000 - recall_m: 0.6667 - val_loss: 0.6986 - val_acc: 0.0000e+00 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 3/32\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6996 - acc: 0.7500 - f1_m: 0.8000 - precision_m: 1.0000 - recall_m: 0.6667 - val_loss: 0.6981 - val_acc: 0.0000e+00 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 4/32\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6992 - acc: 0.7500 - f1_m: 0.8000 - precision_m: 1.0000 - recall_m: 0.6667 - val_loss: 0.6977 - val_acc: 0.0000e+00 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 5/32\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6988 - acc: 0.7500 - f1_m: 0.8000 - precision_m: 1.0000 - recall_m: 0.6667 - val_loss: 0.6973 - val_acc: 0.0000e+00 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 6/32\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6984 - acc: 0.7500 - f1_m: 0.8000 - precision_m: 1.0000 - recall_m: 0.6667 - val_loss: 0.6969 - val_acc: 0.0000e+00 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 7/32\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6979 - acc: 0.7500 - f1_m: 0.8000 - precision_m: 1.0000 - recall_m: 0.6667 - val_loss: 0.6965 - val_acc: 0.0000e+00 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 8/32\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6975 - acc: 0.7500 - f1_m: 0.8000 - precision_m: 1.0000 - recall_m: 0.6667 - val_loss: 0.6961 - val_acc: 0.0000e+00 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 9/32\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6971 - acc: 0.7500 - f1_m: 0.8000 - precision_m: 1.0000 - recall_m: 0.6667 - val_loss: 0.6957 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 10/32\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6967 - acc: 0.7500 - f1_m: 0.8000 - precision_m: 1.0000 - recall_m: 0.6667 - val_loss: 0.6953 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 11/32\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6963 - acc: 0.7500 - f1_m: 0.8000 - precision_m: 1.0000 - recall_m: 0.6667 - val_loss: 0.6949 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 12/32\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6959 - acc: 0.7500 - f1_m: 0.8000 - precision_m: 1.0000 - recall_m: 0.6667 - val_loss: 0.6945 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 13/32\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6955 - acc: 0.7500 - f1_m: 0.8000 - precision_m: 1.0000 - recall_m: 0.6667 - val_loss: 0.6941 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 14/32\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6951 - acc: 0.7500 - f1_m: 0.8000 - precision_m: 1.0000 - recall_m: 0.6667 - val_loss: 0.6937 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 15/32\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6947 - acc: 0.7500 - f1_m: 0.8000 - precision_m: 1.0000 - recall_m: 0.6667 - val_loss: 0.6934 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 16/32\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6943 - acc: 0.7500 - f1_m: 0.8000 - precision_m: 1.0000 - recall_m: 0.6667 - val_loss: 0.6930 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 17/32\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6939 - acc: 0.7500 - f1_m: 0.8000 - precision_m: 1.0000 - recall_m: 0.6667 - val_loss: 0.6926 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 18/32\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6935 - acc: 0.7500 - f1_m: 0.8000 - precision_m: 1.0000 - recall_m: 0.6667 - val_loss: 0.6925 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 19/32\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6931 - acc: 0.7500 - f1_m: 0.8000 - precision_m: 1.0000 - recall_m: 0.6667 - val_loss: 0.6925 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 20/32\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6927 - acc: 0.7500 - f1_m: 0.8000 - precision_m: 1.0000 - recall_m: 0.6667 - val_loss: 0.6926 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 21/32\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6923 - acc: 0.7500 - f1_m: 0.8000 - precision_m: 1.0000 - recall_m: 0.6667 - val_loss: 0.6926 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 22/32\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6919 - acc: 0.7500 - f1_m: 0.8000 - precision_m: 1.0000 - recall_m: 0.6667 - val_loss: 0.6926 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 23/32\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6915 - acc: 0.7500 - f1_m: 0.8000 - precision_m: 1.0000 - recall_m: 0.6667 - val_loss: 0.6927 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 24/32\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6912 - acc: 0.7500 - f1_m: 0.8000 - precision_m: 1.0000 - recall_m: 0.6667 - val_loss: 0.6927 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 25/32\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6908 - acc: 0.7500 - f1_m: 0.8000 - precision_m: 1.0000 - recall_m: 0.6667 - val_loss: 0.6927 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 26/32\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6904 - acc: 0.7500 - f1_m: 0.8000 - precision_m: 1.0000 - recall_m: 0.6667 - val_loss: 0.6927 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 27/32\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6900 - acc: 0.7500 - f1_m: 0.8000 - precision_m: 1.0000 - recall_m: 0.6667 - val_loss: 0.6928 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 28/32\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6896 - acc: 0.7500 - f1_m: 0.8000 - precision_m: 1.0000 - recall_m: 0.6667 - val_loss: 0.6928 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/32\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6893 - acc: 0.7500 - f1_m: 0.8000 - precision_m: 1.0000 - recall_m: 0.6667 - val_loss: 0.6928 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 30/32\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6889 - acc: 0.7500 - f1_m: 0.8000 - precision_m: 1.0000 - recall_m: 0.6667 - val_loss: 0.6929 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 31/32\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6885 - acc: 0.7500 - f1_m: 0.8000 - precision_m: 1.0000 - recall_m: 0.6667 - val_loss: 0.6929 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 32/32\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6881 - acc: 0.7500 - f1_m: 0.8000 - precision_m: 1.0000 - recall_m: 0.6667 - val_loss: 0.6929 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "(0.25, 0.5, 0.3333333333333333, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lynne\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print('Joint full model with one hot encoding, predicting rapport, weighted by throughput')\n",
    "joint_full_model = models_nn.create_joint_model(pred_df_throughput)\n",
    "joint_full_model.summary()\n",
    "history = joint_full_model.fit(x=pred_df_throughput, \n",
    "                               y=y_train_rapport, \n",
    "                               epochs=32, \n",
    "                               batch_size=64,\n",
    "                               validation_data=(pred_df_throughput_test,y_test_rapport))\n",
    "\n",
    "joint_predict = joint_full_model.predict(pred_df_throughput_test)\n",
    "joint_predict_round = joint_predict.round()\n",
    "print(precision_recall_fscore_support(y_test_rapport, np.array(joint_predict_round), average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WorkTime only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joint full model with one hot encoding, predicting deception, weighted by worktime\n",
      "Model: \"functional_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         [(None, 4)]               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 4)                 12        \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 27\n",
      "Trainable params: 27\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/32\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.6906 - acc: 0.7500 - f1_m: 0.8000 - precision_m: 1.0000 - recall_m: 0.6667 - val_loss: 0.7099 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 2/32\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6899 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.7104 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 3/32\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6893 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.7109 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 4/32\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6886 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.7113 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 5/32\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6879 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.7118 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 6/32\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6873 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.7123 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 7/32\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6866 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.7128 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 8/32\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6860 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.7133 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 9/32\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6853 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.7138 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 10/32\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6847 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.7143 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 11/32\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6840 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.7148 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 12/32\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6833 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.7153 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 13/32\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6827 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.7158 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 14/32\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6820 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.7163 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 15/32\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6814 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.7168 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 16/32\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6807 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.7174 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 17/32\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6801 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.7179 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 18/32\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6794 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.7184 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 19/32\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6787 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.7190 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 20/32\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6781 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.7195 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 21/32\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6774 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.7201 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 22/32\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6768 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.7206 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 23/32\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6761 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.7212 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 24/32\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6755 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.7218 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 25/32\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6748 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.7224 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 26/32\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6741 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.7230 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 27/32\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6735 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.7235 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 28/32\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6729 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.7241 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 29/32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6722 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.7247 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 30/32\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6716 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.7253 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 31/32\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6710 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.7259 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 32/32\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6704 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.7265 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lynne\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.25, 0.5, 0.3333333333333333, None)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Joint full model with one hot encoding, predicting deception, weighted by worktime')\n",
    "joint_full_model = models_nn.create_joint_model(pred_df_full_worktime)\n",
    "joint_full_model.summary()\n",
    "history = joint_full_model.fit(x=pred_df_full_worktime, \n",
    "                               y=y_train_deception, \n",
    "                               epochs=32, \n",
    "                               batch_size=64, \n",
    "                               validation_data=(pred_df_full_worktime_test,y_test_deception))\n",
    "\n",
    "joint_predict = joint_full_model.predict(pred_df_full_worktime_test)\n",
    "joint_predict_round = joint_predict.round()\n",
    "precision_recall_fscore_support(y_test_deception, np.array(joint_predict_round), average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joint full model with one hot encoding, predicting rapport, weighted by worktime\n",
      "Model: \"functional_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         [(None, 3)]               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 2)                 8         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 4)                 12        \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 25\n",
      "Trainable params: 25\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/32\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.6931 - acc: 0.2500 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: 0.6931 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 2/32\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6929 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6931 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 3/32\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6926 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6931 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 4/32\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6924 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6931 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 5/32\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6921 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6932 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 6/32\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6919 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6932 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 7/32\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6917 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6932 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 8/32\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6914 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6932 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 9/32\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6912 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6932 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 10/32\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6909 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6932 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 11/32\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6907 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6932 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 12/32\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6904 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6932 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 13/32\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6902 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6932 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 14/32\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6899 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6932 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 15/32\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.6897 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6932 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 16/32\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6894 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6932 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 17/32\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6892 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6932 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 18/32\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6889 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6932 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 19/32\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6887 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6932 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 20/32\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6884 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6932 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 21/32\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6882 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6932 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 22/32\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6880 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6932 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 23/32\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6877 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6932 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 24/32\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6875 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6932 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 25/32\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6872 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6932 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 26/32\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6870 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6932 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 27/32\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6867 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6932 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 28/32\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6865 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6932 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 29/32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6863 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6933 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 30/32\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6860 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6933 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 31/32\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6858 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6933 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 32/32\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6855 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6933 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lynne\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.25, 0.5, 0.3333333333333333, None)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Joint full model with one hot encoding, predicting rapport, weighted by worktime')\n",
    "joint_full_model = models_nn.create_joint_model(pred_df_worktime)\n",
    "joint_full_model.summary()\n",
    "history = joint_full_model.fit(x=pred_df_worktime, \n",
    "                               y=y_train_rapport, \n",
    "                               epochs=32, \n",
    "                               batch_size=64,\n",
    "                               validation_data=(pred_df_worktime_test,y_test_rapport))\n",
    "\n",
    "joint_predict = joint_full_model.predict(pred_df_worktime_test)\n",
    "joint_predict_round = joint_predict.round()\n",
    "precision_recall_fscore_support(y_test_rapport, np.array(joint_predict_round), average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PC Agreement only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joint full model with one hot encoding, predicting deception, weighted by PC Agreement\n",
      "Model: \"functional_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_8 (InputLayer)         [(None, 4)]               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 4)                 12        \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 27\n",
      "Trainable params: 27\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/32\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.6911 - acc: 0.5000 - f1_m: 0.5000 - precision_m: 1.0000 - recall_m: 0.3333 - val_loss: 0.6880 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 2/32\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6905 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6880 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 3/32\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6899 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6879 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 4/32\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6893 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6879 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 5/32\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6887 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6879 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 6/32\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6881 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6878 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 7/32\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6875 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6878 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 8/32\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6869 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6878 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 9/32\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6863 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6878 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 10/32\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6857 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6878 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 11/32\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6851 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6877 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 12/32\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6844 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6877 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 13/32\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6838 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6877 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 14/32\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6832 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6877 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 15/32\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6826 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6877 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 16/32\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6820 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6877 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 17/32\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6814 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6877 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 18/32\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6808 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6877 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 19/32\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6802 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6877 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 20/32\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6795 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6877 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 21/32\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6789 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6878 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 22/32\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6783 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6878 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 23/32\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6776 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6878 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 24/32\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6770 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6879 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 25/32\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6764 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6879 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 26/32\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6758 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6880 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 27/32\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6752 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6880 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 28/32\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6745 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6881 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 29/32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6739 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6882 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 30/32\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6733 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6882 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 31/32\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6727 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6883 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 32/32\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6720 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6883 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n"
     ]
    }
   ],
   "source": [
    "print('Joint full model with one hot encoding, predicting deception, weighted by PC Agreement')\n",
    "joint_full_model = models_nn.create_joint_model(pred_df_full_agreement)\n",
    "joint_full_model.summary()\n",
    "history = joint_full_model.fit(x=pred_df_full_agreement, \n",
    "                               y=y_train_deception, \n",
    "                               epochs=32, \n",
    "                               batch_size=64, \n",
    "                               validation_data=(pred_df_full_agreement_test,y_test_deception))\n",
    "\n",
    "joint_predict = joint_full_model.predict(pred_df_full_throughput_test)\n",
    "joint_predict_round = joint_predict.round()\n",
    "precision_recall_fscore_support(y_test_rapport, np.array(joint_predict_round), average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joint full model with one hot encoding, predicting rapport, weighted by PC Agreement\n",
      "Model: \"functional_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         [(None, 3)]               0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 2)                 8         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 4)                 12        \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 25\n",
      "Trainable params: 25\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/32\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.6741 - acc: 0.5000 - f1_m: 0.6667 - precision_m: 0.6667 - recall_m: 0.6667 - val_loss: 0.6911 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 2/32\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6735 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6912 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 3/32\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6730 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6913 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 4/32\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6725 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6914 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 5/32\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6719 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6915 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 6/32\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6714 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6917 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 7/32\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6709 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6918 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 8/32\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6703 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6919 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 9/32\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6698 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6920 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 10/32\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6692 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6922 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 11/32\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6687 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6923 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 12/32\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6681 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6924 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 13/32\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.6676 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6926 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 14/32\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6670 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6927 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 15/32\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6664 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6929 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 16/32\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6659 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6930 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 17/32\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6653 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6932 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 18/32\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6647 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6933 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 19/32\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6642 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6935 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 20/32\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6636 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6937 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 21/32\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6630 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6938 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 22/32\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6624 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6940 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 23/32\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6619 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6942 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 24/32\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6613 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6944 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 25/32\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6607 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6946 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 26/32\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6601 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6948 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 27/32\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6595 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6949 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 28/32\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6589 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6951 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 29/32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6583 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6954 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 30/32\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6577 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6956 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 31/32\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6571 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6958 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 32/32\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6565 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6960 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lynne\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.25, 0.5, 0.3333333333333333, None)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Joint full model with one hot encoding, predicting rapport, weighted by PC Agreement')\n",
    "joint_full_model = models_nn.create_joint_model(pred_df_agreement)\n",
    "joint_full_model.summary()\n",
    "history = joint_full_model.fit(x=pred_df_agreement, \n",
    "                               y=y_train_rapport, \n",
    "                               epochs=32, \n",
    "                               batch_size=64, \n",
    "                               validation_data=(pred_df_agreement_test,y_test_rapport))\n",
    "\n",
    "joint_predict = joint_full_model.predict(pred_df_throughput_test)\n",
    "joint_predict_round = joint_predict.round()\n",
    "precision_recall_fscore_support(y_test_rapport, np.array(joint_predict_round), average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Length only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joint full model with one hot encoding, predicting deception, weighted by text length\n",
      "Model: \"functional_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_10 (InputLayer)        [(None, 4)]               0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 4)                 12        \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 27\n",
      "Trainable params: 27\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/32\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.7501 - acc: 0.2500 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: 0.6891 - val_acc: 0.5000 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 2/32\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.7482 - acc: 0.2500 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: 0.6891 - val_acc: 0.5000 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 3/32\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.7464 - acc: 0.2500 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: 0.6891 - val_acc: 0.5000 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 4/32\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.7445 - acc: 0.2500 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: 0.6891 - val_acc: 0.5000 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 5/32\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.7427 - acc: 0.2500 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: 0.6893 - val_acc: 0.5000 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 6/32\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.7409 - acc: 0.2500 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: 0.6893 - val_acc: 0.5000 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 7/32\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.7391 - acc: 0.2500 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: 0.6893 - val_acc: 0.5000 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 8/32\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.7373 - acc: 0.2500 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: 0.6893 - val_acc: 0.5000 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 9/32\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.7357 - acc: 0.2500 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: 0.6893 - val_acc: 0.5000 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 10/32\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.7341 - acc: 0.2500 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: 0.6893 - val_acc: 0.5000 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 11/32\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.7326 - acc: 0.2500 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: 0.6894 - val_acc: 0.5000 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 12/32\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.7311 - acc: 0.2500 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: 0.6894 - val_acc: 0.5000 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 13/32\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.7296 - acc: 0.2500 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: 0.6894 - val_acc: 0.5000 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 14/32\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.7283 - acc: 0.2500 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: 0.6894 - val_acc: 0.5000 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 15/32\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.7270 - acc: 0.2500 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: 0.6894 - val_acc: 0.5000 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 16/32\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.7257 - acc: 0.2500 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: 0.6895 - val_acc: 0.5000 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 17/32\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.7244 - acc: 0.2500 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: 0.6895 - val_acc: 0.5000 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 18/32\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.7232 - acc: 0.2500 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: 0.6896 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000\n",
      "Epoch 19/32\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.7219 - acc: 0.2500 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: 0.6896 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000\n",
      "Epoch 20/32\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.7207 - acc: 0.2500 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: 0.6897 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000\n",
      "Epoch 21/32\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.7194 - acc: 0.2500 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: 0.6898 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000\n",
      "Epoch 22/32\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.7182 - acc: 0.2500 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: 0.6899 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 23/32\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.7170 - acc: 0.0000e+00 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: 0.6900 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 24/32\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.7158 - acc: 0.2500 - f1_m: 0.4000 - precision_m: 0.5000 - recall_m: 0.3333 - val_loss: 0.6900 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 25/32\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.7146 - acc: 0.2500 - f1_m: 0.4000 - precision_m: 0.5000 - recall_m: 0.3333 - val_loss: 0.6901 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 26/32\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.7134 - acc: 0.2500 - f1_m: 0.4000 - precision_m: 0.5000 - recall_m: 0.3333 - val_loss: 0.6901 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 27/32\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.7123 - acc: 0.2500 - f1_m: 0.4000 - precision_m: 0.5000 - recall_m: 0.3333 - val_loss: 0.6902 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/32\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.7111 - acc: 0.2500 - f1_m: 0.4000 - precision_m: 0.5000 - recall_m: 0.3333 - val_loss: 0.6903 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 29/32\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.7100 - acc: 0.2500 - f1_m: 0.4000 - precision_m: 0.5000 - recall_m: 0.3333 - val_loss: 0.6903 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 30/32\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.7088 - acc: 0.2500 - f1_m: 0.4000 - precision_m: 0.5000 - recall_m: 0.3333 - val_loss: 0.6904 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 31/32\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.7077 - acc: 0.2500 - f1_m: 0.4000 - precision_m: 0.5000 - recall_m: 0.3333 - val_loss: 0.6905 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 32/32\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.7066 - acc: 0.5000 - f1_m: 0.6667 - precision_m: 0.6667 - recall_m: 0.6667 - val_loss: 0.6905 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lynne\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.25, 0.5, 0.3333333333333333, None)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Joint full model with one hot encoding, predicting deception, weighted by text length')\n",
    "joint_full_model = models_nn.create_joint_model(pred_df_full_textlength)\n",
    "joint_full_model.summary()\n",
    "history = joint_full_model.fit(x=pred_df_full_textlength, \n",
    "                               y=y_train_deception, \n",
    "                               epochs=32, \n",
    "                               batch_size=64, \n",
    "                               validation_data=(pred_df_full_textlength_test,y_test_deception))\n",
    "\n",
    "joint_predict = joint_full_model.predict(pred_df_full_textlength_test)\n",
    "joint_predict_round = joint_predict.round()\n",
    "precision_recall_fscore_support(y_test_deception, np.array(joint_predict_round), average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joint full model with one hot encoding, predicting rapport, weighted by text length\n",
      "Model: \"functional_23\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_11 (InputLayer)        [(None, 3)]               0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 2)                 8         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 4)                 12        \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 25\n",
      "Trainable params: 25\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/32\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.6585 - acc: 0.5000 - f1_m: 0.5000 - precision_m: 1.0000 - recall_m: 0.3333 - val_loss: 0.7425 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 2/32\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6574 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.7433 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 3/32\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6562 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.7442 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 4/32\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6551 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.7451 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 5/32\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6539 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.7460 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 6/32\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6528 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.7468 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 7/32\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6516 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.7477 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 8/32\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6504 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.7487 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 9/32\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6493 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.7496 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 10/32\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6481 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.7505 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 11/32\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6469 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.7514 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 12/32\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6458 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.7524 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 13/32\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6446 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.7533 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 14/32\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6435 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.7543 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 15/32\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6423 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.7553 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 16/32\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6411 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.7562 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 17/32\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6400 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.7572 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 18/32\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6388 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.7582 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 19/32\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6377 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.7592 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 20/32\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6365 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.7602 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 21/32\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6354 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.7612 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 22/32\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6342 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.7623 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 23/32\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6331 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.7633 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 24/32\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6320 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.7644 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 25/32\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6308 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.7654 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 26/32\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6297 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.7665 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 27/32\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6286 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.7676 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 28/32\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6274 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.7686 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 29/32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6263 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.7697 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 30/32\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6252 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.7708 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 31/32\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6241 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.7719 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 32/32\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6229 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.7730 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lynne\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.25, 0.5, 0.3333333333333333, None)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Joint full model with one hot encoding, predicting rapport, weighted by text length')\n",
    "joint_full_model = models_nn.create_joint_model(pred_df_textlength)\n",
    "joint_full_model.summary()\n",
    "history = joint_full_model.fit(x=pred_df_textlength, \n",
    "                               y=y_train_rapport, \n",
    "                               epochs=32, \n",
    "                               batch_size=64, \n",
    "                               validation_data=(pred_df_textlength_test,y_test_rapport))\n",
    "\n",
    "joint_predict = joint_full_model.predict(pred_df_textlength_test)\n",
    "joint_predict_round = joint_predict.round()\n",
    "precision_recall_fscore_support(y_test_rapport, np.array(joint_predict_round), average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other special options (either SP1, SP2, SP3, RAND_UNI, or RAND_NORM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joint full model with one hot encoding, predicting deception, weighted by special option\n",
      "Model: \"functional_25\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_12 (InputLayer)        [(None, 4)]               0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 4)                 12        \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 27\n",
      "Trainable params: 27\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/32\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.6870 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6944 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 2/32\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6861 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6945 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 3/32\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6853 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6946 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 4/32\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6845 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6946 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 5/32\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6837 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6947 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 6/32\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6829 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6948 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 7/32\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6821 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6949 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 8/32\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6813 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6950 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 9/32\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6805 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6951 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 10/32\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6797 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6952 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 11/32\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6789 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6953 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 12/32\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6781 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6954 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 13/32\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6773 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6956 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 14/32\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6765 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6957 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 15/32\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6757 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6958 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 16/32\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6749 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6959 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 17/32\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6741 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6961 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 18/32\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6732 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6962 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 19/32\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6724 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6963 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 20/32\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6716 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6965 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 21/32\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6708 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6966 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 22/32\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6700 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6968 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 23/32\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6692 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6969 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 24/32\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6684 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6971 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 25/32\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6676 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6972 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 26/32\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6668 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6974 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 27/32\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6660 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6976 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 28/32\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6652 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6977 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 29/32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6644 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6979 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 30/32\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6636 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6981 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 31/32\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6628 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6983 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n",
      "Epoch 32/32\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6620 - acc: 0.7500 - f1_m: 0.8571 - precision_m: 0.7500 - recall_m: 1.0000 - val_loss: 0.6985 - val_acc: 0.5000 - val_f1_m: 0.6667 - val_precision_m: 0.5000 - val_recall_m: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lynne\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.25, 0.5, 0.3333333333333333, None)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Joint full model with one hot encoding, predicting deception, weighted by special option')\n",
    "joint_full_model = models_nn.create_joint_model(pred_df_full_special)\n",
    "joint_full_model.summary()\n",
    "history = joint_full_model.fit(x=pred_df_full_special, \n",
    "                               y=y_train_deception, \n",
    "                               epochs=32, \n",
    "                               batch_size=64, \n",
    "                               validation_data=(pred_df_full_special_test,y_test_deception))\n",
    "\n",
    "joint_predict = joint_full_model.predict(pred_df_full_special_test)\n",
    "joint_predict_round = joint_predict.round()\n",
    "precision_recall_fscore_support(y_test_deception, np.array(joint_predict_round), average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Joint full model with one hot encoding, predicting rapport, weighted by special option')\n",
    "joint_full_model = models_nn.create_joint_model(pred_df_special)\n",
    "joint_full_model.summary()\n",
    "history = joint_full_model.fit(x=pred_df_special, \n",
    "                               y=y_train_rapport, \n",
    "                               epochs=32, \n",
    "                               batch_size=64,\n",
    "                               validation_data=(pred_df_special_test,y_test_rapport))\n",
    "\n",
    "joint_predict = joint_full_model.predict(pred_df_special_test)\n",
    "joint_predict_round = joint_predict.round()\n",
    "precision_recall_fscore_support(y_test_rapport, np.array(joint_predict_round), average='macro')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfgpu",
   "language": "python",
   "name": "tfgpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
