{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Input, InputLayer, Dropout, Dense, Flatten, Embedding\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/kokil dec 6 reprepare/linguistics/affcon_final_with_linguistics_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size=0.2)\n",
    "\n",
    "y_train_deception = to_categorical(train['Input.deception_quadrant_cat'].tolist())\n",
    "y_train_rapport_c = to_categorical(train['affcon_rapport'].tolist())\n",
    "y_train_rapport = train['affcon_rapport'].tolist()\n",
    "y_train_share_information = train['affcon_shareinformation'].tolist()\n",
    "y_train_reasoning = train['affcon_reasoning'].tolist()\n",
    "y_train_gamemove = train['affcon_gamemove'].tolist()\n",
    "\n",
    "y_test_deception = to_categorical(test['Input.deception_quadrant_cat'].tolist())\n",
    "y_test_rapport_c = to_categorical(test['affcon_rapport'].tolist())\n",
    "y_test_rapport = test['affcon_rapport'].tolist()\n",
    "y_test_share_information = test['affcon_shareinformation'].tolist()\n",
    "y_test_reasoning = test['affcon_reasoning'].tolist()\n",
    "y_test_gamemove = test['affcon_gamemove'].tolist()\n",
    "\n",
    "X_train = train.drop(columns=['affcon_gamemove', 'affcon_reasoning',\n",
    "                              'affcon_rapport', 'affcon_shareinformation', 'Input.deception_quadrant',\n",
    "                              'Input.deception_quadrant_cat'])\n",
    "\n",
    "X_test = test.drop(columns=['affcon_gamemove', 'affcon_reasoning',\n",
    "                              'affcon_rapport', 'affcon_shareinformation', 'Input.deception_quadrant',\n",
    "                              'Input.deception_quadrant_cat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       1.00      0.84      0.91      3210\n",
      "\n",
      "    accuracy                           0.84      3210\n",
      "   macro avg       0.50      0.42      0.46      3210\n",
      "weighted avg       1.00      0.84      0.91      3210\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lynne\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Game move classifier\n",
    "clf_gamemove = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "clf_gamemove.fit(X_train, y_train_gamemove)\n",
    "y_pred_gamemove = clf_gamemove.predict(X_train)\n",
    "y_pred_test_gamemove = clf_gamemove.predict(X_test)\n",
    "print(classification_report(y_pred_gamemove, y_train_gamemove))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       1.00      0.83      0.91      3210\n",
      "\n",
      "    accuracy                           0.83      3210\n",
      "   macro avg       0.50      0.42      0.45      3210\n",
      "weighted avg       1.00      0.83      0.91      3210\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lynne\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Rapport classifier\n",
    "clf_rapport = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "clf_rapport.fit(X_train, y_train_rapport)\n",
    "y_pred_rapport = clf_rapport.predict(X_train)\n",
    "y_pred_test_rapport = clf_rapport.predict(X_test)\n",
    "print(classification_report(y_pred_rapport, y_train_rapport))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       1.00      0.81      0.89      3210\n",
      "\n",
      "    accuracy                           0.81      3210\n",
      "   macro avg       0.50      0.40      0.45      3210\n",
      "weighted avg       1.00      0.81      0.89      3210\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lynne\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Share Information classifier\n",
    "clf_shareinfo = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "clf_shareinfo.fit(X_train, y_train_share_information)\n",
    "y_pred_shareinfo = clf_shareinfo.predict(X_train)\n",
    "y_pred_test_shareinfo = clf_shareinfo.predict(X_test)\n",
    "print(classification_report(y_pred_shareinfo, y_train_share_information))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       1.00      0.80      0.89      3210\n",
      "\n",
      "    accuracy                           0.80      3210\n",
      "   macro avg       0.50      0.40      0.44      3210\n",
      "weighted avg       1.00      0.80      0.89      3210\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lynne\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Reasoning classifier\n",
    "clf_reasoning = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "clf_reasoning.fit(X_train, y_train_reasoning)\n",
    "y_pred_reasoning = clf_reasoning.predict(X_train)\n",
    "y_pred_test_reasoning = clf_reasoning.predict(X_test)\n",
    "print(classification_report(y_pred_reasoning, y_train_reasoning))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df_arr = []\n",
    "for i in range(0, len(y_pred_gamemove)):\n",
    "    pred_obj = {}\n",
    "    pred_obj['gamemove'] = y_pred_gamemove[i]\n",
    "    pred_obj['reasoning'] = y_pred_reasoning[i]\n",
    "    pred_obj['shareinfo'] = y_pred_shareinfo[i]\n",
    "    pred_obj['rapport'] = y_pred_rapport[i]\n",
    "    \n",
    "    pred_df_arr.append(pred_obj)\n",
    "    \n",
    "pred_df = pd.DataFrame(pred_df_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test_df_arr = []\n",
    "for i in range(0, len(y_pred_test_gamemove)):\n",
    "    pred_obj = {}\n",
    "    pred_obj['gamemove'] = y_pred_test_gamemove[i]\n",
    "    pred_obj['reasoning'] = y_pred_test_reasoning[i]\n",
    "    pred_obj['shareinfo'] = y_pred_test_shareinfo[i]\n",
    "    pred_obj['rapport'] = y_pred_test_rapport[i]\n",
    "    \n",
    "    pred_test_df_arr.append(pred_obj)\n",
    "    \n",
    "pred_test_df = pd.DataFrame(pred_test_df_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', min_delta=0, patience=0, verbose=0, mode='auto',\n",
    "    baseline=None, restore_best_weights=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "51/51 [==============================] - 0s 8ms/step - loss: 7.7125 - acc: 0.0458 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: 7.7125 - val_acc: 0.0523 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 2/32\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 7.7125 - acc: 0.0458 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: 7.7125 - val_acc: 0.0523 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "# Combined model\n",
    "\n",
    "inputB = Input(shape=(pred_df.shape[1],))\n",
    "c = Dense(2, activation='relu')(inputB)\n",
    "c = Dense(4, activation='relu')(c)\n",
    "c = Dense(2, activation='linear')(c)\n",
    "m = Model(inputs=inputB, outputs=c)\n",
    "\n",
    "m.compile(loss='binary_crossentropy', optimizer='adam', \n",
    "                      metrics=['acc',f1_m, precision_m,recall_m])\n",
    "history = m.fit(x=pred_df, y=y_train_deception, epochs=32, \n",
    "                    batch_size=64, \n",
    "                    validation_data=(pred_test_df,y_test_deception), callbacks=[callback])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfgpu",
   "language": "python",
   "name": "tfgpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
