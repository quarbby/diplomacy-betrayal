{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Input, Embedding, Flatten, Conv1D, MaxPooling1D\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.read_csv('data/kokil dec 6 reprepare/conf_good_agg_withpc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HITId</th>\n",
       "      <th>Input.sentence_id</th>\n",
       "      <th>Input.convo_id</th>\n",
       "      <th>Input.train_test_val</th>\n",
       "      <th>Input.msg_id</th>\n",
       "      <th>Input.timestamp</th>\n",
       "      <th>Input.full_text</th>\n",
       "      <th>Input.speaker</th>\n",
       "      <th>Input.reply_to</th>\n",
       "      <th>Input.speaker_intention</th>\n",
       "      <th>...</th>\n",
       "      <th>Answer.3rapport.yes_pc_agree</th>\n",
       "      <th>Answer.4shareinformation.yes_pc_agree</th>\n",
       "      <th>Answer.1gamemove.yes_label</th>\n",
       "      <th>Answer.2reasoning.yes_label</th>\n",
       "      <th>Answer.3a_apologies.yes_label</th>\n",
       "      <th>Answer.3a_compliment.yes_label</th>\n",
       "      <th>Answer.3a_personalthoughts.yes_label</th>\n",
       "      <th>Answer.3a_reassurance.yes_label</th>\n",
       "      <th>Answer.3rapport.yes_label</th>\n",
       "      <th>Answer.4shareinformation.yes_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>301KG0KX9CLR06T6MC6UVPAHBC92HU</td>\n",
       "      <td>22056</td>\n",
       "      <td>Game7-turkey-austria</td>\n",
       "      <td>Train</td>\n",
       "      <td>Game7-turkey-austria-9</td>\n",
       "      <td>197</td>\n",
       "      <td>Im moving my fleet to Alb not for Greece but f...</td>\n",
       "      <td>austria-Game7</td>\n",
       "      <td>Game7-turkey-austria-8</td>\n",
       "      <td>Truth</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>301KG0KX9CLR06T6MC6UVPAHBCAH2A</td>\n",
       "      <td>6906</td>\n",
       "      <td>Game11-austria-italy</td>\n",
       "      <td>Validation</td>\n",
       "      <td>Game11-austria-italy-5</td>\n",
       "      <td>45</td>\n",
       "      <td>And yes I would like peace on our front, I cou...</td>\n",
       "      <td>austria-Game11</td>\n",
       "      <td>Game11-austria-italy-4</td>\n",
       "      <td>Truth</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>301KG0KX9CLR06T6MC6UVPAHBCC2HX</td>\n",
       "      <td>3066</td>\n",
       "      <td>Game1-england-germany</td>\n",
       "      <td>Train</td>\n",
       "      <td>Game1-england-germany-271</td>\n",
       "      <td>1468</td>\n",
       "      <td>okay...well, as the person who has ever seen a...</td>\n",
       "      <td>germany-Game1</td>\n",
       "      <td>Game1-england-germany-270</td>\n",
       "      <td>Truth</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>301KG0KX9CLR06T6MC6UVPAHBCCH2C</td>\n",
       "      <td>24093</td>\n",
       "      <td>Game9-italy-germany</td>\n",
       "      <td>Train</td>\n",
       "      <td>Game9-italy-germany-70</td>\n",
       "      <td>1460</td>\n",
       "      <td>I think the best thing we can do to keep the a...</td>\n",
       "      <td>germany-Game9</td>\n",
       "      <td>Game9-italy-germany-69</td>\n",
       "      <td>Truth</td>\n",
       "      <td>...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>301KG0KX9CLR06T6MC6UVPAHBCD2HY</td>\n",
       "      <td>1591</td>\n",
       "      <td>Game1-england-italy</td>\n",
       "      <td>Train</td>\n",
       "      <td>Game1-england-italy-273</td>\n",
       "      <td>1809</td>\n",
       "      <td>We'll see if I can keep it friendly.</td>\n",
       "      <td>england-Game1</td>\n",
       "      <td>Game1-england-italy-272</td>\n",
       "      <td>Truth</td>\n",
       "      <td>...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            HITId  Input.sentence_id         Input.convo_id  \\\n",
       "0  301KG0KX9CLR06T6MC6UVPAHBC92HU              22056   Game7-turkey-austria   \n",
       "1  301KG0KX9CLR06T6MC6UVPAHBCAH2A               6906   Game11-austria-italy   \n",
       "2  301KG0KX9CLR06T6MC6UVPAHBCC2HX               3066  Game1-england-germany   \n",
       "3  301KG0KX9CLR06T6MC6UVPAHBCCH2C              24093    Game9-italy-germany   \n",
       "4  301KG0KX9CLR06T6MC6UVPAHBCD2HY               1591    Game1-england-italy   \n",
       "\n",
       "  Input.train_test_val               Input.msg_id  Input.timestamp  \\\n",
       "0                Train     Game7-turkey-austria-9              197   \n",
       "1           Validation     Game11-austria-italy-5               45   \n",
       "2                Train  Game1-england-germany-271             1468   \n",
       "3                Train     Game9-italy-germany-70             1460   \n",
       "4                Train    Game1-england-italy-273             1809   \n",
       "\n",
       "                                     Input.full_text   Input.speaker  \\\n",
       "0  Im moving my fleet to Alb not for Greece but f...   austria-Game7   \n",
       "1  And yes I would like peace on our front, I cou...  austria-Game11   \n",
       "2  okay...well, as the person who has ever seen a...   germany-Game1   \n",
       "3  I think the best thing we can do to keep the a...   germany-Game9   \n",
       "4               We'll see if I can keep it friendly.   england-Game1   \n",
       "\n",
       "              Input.reply_to Input.speaker_intention  ...  \\\n",
       "0     Game7-turkey-austria-8                   Truth  ...   \n",
       "1     Game11-austria-italy-4                   Truth  ...   \n",
       "2  Game1-england-germany-270                   Truth  ...   \n",
       "3     Game9-italy-germany-69                   Truth  ...   \n",
       "4    Game1-england-italy-272                   Truth  ...   \n",
       "\n",
       "  Answer.3rapport.yes_pc_agree Answer.4shareinformation.yes_pc_agree  \\\n",
       "0                         1.00                              1.000000   \n",
       "1                         1.00                              1.000000   \n",
       "2                         1.00                              0.666667   \n",
       "3                         0.75                              0.750000   \n",
       "4                         0.75                              0.750000   \n",
       "\n",
       "   Answer.1gamemove.yes_label  Answer.2reasoning.yes_label  \\\n",
       "0                         1.0                          1.0   \n",
       "1                         1.0                          1.0   \n",
       "2                         1.0                          1.0   \n",
       "3                         1.0                          1.0   \n",
       "4                         1.0                          1.0   \n",
       "\n",
       "   Answer.3a_apologies.yes_label  Answer.3a_compliment.yes_label  \\\n",
       "0                            1.0                             1.0   \n",
       "1                            1.0                             1.0   \n",
       "2                            1.0                             1.0   \n",
       "3                            1.0                             1.0   \n",
       "4                            1.0                             1.0   \n",
       "\n",
       "   Answer.3a_personalthoughts.yes_label  Answer.3a_reassurance.yes_label  \\\n",
       "0                                   1.0                              1.0   \n",
       "1                                   1.0                              1.0   \n",
       "2                                   1.0                              1.0   \n",
       "3                                   1.0                              1.0   \n",
       "4                                   NaN                              NaN   \n",
       "\n",
       "  Answer.3rapport.yes_label  Answer.4shareinformation.yes_label  \n",
       "0                       1.0                                 1.0  \n",
       "1                       1.0                                 1.0  \n",
       "2                       1.0                                 1.0  \n",
       "3                       1.0                                 1.0  \n",
       "4                       1.0                                 1.0  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 718 rows with NaN\n",
      "(2636,)\n",
      "(2636, 1)\n",
      "(659,)\n",
      "(659, 1)\n"
     ]
    }
   ],
   "source": [
    "full_df_length = full_df.shape[0]\n",
    "full_df = full_df.dropna() # dataset contains NaN values, dropping NaNs here\n",
    "\n",
    "X = full_df['Input.full_text']\n",
    "\n",
    "print(\"Dropped {} rows with NaN\".format(full_df_length - X.shape[0]))\n",
    "\n",
    "# full_df[\"Input.deception_quadrant\"] = full_df[\"Input.deception_quadrant\"].apply(lambda x : 1 if x == \"Straightforward\" else 0)\n",
    "y = full_df['Answer.4shareinformation.yes_label']\n",
    "\n",
    "le = LabelEncoder() # this can convert our categories into labels, make sure you don't have NaNs or Nulls in your data first\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "# we reshape \n",
    "y = y.reshape(-1,1) # the -1 allows it to have whatever number went in there\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 1000\n",
    "max_len = 150\n",
    "\n",
    "tok = Tokenizer(num_words=max_words, oov_token=True)\n",
    "tok.fit_on_texts(X_train)\n",
    "\n",
    "sequences = tok.texts_to_sequences(X_train)\n",
    "X_train = sequence.pad_sequences(sequences,maxlen=max_len)\n",
    "# X_train = sequence.pad_sequences(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          [(None, 150)]             0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 150, 100)          100000    \n",
      "_________________________________________________________________\n",
      "LSTM_01 (LSTM)               (None, 64)                42240     \n",
      "_________________________________________________________________\n",
      "Dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "Dense_01 (Dense)             (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "Dense_02 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 158,881\n",
      "Trainable params: 158,881\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Inp = Input(name='inputs',shape=[max_len])\n",
    "x = Embedding(max_words,100,input_length=max_len)(Inp)\n",
    "x = LSTM(64,name='LSTM_01')(x)\n",
    "x = Dropout(0.3,name='Dropout')(x)\n",
    "x = Dense(128,activation='relu',name='Dense_01')(x)\n",
    "x = Dense(64,activation='relu',name='Dense_02')(x)\n",
    "# x = Dropout(0.5,name='Dropout')(x)\n",
    "out = Dense(1,activation='sigmoid', name='output')(x)\n",
    "\n",
    "model = Model(inputs=Inp,outputs=out)\n",
    "\n",
    "model.compile(loss='binary_crossentropy',optimizer=RMSprop(),metrics=['acc',f1_m,precision_m, recall_m])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.4873 - acc: 0.8250 - f1_m: 0.8964 - precision_m: 0.8549 - recall_m: 0.9620 - val_loss: 0.3937 - val_acc: 0.8674 - val_f1_m: 0.9356 - val_precision_m: 0.8797 - val_recall_m: 1.0000\n",
      "Epoch 2/30\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.4150 - acc: 0.8553 - f1_m: 0.9195 - precision_m: 0.8520 - recall_m: 1.0000 - val_loss: 0.4354 - val_acc: 0.8674 - val_f1_m: 0.9356 - val_precision_m: 0.8797 - val_recall_m: 1.0000\n",
      "Epoch 3/30\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.4137 - acc: 0.8553 - f1_m: 0.9238 - precision_m: 0.8593 - recall_m: 1.0000 - val_loss: 0.4216 - val_acc: 0.8674 - val_f1_m: 0.9356 - val_precision_m: 0.8797 - val_recall_m: 1.0000\n",
      "Epoch 4/30\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.3906 - acc: 0.8553 - f1_m: 0.9223 - precision_m: 0.8562 - recall_m: 1.0000 - val_loss: 0.3990 - val_acc: 0.8674 - val_f1_m: 0.9356 - val_precision_m: 0.8797 - val_recall_m: 1.0000\n",
      "Epoch 5/30\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.3477 - acc: 0.8553 - f1_m: 0.9208 - precision_m: 0.8536 - recall_m: 1.0000 - val_loss: 0.4284 - val_acc: 0.8636 - val_f1_m: 0.9338 - val_precision_m: 0.8793 - val_recall_m: 0.9964\n",
      "Epoch 6/30\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.3120 - acc: 0.8634 - f1_m: 0.9248 - precision_m: 0.8648 - recall_m: 0.9947 - val_loss: 0.4658 - val_acc: 0.8447 - val_f1_m: 0.9302 - val_precision_m: 0.8907 - val_recall_m: 0.9749\n",
      "Epoch 7/30\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.2824 - acc: 0.8805 - f1_m: 0.9325 - precision_m: 0.8917 - recall_m: 0.9785 - val_loss: 0.5536 - val_acc: 0.8428 - val_f1_m: 0.9289 - val_precision_m: 0.8913 - val_recall_m: 0.9709\n",
      "Epoch 8/30\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.2669 - acc: 0.8866 - f1_m: 0.9359 - precision_m: 0.9114 - recall_m: 0.9633 - val_loss: 0.5617 - val_acc: 0.8163 - val_f1_m: 0.9156 - val_precision_m: 0.8894 - val_recall_m: 0.9440\n",
      "Epoch 9/30\n",
      "17/17 [==============================] - 0s 15ms/step - loss: 0.2378 - acc: 0.9037 - f1_m: 0.9448 - precision_m: 0.9273 - recall_m: 0.9646 - val_loss: 0.6194 - val_acc: 0.8182 - val_f1_m: 0.9167 - val_precision_m: 0.8885 - val_recall_m: 0.9476\n",
      "Epoch 10/30\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.2208 - acc: 0.9127 - f1_m: 0.9493 - precision_m: 0.9355 - recall_m: 0.9644 - val_loss: 0.6245 - val_acc: 0.7973 - val_f1_m: 0.9055 - val_precision_m: 0.8881 - val_recall_m: 0.9239\n",
      "Epoch 11/30\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.2033 - acc: 0.9231 - f1_m: 0.9559 - precision_m: 0.9477 - recall_m: 0.9657 - val_loss: 0.7543 - val_acc: 0.8409 - val_f1_m: 0.9276 - val_precision_m: 0.8934 - val_recall_m: 0.9655\n",
      "Epoch 12/30\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.1869 - acc: 0.9255 - f1_m: 0.9547 - precision_m: 0.9471 - recall_m: 0.9638 - val_loss: 0.7329 - val_acc: 0.7936 - val_f1_m: 0.8912 - val_precision_m: 0.8895 - val_recall_m: 0.8957\n",
      "Epoch 13/30\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.1688 - acc: 0.9336 - f1_m: 0.9601 - precision_m: 0.9576 - recall_m: 0.9640 - val_loss: 0.8226 - val_acc: 0.8182 - val_f1_m: 0.9040 - val_precision_m: 0.8913 - val_recall_m: 0.9210\n",
      "Epoch 14/30\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.1447 - acc: 0.9435 - f1_m: 0.9671 - precision_m: 0.9631 - recall_m: 0.9721 - val_loss: 0.9369 - val_acc: 0.7765 - val_f1_m: 0.8748 - val_precision_m: 0.8886 - val_recall_m: 0.8659\n",
      "Epoch 15/30\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.1244 - acc: 0.9583 - f1_m: 0.9758 - precision_m: 0.9722 - recall_m: 0.9801 - val_loss: 0.9632 - val_acc: 0.7860 - val_f1_m: 0.8804 - val_precision_m: 0.8861 - val_recall_m: 0.8805\n",
      "Epoch 16/30\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.1131 - acc: 0.9620 - f1_m: 0.9786 - precision_m: 0.9762 - recall_m: 0.9813 - val_loss: 1.0440 - val_acc: 0.7538 - val_f1_m: 0.8548 - val_precision_m: 0.8872 - val_recall_m: 0.8312\n",
      "Epoch 17/30\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.1030 - acc: 0.9673 - f1_m: 0.9810 - precision_m: 0.9781 - recall_m: 0.9843 - val_loss: 1.0492 - val_acc: 0.7917 - val_f1_m: 0.8970 - val_precision_m: 0.8851 - val_recall_m: 0.9107\n",
      "Epoch 18/30\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.0921 - acc: 0.9673 - f1_m: 0.9809 - precision_m: 0.9784 - recall_m: 0.9838 - val_loss: 1.1728 - val_acc: 0.7500 - val_f1_m: 0.8533 - val_precision_m: 0.8842 - val_recall_m: 0.8312\n",
      "Epoch 19/30\n",
      "17/17 [==============================] - 0s 18ms/step - loss: 0.0694 - acc: 0.9791 - f1_m: 0.9881 - precision_m: 0.9889 - recall_m: 0.9875 - val_loss: 1.4168 - val_acc: 0.7708 - val_f1_m: 0.8724 - val_precision_m: 0.8855 - val_recall_m: 0.8643\n",
      "Epoch 20/30\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0645 - acc: 0.9758 - f1_m: 0.9851 - precision_m: 0.9818 - recall_m: 0.9886 - val_loss: 1.2339 - val_acc: 0.7273 - val_f1_m: 0.8409 - val_precision_m: 0.8813 - val_recall_m: 0.8095\n",
      "Epoch 21/30\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0630 - acc: 0.9829 - f1_m: 0.9899 - precision_m: 0.9895 - recall_m: 0.9904 - val_loss: 1.3572 - val_acc: 0.7576 - val_f1_m: 0.8652 - val_precision_m: 0.8838 - val_recall_m: 0.8517\n",
      "Epoch 22/30\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.0386 - acc: 0.9886 - f1_m: 0.9932 - precision_m: 0.9936 - recall_m: 0.9929 - val_loss: 1.6929 - val_acc: 0.7311 - val_f1_m: 0.8495 - val_precision_m: 0.8838 - val_recall_m: 0.8209\n",
      "Epoch 23/30\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.0453 - acc: 0.9843 - f1_m: 0.9907 - precision_m: 0.9910 - recall_m: 0.9906 - val_loss: 1.7056 - val_acc: 0.7576 - val_f1_m: 0.8647 - val_precision_m: 0.8862 - val_recall_m: 0.8481\n",
      "Epoch 24/30\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0340 - acc: 0.9867 - f1_m: 0.9922 - precision_m: 0.9915 - recall_m: 0.9930 - val_loss: 1.8960 - val_acc: 0.7367 - val_f1_m: 0.8532 - val_precision_m: 0.8834 - val_recall_m: 0.8281\n",
      "Epoch 25/30\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.0254 - acc: 0.9929 - f1_m: 0.9954 - precision_m: 0.9948 - recall_m: 0.9962 - val_loss: 2.0749 - val_acc: 0.7330 - val_f1_m: 0.8423 - val_precision_m: 0.8883 - val_recall_m: 0.8056\n",
      "Epoch 26/30\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0570 - acc: 0.9839 - f1_m: 0.9906 - precision_m: 0.9893 - recall_m: 0.9924 - val_loss: 1.8422 - val_acc: 0.7652 - val_f1_m: 0.8690 - val_precision_m: 0.8859 - val_recall_m: 0.8571\n",
      "Epoch 27/30\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.0193 - acc: 0.9972 - f1_m: 0.9984 - precision_m: 0.9978 - recall_m: 0.9989 - val_loss: 2.0551 - val_acc: 0.7481 - val_f1_m: 0.8589 - val_precision_m: 0.8875 - val_recall_m: 0.8353\n",
      "Epoch 28/30\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.0156 - acc: 0.9953 - f1_m: 0.9973 - precision_m: 0.9968 - recall_m: 0.9979 - val_loss: 2.1869 - val_acc: 0.7405 - val_f1_m: 0.8546 - val_precision_m: 0.8865 - val_recall_m: 0.8281\n",
      "Epoch 29/30\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.0159 - acc: 0.9962 - f1_m: 0.9979 - precision_m: 0.9979 - recall_m: 0.9979 - val_loss: 2.2985 - val_acc: 0.7424 - val_f1_m: 0.8560 - val_precision_m: 0.8854 - val_recall_m: 0.8317\n",
      "Epoch 30/30\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.0178 - acc: 0.9948 - f1_m: 0.9971 - precision_m: 0.9963 - recall_m: 0.9978 - val_loss: 2.3131 - val_acc: 0.7481 - val_f1_m: 0.8655 - val_precision_m: 0.8873 - val_recall_m: 0.8468\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f403f4c4fd0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss',min_delta=0.00001)\n",
    "\n",
    "# model.fit(X_train,y_train,\n",
    "#           batch_size=128,\n",
    "#           epochs=15,\n",
    "#           validation_split=0.2,\n",
    "#           callbacks=[early_stop])\n",
    "\n",
    "model.fit(X_train,y_train,\n",
    "          batch_size=128,\n",
    "          epochs=30,\n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 4ms/step - loss: 2.3552 - acc: 0.7572 - f1_m: 0.8581 - precision_m: 0.8386 - recall_m: 0.8818\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.355189085006714,\n",
       " 0.7572078704833984,\n",
       " 0.8580648303031921,\n",
       " 0.8386263251304626,\n",
       " 0.8818392753601074]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sequences_LSTM = tok.texts_to_sequences(X_test)\n",
    "X_test_LSTM = sequence.pad_sequences(test_sequences_LSTM,maxlen=max_len)\n",
    "model.evaluate(X_test_LSTM,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"CNN_with_embeddings\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 150, 100)          100000    \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 141, 128)          128128    \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 70, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 8960)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 8960)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                286752    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 514,913\n",
      "Trainable params: 514,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_CNN = Sequential(name=\"CNN_with_embeddings\")\n",
    "model_CNN.add(Embedding(max_words, 100, input_length=max_len))\n",
    "model_CNN.add(Conv1D(filters=128, kernel_size=10, activation='relu'))\n",
    "model_CNN.add(MaxPooling1D(pool_size=2))\n",
    "model_CNN.add(Flatten())\n",
    "model_CNN.add(Dropout(0.5))\n",
    "model_CNN.add(Dense(32, activation='relu'))\n",
    "model_CNN.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_CNN.compile(loss='binary_crossentropy', \n",
    "              optimizer= 'adam',\n",
    "              metrics=['acc',f1_m,precision_m, recall_m])\n",
    "\n",
    "model_CNN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.4492 - acc: 0.8529 - f1_m: 0.9193 - precision_m: 0.8547 - recall_m: 0.9951 - val_loss: 0.4787 - val_acc: 0.8220 - val_f1_m: 0.9011 - val_precision_m: 0.8203 - val_recall_m: 1.0000\n",
      "Epoch 2/15\n",
      "17/17 [==============================] - 0s 15ms/step - loss: 0.4086 - acc: 0.8567 - f1_m: 0.9208 - precision_m: 0.8539 - recall_m: 1.0000 - val_loss: 0.4712 - val_acc: 0.8220 - val_f1_m: 0.9011 - val_precision_m: 0.8203 - val_recall_m: 1.0000\n",
      "Epoch 3/15\n",
      "17/17 [==============================] - 0s 15ms/step - loss: 0.3987 - acc: 0.8567 - f1_m: 0.9231 - precision_m: 0.8576 - recall_m: 1.0000 - val_loss: 0.4777 - val_acc: 0.8220 - val_f1_m: 0.9011 - val_precision_m: 0.8203 - val_recall_m: 1.0000\n",
      "Epoch 4/15\n",
      "17/17 [==============================] - 0s 15ms/step - loss: 0.3688 - acc: 0.8567 - f1_m: 0.9221 - precision_m: 0.8560 - recall_m: 1.0000 - val_loss: 0.4964 - val_acc: 0.8220 - val_f1_m: 0.9011 - val_precision_m: 0.8203 - val_recall_m: 1.0000\n",
      "Epoch 5/15\n",
      "17/17 [==============================] - 0s 14ms/step - loss: 0.3116 - acc: 0.8567 - f1_m: 0.9231 - precision_m: 0.8581 - recall_m: 1.0000 - val_loss: 0.6332 - val_acc: 0.8220 - val_f1_m: 0.9011 - val_precision_m: 0.8203 - val_recall_m: 1.0000\n",
      "Epoch 6/15\n",
      "17/17 [==============================] - 0s 14ms/step - loss: 0.2477 - acc: 0.8567 - f1_m: 0.9231 - precision_m: 0.8576 - recall_m: 1.0000 - val_loss: 0.6357 - val_acc: 0.8220 - val_f1_m: 0.9011 - val_precision_m: 0.8203 - val_recall_m: 1.0000\n",
      "Epoch 7/15\n",
      "17/17 [==============================] - 0s 15ms/step - loss: 0.1978 - acc: 0.8937 - f1_m: 0.9412 - precision_m: 0.8914 - recall_m: 0.9973 - val_loss: 0.7732 - val_acc: 0.8125 - val_f1_m: 0.8890 - val_precision_m: 0.8198 - val_recall_m: 0.9715\n",
      "Epoch 8/15\n",
      "17/17 [==============================] - 0s 15ms/step - loss: 0.1641 - acc: 0.9231 - f1_m: 0.9559 - precision_m: 0.9172 - recall_m: 0.9990 - val_loss: 0.8710 - val_acc: 0.7822 - val_f1_m: 0.8733 - val_precision_m: 0.8166 - val_recall_m: 0.9397\n",
      "Epoch 9/15\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.1444 - acc: 0.9497 - f1_m: 0.9714 - precision_m: 0.9476 - recall_m: 0.9968 - val_loss: 0.9758 - val_acc: 0.7860 - val_f1_m: 0.8750 - val_precision_m: 0.8180 - val_recall_m: 0.9412\n",
      "Epoch 10/15\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.1292 - acc: 0.9535 - f1_m: 0.9737 - precision_m: 0.9516 - recall_m: 0.9973 - val_loss: 1.1186 - val_acc: 0.7841 - val_f1_m: 0.8738 - val_precision_m: 0.8189 - val_recall_m: 0.9376\n",
      "Epoch 11/15\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.1163 - acc: 0.9701 - f1_m: 0.9831 - precision_m: 0.9699 - recall_m: 0.9968 - val_loss: 1.1819 - val_acc: 0.7727 - val_f1_m: 0.8678 - val_precision_m: 0.8170 - val_recall_m: 0.9259\n",
      "Epoch 12/15\n",
      "17/17 [==============================] - 0s 14ms/step - loss: 0.1106 - acc: 0.9815 - f1_m: 0.9894 - precision_m: 0.9807 - recall_m: 0.9984 - val_loss: 1.2494 - val_acc: 0.7803 - val_f1_m: 0.8716 - val_precision_m: 0.8192 - val_recall_m: 0.9318\n",
      "Epoch 13/15\n",
      "17/17 [==============================] - 0s 14ms/step - loss: 0.1042 - acc: 0.9858 - f1_m: 0.9919 - precision_m: 0.9861 - recall_m: 0.9979 - val_loss: 1.2818 - val_acc: 0.7860 - val_f1_m: 0.8742 - val_precision_m: 0.8226 - val_recall_m: 0.9337\n",
      "Epoch 14/15\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.1007 - acc: 0.9872 - f1_m: 0.9924 - precision_m: 0.9865 - recall_m: 0.9984 - val_loss: 1.3518 - val_acc: 0.7822 - val_f1_m: 0.8724 - val_precision_m: 0.8208 - val_recall_m: 0.9318\n",
      "Epoch 15/15\n",
      "17/17 [==============================] - 0s 14ms/step - loss: 0.0974 - acc: 0.9929 - f1_m: 0.9960 - precision_m: 0.9936 - recall_m: 0.9984 - val_loss: 1.3544 - val_acc: 0.7727 - val_f1_m: 0.8667 - val_precision_m: 0.8227 - val_recall_m: 0.9166\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa15c15ac88>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss',min_delta=0.000001)\n",
    "\n",
    "# model_CNN.fit(X_train,y_train,\n",
    "#           batch_size=256,\n",
    "#           epochs=15,\n",
    "#           validation_split=0.2,\n",
    "#           callbacks=[early_stop])\n",
    "\n",
    "model_CNN.fit(X_train,y_train,\n",
    "          batch_size=128,\n",
    "          epochs=15,\n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 3ms/step - loss: 1.1617 - acc: 0.8209 - f1_m: 0.8996 - precision_m: 0.8715 - recall_m: 0.9336\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.1617460250854492,\n",
       " 0.8209407925605774,\n",
       " 0.8995769023895264,\n",
       " 0.8714513182640076,\n",
       " 0.9335665106773376]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sequences_CNN = tok.texts_to_sequences(X_test)\n",
    "X_test_CNN = sequence.pad_sequences(test_sequences_CNN,maxlen=max_len)\n",
    "\n",
    "model_CNN.evaluate(X_test_CNN,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
