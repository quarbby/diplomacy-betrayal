{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Input, Embedding, Flatten, Conv1D, MaxPooling1D\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.read_csv('data/kokil dec 6 reprepare/conf_good_agg_withpc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HITId</th>\n",
       "      <th>Input.sentence_id</th>\n",
       "      <th>Input.convo_id</th>\n",
       "      <th>Input.train_test_val</th>\n",
       "      <th>Input.msg_id</th>\n",
       "      <th>Input.timestamp</th>\n",
       "      <th>Input.full_text</th>\n",
       "      <th>Input.speaker</th>\n",
       "      <th>Input.reply_to</th>\n",
       "      <th>Input.speaker_intention</th>\n",
       "      <th>...</th>\n",
       "      <th>Answer.3rapport.yes_pc_agree</th>\n",
       "      <th>Answer.4shareinformation.yes_pc_agree</th>\n",
       "      <th>Answer.1gamemove.yes_label</th>\n",
       "      <th>Answer.2reasoning.yes_label</th>\n",
       "      <th>Answer.3a_apologies.yes_label</th>\n",
       "      <th>Answer.3a_compliment.yes_label</th>\n",
       "      <th>Answer.3a_personalthoughts.yes_label</th>\n",
       "      <th>Answer.3a_reassurance.yes_label</th>\n",
       "      <th>Answer.3rapport.yes_label</th>\n",
       "      <th>Answer.4shareinformation.yes_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>301KG0KX9CLR06T6MC6UVPAHBC92HU</td>\n",
       "      <td>22056</td>\n",
       "      <td>Game7-turkey-austria</td>\n",
       "      <td>Train</td>\n",
       "      <td>Game7-turkey-austria-9</td>\n",
       "      <td>197</td>\n",
       "      <td>Im moving my fleet to Alb not for Greece but f...</td>\n",
       "      <td>austria-Game7</td>\n",
       "      <td>Game7-turkey-austria-8</td>\n",
       "      <td>Truth</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>301KG0KX9CLR06T6MC6UVPAHBCAH2A</td>\n",
       "      <td>6906</td>\n",
       "      <td>Game11-austria-italy</td>\n",
       "      <td>Validation</td>\n",
       "      <td>Game11-austria-italy-5</td>\n",
       "      <td>45</td>\n",
       "      <td>And yes I would like peace on our front, I cou...</td>\n",
       "      <td>austria-Game11</td>\n",
       "      <td>Game11-austria-italy-4</td>\n",
       "      <td>Truth</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>301KG0KX9CLR06T6MC6UVPAHBCC2HX</td>\n",
       "      <td>3066</td>\n",
       "      <td>Game1-england-germany</td>\n",
       "      <td>Train</td>\n",
       "      <td>Game1-england-germany-271</td>\n",
       "      <td>1468</td>\n",
       "      <td>okay...well, as the person who has ever seen a...</td>\n",
       "      <td>germany-Game1</td>\n",
       "      <td>Game1-england-germany-270</td>\n",
       "      <td>Truth</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>301KG0KX9CLR06T6MC6UVPAHBCCH2C</td>\n",
       "      <td>24093</td>\n",
       "      <td>Game9-italy-germany</td>\n",
       "      <td>Train</td>\n",
       "      <td>Game9-italy-germany-70</td>\n",
       "      <td>1460</td>\n",
       "      <td>I think the best thing we can do to keep the a...</td>\n",
       "      <td>germany-Game9</td>\n",
       "      <td>Game9-italy-germany-69</td>\n",
       "      <td>Truth</td>\n",
       "      <td>...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>301KG0KX9CLR06T6MC6UVPAHBCD2HY</td>\n",
       "      <td>1591</td>\n",
       "      <td>Game1-england-italy</td>\n",
       "      <td>Train</td>\n",
       "      <td>Game1-england-italy-273</td>\n",
       "      <td>1809</td>\n",
       "      <td>We'll see if I can keep it friendly.</td>\n",
       "      <td>england-Game1</td>\n",
       "      <td>Game1-england-italy-272</td>\n",
       "      <td>Truth</td>\n",
       "      <td>...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            HITId  Input.sentence_id         Input.convo_id  \\\n",
       "0  301KG0KX9CLR06T6MC6UVPAHBC92HU              22056   Game7-turkey-austria   \n",
       "1  301KG0KX9CLR06T6MC6UVPAHBCAH2A               6906   Game11-austria-italy   \n",
       "2  301KG0KX9CLR06T6MC6UVPAHBCC2HX               3066  Game1-england-germany   \n",
       "3  301KG0KX9CLR06T6MC6UVPAHBCCH2C              24093    Game9-italy-germany   \n",
       "4  301KG0KX9CLR06T6MC6UVPAHBCD2HY               1591    Game1-england-italy   \n",
       "\n",
       "  Input.train_test_val               Input.msg_id  Input.timestamp  \\\n",
       "0                Train     Game7-turkey-austria-9              197   \n",
       "1           Validation     Game11-austria-italy-5               45   \n",
       "2                Train  Game1-england-germany-271             1468   \n",
       "3                Train     Game9-italy-germany-70             1460   \n",
       "4                Train    Game1-england-italy-273             1809   \n",
       "\n",
       "                                     Input.full_text   Input.speaker  \\\n",
       "0  Im moving my fleet to Alb not for Greece but f...   austria-Game7   \n",
       "1  And yes I would like peace on our front, I cou...  austria-Game11   \n",
       "2  okay...well, as the person who has ever seen a...   germany-Game1   \n",
       "3  I think the best thing we can do to keep the a...   germany-Game9   \n",
       "4               We'll see if I can keep it friendly.   england-Game1   \n",
       "\n",
       "              Input.reply_to Input.speaker_intention  ...  \\\n",
       "0     Game7-turkey-austria-8                   Truth  ...   \n",
       "1     Game11-austria-italy-4                   Truth  ...   \n",
       "2  Game1-england-germany-270                   Truth  ...   \n",
       "3     Game9-italy-germany-69                   Truth  ...   \n",
       "4    Game1-england-italy-272                   Truth  ...   \n",
       "\n",
       "  Answer.3rapport.yes_pc_agree Answer.4shareinformation.yes_pc_agree  \\\n",
       "0                         1.00                              1.000000   \n",
       "1                         1.00                              1.000000   \n",
       "2                         1.00                              0.666667   \n",
       "3                         0.75                              0.750000   \n",
       "4                         0.75                              0.750000   \n",
       "\n",
       "   Answer.1gamemove.yes_label  Answer.2reasoning.yes_label  \\\n",
       "0                         1.0                          1.0   \n",
       "1                         1.0                          1.0   \n",
       "2                         1.0                          1.0   \n",
       "3                         1.0                          1.0   \n",
       "4                         1.0                          1.0   \n",
       "\n",
       "   Answer.3a_apologies.yes_label  Answer.3a_compliment.yes_label  \\\n",
       "0                            1.0                             1.0   \n",
       "1                            1.0                             1.0   \n",
       "2                            1.0                             1.0   \n",
       "3                            1.0                             1.0   \n",
       "4                            1.0                             1.0   \n",
       "\n",
       "   Answer.3a_personalthoughts.yes_label  Answer.3a_reassurance.yes_label  \\\n",
       "0                                   1.0                              1.0   \n",
       "1                                   1.0                              1.0   \n",
       "2                                   1.0                              1.0   \n",
       "3                                   1.0                              1.0   \n",
       "4                                   NaN                              NaN   \n",
       "\n",
       "  Answer.3rapport.yes_label  Answer.4shareinformation.yes_label  \n",
       "0                       1.0                                 1.0  \n",
       "1                       1.0                                 1.0  \n",
       "2                       1.0                                 1.0  \n",
       "3                       1.0                                 1.0  \n",
       "4                       1.0                                 1.0  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 718 rows with NaN\n",
      "(2636,)\n",
      "(2636, 1)\n",
      "(659,)\n",
      "(659, 1)\n"
     ]
    }
   ],
   "source": [
    "full_df_length = full_df.shape[0]\n",
    "full_df = full_df.dropna() # dataset contains NaN values, dropping NaNs here\n",
    "\n",
    "X = full_df['Input.full_text']\n",
    "\n",
    "print(\"Dropped {} rows with NaN\".format(full_df_length - X.shape[0]))\n",
    "\n",
    "# full_df[\"Input.deception_quadrant\"] = full_df[\"Input.deception_quadrant\"].apply(lambda x : 1 if x == \"Straightforward\" else 0)\n",
    "y = full_df['Answer.4shareinformation.yes_label']\n",
    "\n",
    "le = LabelEncoder() # this can convert our categories into labels, make sure you don't have NaNs or Nulls in your data first\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "# we reshape \n",
    "y = y.reshape(-1,1) # the -1 allows it to have whatever number went in there\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 1000\n",
    "max_len = 150\n",
    "\n",
    "tok = Tokenizer(num_words=max_words, oov_token=True)\n",
    "tok.fit_on_texts(X_train)\n",
    "\n",
    "sequences = tok.texts_to_sequences(X_train)\n",
    "X_train = sequence.pad_sequences(sequences,maxlen=max_len)\n",
    "# X_train = sequence.pad_sequences(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          [(None, 150)]             0         \n",
      "_________________________________________________________________\n",
      "embedding_7 (Embedding)      (None, 150, 200)          200000    \n",
      "_________________________________________________________________\n",
      "LSTM_01 (LSTM)               (None, 64)                67840     \n",
      "_________________________________________________________________\n",
      "Dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "Dense_01 (Dense)             (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "Dense_02 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 284,481\n",
      "Trainable params: 284,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Inp = Input(name='inputs',shape=[max_len])\n",
    "x = Embedding(max_words,200,input_length=max_len)(Inp)\n",
    "x = LSTM(64,name='LSTM_01')(x)\n",
    "x = Dropout(0.5,name='Dropout')(x)\n",
    "x = Dense(128,activation='relu',name='Dense_01')(x)\n",
    "x = Dense(64,activation='relu',name='Dense_02')(x)\n",
    "# x = Dropout(0.5,name='Dropout')(x)\n",
    "out = Dense(1,activation='sigmoid', name='output')(x)\n",
    "\n",
    "model = Model(inputs=Inp,outputs=out)\n",
    "\n",
    "model.compile(loss='binary_crossentropy',optimizer=RMSprop(),metrics=['acc',f1_m,precision_m, recall_m])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.4762 - acc: 0.8368 - f1_m: 0.9073 - precision_m: 0.8628 - recall_m: 0.9695 - val_loss: 0.4413 - val_acc: 0.8466 - val_f1_m: 0.9063 - val_precision_m: 0.8297 - val_recall_m: 1.0000\n",
      "Epoch 2/15\n",
      "17/17 [==============================] - 0s 22ms/step - loss: 0.4108 - acc: 0.8596 - f1_m: 0.9257 - precision_m: 0.8624 - recall_m: 1.0000 - val_loss: 0.4728 - val_acc: 0.8466 - val_f1_m: 0.9063 - val_precision_m: 0.8297 - val_recall_m: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f13f44c95f8>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss',min_delta=0.00001)\n",
    "\n",
    "model.fit(X_train,y_train,\n",
    "          batch_size=128,\n",
    "          epochs=15,\n",
    "          validation_split=0.2,\n",
    "          callbacks=[early_stop])\n",
    "\n",
    "# model.fit(X_train,y_train,\n",
    "#           batch_size=128,\n",
    "#           epochs=30,\n",
    "#           validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 3ms/step - loss: 0.4415 - acc: 0.8407 - f1_m: 0.9113 - precision_m: 0.8387 - recall_m: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4414748251438141,\n",
       " 0.8406676650047302,\n",
       " 0.9113032221794128,\n",
       " 0.8386591076850891,\n",
       " 1.0]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sequences_LSTM = tok.texts_to_sequences(X_test)\n",
    "X_test_LSTM = sequence.pad_sequences(test_sequences_LSTM,maxlen=max_len)\n",
    "model.evaluate(X_test_LSTM,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"CNN_with_embeddings\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 150, 100)          100000    \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 141, 128)          128128    \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 70, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 8960)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 8960)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                286752    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 514,913\n",
      "Trainable params: 514,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_CNN = Sequential(name=\"CNN_with_embeddings\")\n",
    "model_CNN.add(Embedding(max_words, 100, input_length=max_len))\n",
    "model_CNN.add(Conv1D(filters=128, kernel_size=10, activation='relu'))\n",
    "model_CNN.add(MaxPooling1D(pool_size=2))\n",
    "model_CNN.add(Flatten())\n",
    "model_CNN.add(Dropout(0.5))\n",
    "model_CNN.add(Dense(32, activation='relu'))\n",
    "model_CNN.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_CNN.compile(loss='binary_crossentropy', \n",
    "              optimizer= 'adam',\n",
    "              metrics=['acc',f1_m,precision_m, recall_m])\n",
    "\n",
    "model_CNN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.4492 - acc: 0.8529 - f1_m: 0.9193 - precision_m: 0.8547 - recall_m: 0.9951 - val_loss: 0.4787 - val_acc: 0.8220 - val_f1_m: 0.9011 - val_precision_m: 0.8203 - val_recall_m: 1.0000\n",
      "Epoch 2/15\n",
      "17/17 [==============================] - 0s 15ms/step - loss: 0.4086 - acc: 0.8567 - f1_m: 0.9208 - precision_m: 0.8539 - recall_m: 1.0000 - val_loss: 0.4712 - val_acc: 0.8220 - val_f1_m: 0.9011 - val_precision_m: 0.8203 - val_recall_m: 1.0000\n",
      "Epoch 3/15\n",
      "17/17 [==============================] - 0s 15ms/step - loss: 0.3987 - acc: 0.8567 - f1_m: 0.9231 - precision_m: 0.8576 - recall_m: 1.0000 - val_loss: 0.4777 - val_acc: 0.8220 - val_f1_m: 0.9011 - val_precision_m: 0.8203 - val_recall_m: 1.0000\n",
      "Epoch 4/15\n",
      "17/17 [==============================] - 0s 15ms/step - loss: 0.3688 - acc: 0.8567 - f1_m: 0.9221 - precision_m: 0.8560 - recall_m: 1.0000 - val_loss: 0.4964 - val_acc: 0.8220 - val_f1_m: 0.9011 - val_precision_m: 0.8203 - val_recall_m: 1.0000\n",
      "Epoch 5/15\n",
      "17/17 [==============================] - 0s 14ms/step - loss: 0.3116 - acc: 0.8567 - f1_m: 0.9231 - precision_m: 0.8581 - recall_m: 1.0000 - val_loss: 0.6332 - val_acc: 0.8220 - val_f1_m: 0.9011 - val_precision_m: 0.8203 - val_recall_m: 1.0000\n",
      "Epoch 6/15\n",
      "17/17 [==============================] - 0s 14ms/step - loss: 0.2477 - acc: 0.8567 - f1_m: 0.9231 - precision_m: 0.8576 - recall_m: 1.0000 - val_loss: 0.6357 - val_acc: 0.8220 - val_f1_m: 0.9011 - val_precision_m: 0.8203 - val_recall_m: 1.0000\n",
      "Epoch 7/15\n",
      "17/17 [==============================] - 0s 15ms/step - loss: 0.1978 - acc: 0.8937 - f1_m: 0.9412 - precision_m: 0.8914 - recall_m: 0.9973 - val_loss: 0.7732 - val_acc: 0.8125 - val_f1_m: 0.8890 - val_precision_m: 0.8198 - val_recall_m: 0.9715\n",
      "Epoch 8/15\n",
      "17/17 [==============================] - 0s 15ms/step - loss: 0.1641 - acc: 0.9231 - f1_m: 0.9559 - precision_m: 0.9172 - recall_m: 0.9990 - val_loss: 0.8710 - val_acc: 0.7822 - val_f1_m: 0.8733 - val_precision_m: 0.8166 - val_recall_m: 0.9397\n",
      "Epoch 9/15\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.1444 - acc: 0.9497 - f1_m: 0.9714 - precision_m: 0.9476 - recall_m: 0.9968 - val_loss: 0.9758 - val_acc: 0.7860 - val_f1_m: 0.8750 - val_precision_m: 0.8180 - val_recall_m: 0.9412\n",
      "Epoch 10/15\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.1292 - acc: 0.9535 - f1_m: 0.9737 - precision_m: 0.9516 - recall_m: 0.9973 - val_loss: 1.1186 - val_acc: 0.7841 - val_f1_m: 0.8738 - val_precision_m: 0.8189 - val_recall_m: 0.9376\n",
      "Epoch 11/15\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.1163 - acc: 0.9701 - f1_m: 0.9831 - precision_m: 0.9699 - recall_m: 0.9968 - val_loss: 1.1819 - val_acc: 0.7727 - val_f1_m: 0.8678 - val_precision_m: 0.8170 - val_recall_m: 0.9259\n",
      "Epoch 12/15\n",
      "17/17 [==============================] - 0s 14ms/step - loss: 0.1106 - acc: 0.9815 - f1_m: 0.9894 - precision_m: 0.9807 - recall_m: 0.9984 - val_loss: 1.2494 - val_acc: 0.7803 - val_f1_m: 0.8716 - val_precision_m: 0.8192 - val_recall_m: 0.9318\n",
      "Epoch 13/15\n",
      "17/17 [==============================] - 0s 14ms/step - loss: 0.1042 - acc: 0.9858 - f1_m: 0.9919 - precision_m: 0.9861 - recall_m: 0.9979 - val_loss: 1.2818 - val_acc: 0.7860 - val_f1_m: 0.8742 - val_precision_m: 0.8226 - val_recall_m: 0.9337\n",
      "Epoch 14/15\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.1007 - acc: 0.9872 - f1_m: 0.9924 - precision_m: 0.9865 - recall_m: 0.9984 - val_loss: 1.3518 - val_acc: 0.7822 - val_f1_m: 0.8724 - val_precision_m: 0.8208 - val_recall_m: 0.9318\n",
      "Epoch 15/15\n",
      "17/17 [==============================] - 0s 14ms/step - loss: 0.0974 - acc: 0.9929 - f1_m: 0.9960 - precision_m: 0.9936 - recall_m: 0.9984 - val_loss: 1.3544 - val_acc: 0.7727 - val_f1_m: 0.8667 - val_precision_m: 0.8227 - val_recall_m: 0.9166\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa15c15ac88>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss',min_delta=0.000001)\n",
    "\n",
    "# model_CNN.fit(X_train,y_train,\n",
    "#           batch_size=256,\n",
    "#           epochs=15,\n",
    "#           validation_split=0.2,\n",
    "#           callbacks=[early_stop])\n",
    "\n",
    "model_CNN.fit(X_train,y_train,\n",
    "          batch_size=128,\n",
    "          epochs=15,\n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 3ms/step - loss: 1.1617 - acc: 0.8209 - f1_m: 0.8996 - precision_m: 0.8715 - recall_m: 0.9336\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.1617460250854492,\n",
       " 0.8209407925605774,\n",
       " 0.8995769023895264,\n",
       " 0.8714513182640076,\n",
       " 0.9335665106773376]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sequences_CNN = tok.texts_to_sequences(X_test)\n",
    "X_test_CNN = sequence.pad_sequences(test_sequences_CNN,maxlen=max_len)\n",
    "\n",
    "model_CNN.evaluate(X_test_CNN,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
