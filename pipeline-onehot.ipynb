{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import LSTM, Input, InputLayer, Dropout, Dense, Flatten, Embedding, Add, Concatenate\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import torch\n",
    "from sklearn.metrics import precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Good data\n",
    "# df = pd.read_csv('./data/kokil dec 6 reprepare/affcon_final_with_linguistics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Messy data\n",
    "# df = pd.read_csv('./data/affcon_final_politeness_strategies_merge.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data with Throughput & WorkTime\n",
    "df = pd.read_csv('./data/kokil dec 6 reprepare/conf_pc_worker_sem.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input.sentence_id</th>\n",
       "      <th>HITId</th>\n",
       "      <th>Input.convo_id</th>\n",
       "      <th>Input.train_test_val</th>\n",
       "      <th>Input.msg_id</th>\n",
       "      <th>Input.timestamp</th>\n",
       "      <th>Input.full_text</th>\n",
       "      <th>Input.speaker</th>\n",
       "      <th>Input.reply_to</th>\n",
       "      <th>Input.speaker_intention</th>\n",
       "      <th>...</th>\n",
       "      <th>prt</th>\n",
       "      <th>punct</th>\n",
       "      <th>purpcl</th>\n",
       "      <th>quantmod</th>\n",
       "      <th>rcmod</th>\n",
       "      <th>rel</th>\n",
       "      <th>root</th>\n",
       "      <th>tmod</th>\n",
       "      <th>xcomp</th>\n",
       "      <th>xsubj</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11</td>\n",
       "      <td>3MG8450X2OASXZ0WO9O5AH70GU3UPA</td>\n",
       "      <td>Game1-italy-germany</td>\n",
       "      <td>Train</td>\n",
       "      <td>Game1-italy-germany-3</td>\n",
       "      <td>87</td>\n",
       "      <td>It seems like there are a lot of ways that cou...</td>\n",
       "      <td>germany-Game1</td>\n",
       "      <td>Game1-italy-germany-2</td>\n",
       "      <td>Truth</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>12</td>\n",
       "      <td>38G0E1M85M552JXSALX4G9WI2I6UVX</td>\n",
       "      <td>Game1-italy-germany</td>\n",
       "      <td>Train</td>\n",
       "      <td>Game1-italy-germany-7</td>\n",
       "      <td>117</td>\n",
       "      <td>Sorry Italy I've been away doing, um, German t...</td>\n",
       "      <td>germany-Game1</td>\n",
       "      <td>Game1-italy-germany-6</td>\n",
       "      <td>Truth</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>14</td>\n",
       "      <td>3HYV4299H0WQ2B4TCS7PKDQ75WHE81</td>\n",
       "      <td>Game1-italy-germany</td>\n",
       "      <td>Train</td>\n",
       "      <td>Game1-italy-germany-8</td>\n",
       "      <td>119</td>\n",
       "      <td>I don't think I'm ready to go for that idea, h...</td>\n",
       "      <td>germany-Game1</td>\n",
       "      <td>Game1-italy-germany-7</td>\n",
       "      <td>Truth</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>15</td>\n",
       "      <td>3XU9MCX6VOC4P079IHIO9TCNYLGR2P</td>\n",
       "      <td>Game1-italy-germany</td>\n",
       "      <td>Train</td>\n",
       "      <td>Game1-italy-germany-9</td>\n",
       "      <td>121</td>\n",
       "      <td>I am pretty conflicted about whether to guess ...</td>\n",
       "      <td>italy-Game1</td>\n",
       "      <td>Game1-italy-germany-8</td>\n",
       "      <td>Truth</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>16</td>\n",
       "      <td>3FVBZG9CLJEK4WQS7P2GC1H2EEQH0Q</td>\n",
       "      <td>Game1-italy-germany</td>\n",
       "      <td>Train</td>\n",
       "      <td>Game1-italy-germany-9</td>\n",
       "      <td>121</td>\n",
       "      <td>I am going to take it literally and say  even ...</td>\n",
       "      <td>italy-Game1</td>\n",
       "      <td>Game1-italy-germany-8</td>\n",
       "      <td>Truth</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 862 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Input.sentence_id                           HITId       Input.convo_id  \\\n",
       "5                 11  3MG8450X2OASXZ0WO9O5AH70GU3UPA  Game1-italy-germany   \n",
       "6                 12  38G0E1M85M552JXSALX4G9WI2I6UVX  Game1-italy-germany   \n",
       "7                 14  3HYV4299H0WQ2B4TCS7PKDQ75WHE81  Game1-italy-germany   \n",
       "8                 15  3XU9MCX6VOC4P079IHIO9TCNYLGR2P  Game1-italy-germany   \n",
       "9                 16  3FVBZG9CLJEK4WQS7P2GC1H2EEQH0Q  Game1-italy-germany   \n",
       "\n",
       "  Input.train_test_val           Input.msg_id  Input.timestamp  \\\n",
       "5                Train  Game1-italy-germany-3               87   \n",
       "6                Train  Game1-italy-germany-7              117   \n",
       "7                Train  Game1-italy-germany-8              119   \n",
       "8                Train  Game1-italy-germany-9              121   \n",
       "9                Train  Game1-italy-germany-9              121   \n",
       "\n",
       "                                     Input.full_text  Input.speaker  \\\n",
       "5  It seems like there are a lot of ways that cou...  germany-Game1   \n",
       "6  Sorry Italy I've been away doing, um, German t...  germany-Game1   \n",
       "7  I don't think I'm ready to go for that idea, h...  germany-Game1   \n",
       "8  I am pretty conflicted about whether to guess ...    italy-Game1   \n",
       "9  I am going to take it literally and say  even ...    italy-Game1   \n",
       "\n",
       "          Input.reply_to Input.speaker_intention  ...  prt punct  purpcl  \\\n",
       "5  Game1-italy-germany-2                   Truth  ...  0.0   0.0     0.0   \n",
       "6  Game1-italy-germany-6                   Truth  ...  0.0   0.0     0.0   \n",
       "7  Game1-italy-germany-7                   Truth  ...  0.0   0.0     0.0   \n",
       "8  Game1-italy-germany-8                   Truth  ...  0.0   0.0     0.0   \n",
       "9  Game1-italy-germany-8                   Truth  ...  0.0   0.0     0.0   \n",
       "\n",
       "   quantmod  rcmod  rel  root  tmod xcomp  xsubj  \n",
       "5       0.0    1.0  0.0   1.0   0.0   0.0    0.0  \n",
       "6       0.0    0.0  0.0   1.0   0.0   0.0    0.0  \n",
       "7       0.0    0.0  0.0   1.0   0.0   1.0    0.0  \n",
       "8       0.0    0.0  0.0   1.0   0.0   0.0    0.0  \n",
       "9       0.0    0.0  0.0   1.0   0.0   2.0    1.0  \n",
       "\n",
       "[5 rows x 862 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot old throughput (x-axis) vs new throughput (y-axis)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEQCAYAAACgBo8fAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAAhUUlEQVR4nO3deXhU9fn+8ffDvgrKIghGEEG07KTsIruIVr61aNFWq6WgtlptxbpUBbHura0UlV9cWnHBfUGrIgoIlH2XTWVTNkX2NUCS5/dHpicxJmQCk5yZyf26rlzMM+eEuRmT25OTM58xd0dERBJfmbADiIhIbKjQRUSShApdRCRJqNBFRJKECl1EJEmo0EVEkkSohW5mz5rZVjNbFuX+l5rZCjNbbmYvFXc+EZFEYmFeh25m3YF9wDh3b1HIvk2BV4Fe7r7TzOq6+9aSyCkikghCPUJ392nAjtz3mVkTM/vQzBaY2XQzax7ZNBR43N13Rj5XZS4ikks8nkNPA25w9/bAcOCJyP3NgGZm9l8zm21m/UNLKCISh8qFHSA3M6sGdAFeM7P/3V0x8mc5oCnQA2gITDOzlu6+q4RjiojEpbgqdLJ/Ytjl7m3y2bYRmOPuR4B1ZvYF2QU/rwTziYjErbg65eLue8gu60sALFvryOa3yT46x8xqk30KZm0IMUVE4lLYly2OB2YBZ5rZRjMbAvwCGGJmS4DlwMDI7hOB7Wa2ApgC3OLu28PILSISj0K9bFFERGInrk65iIjIsQvtl6K1a9f2Ro0ahfXwIiIJacGCBdvcvU5+20Ir9EaNGjF//vywHl5EJCGZ2VcFbdMpFxGRJKFCFxFJEip0EZEkoUIXEUkSKnQRkSShQhcRSRIqdBGRJKFCFxEpIelHMrn6X3NZ8NXOYvn74235XBGRpPTq/A386fWlAJQtYzz9qx/H/DFU6CIixWj3wSO0vuejYP6/Nqfwj8Fti+WxVOgiIsVk7KdrePCDVcE87ZaepNSqUmyPp0IXEYmxrXvS6XD/J8F8TffTuX3AWcX+uCp0EZEYuve9FTwzY10wz/tzH+pUr3iUz4gdFbqISAys37afHn+dGsx/HnAWQ7ufXqIZVOgiIsfphvGLeHfJ5mBeOrIfJ1QqX+I5VOgiIsdo2abdXPjPGcH810taM6h9w9DyqNBFRIooK8sZ/NRs5q7bAcCJVcoz6/beVCpfNtRcKnQRkSKYuWYblz81J5ifvSqVXs1PDjFRjkIL3cwqAdOAipH9X3f3EXn2qQiMA9oD24Gfu/v6mKcVEQnJkcws+jz6KV9tPwBA83rV+c/vz6FsGQs5WY5ojtAPAb3cfZ+ZlQdmmNkH7j471z5DgJ3ufoaZDQYeAn5eDHlFRErch8u2cO0LC4P59Ws7k9ropBAT5a/QQnd3B/ZFxvKRD8+z20BgZOT268AYM7PI54qIJKSDhzNpe+9HpB/JAqB7szo8d/WPMYufo/LcojqHbmZlgQXAGcDj7j4nzy4NgA0A7p5hZruBWsC2GGYVESkxL835mjve+iyYJ97UnTPrVQ8xUeGiKnR3zwTamFlN4C0za+Huy4r6YGY2DBgGkJKSUtRPFxEpdrsOHKbNqEnBfEn7hjxySesQE0WvSFe5uPsuM5sC9AdyF/om4FRgo5mVA2qQ/cvRvJ+fBqQBpKam6nSMiMSVMZO/5K8ffRHM0//Uk1NPKr7FtGItmqtc6gBHImVeGehL9i89c5sA/AqYBQwCJuv8uYgkim92p9PpgZzFtH7Xswm3nNc8xETHJpoj9PrAc5Hz6GWAV939PTMbBcx39wnAM8DzZrYa2AEMLrbEIiIxNOKdZTw366tgXnBnH2pVK5nFtGItmqtclgI/WI3d3e/OdTsduCS20UREis+a7/bR+2+fBvPdF57Nr7s1DjHR8dMrRUWkVHF3fvviQj5Y9k1w37J7zqNaxcSvw8T/F4iIRGnpxl1cNOa/wfzY4DYMbNMgxESxpUIXkaSXleVc/ORMFm/YBUDd6hWZfmtPKpYLdzGtWFOhi0hSm/HlNn75TM5rIf999Y/pcWbdEBMVHxW6iCSlwxlZ9HhkCpt3pwPQskEN3v5d17haTCvWVOgiknTeW7qZ619aFMxv/rYL7VJODDFRyVChi0jSOHA4g5YjPyIzK/t1jX3OqstTV6bG7WJasaZCF5Gk8Pys9dz1zvJg/viP3TmjbnwvphVrKnQRSWg79x+m7b05i2ld1iGFBy5uGWKi8KjQRSRh/X3SFzz2yZfBPPO2XpxSs3KIicKlQheRhLN510G6PDg5mH/fuyl/7NssxETxQYUuIgnljrc+46U5Xwfzwrv6clLVCiEmih8qdBFJCKu37qXPo9OCedTAH3Fl50bhBYpDKnQRiWvuztBx8/l45VYAypYxlo7oR9UkWEwr1vSMiEjcWvj1Ti5+YmYwj7m8LRe2OiXERPFNhS4icSczyxn4+AyWbdoDQIOalZkyvAcVypUJOVl8U6GLSFyZ+vlWrvrXvGB+YUhHujWtHWKixKFCF5G4cCgjk24PTeG7vYcAaJtSkzeu7UKZJF5MK9ZU6CISuncWb+LGlxcH84Tru9KqYc3Q8iQqFbqIhGbfoQxajJgYzOe3qMcTv2hXahbTijUVuoiE4tkZ6xj13opgnnzzuZxep1qIiRKfCl1EStT2fYdo/5ePg/lXnU/jnoEtQkyUPAotdDM7FRgHnAw4kObuj+XZpwfwDrAucteb7j4qpklFJOE9MnEVj09ZE8yzb+9NvRqVQkyUXKI5Qs8Abnb3hWZWHVhgZpPcfUWe/aa7+4WxjygiiW7jzgN0e2hKMN/ctxk39G4aYqLkVGihu/sWYEvk9l4zWwk0APIWuojID9zy2hJeW7AxmBff3ZeaVbSYVnEo0jl0M2sEtAXm5LO5s5ktATYDw919ed4dzGwYMAwgJSWlyGFFJHF8/s1ezvtHzmJa9/+0JZd31Pd9cYq60M2sGvAGcJO778mzeSFwmrvvM7MBwNvAD36ecvc0IA0gNTXVjzW0iMQvd+dX/5rHtC++A6BS+TIsuqsflSuUDTlZ8ouq0M2sPNll/qK7v5l3e+6Cd/f3zewJM6vt7ttiF1VE4t389TsYNHZWMI/9ZTv6t6gfYqLSJZqrXAx4Bljp7o8WsE894Ft3dzPrAJQBtsc0qYjErcws54LR01n1zV4ATqtVhY//eC7ly2oxrZIUzRF6V+AK4DMzWxy57w4gBcDdxwKDgOvMLAM4CAx2d51SESkFJq/6ll//e34wvzS0I12aaDGtMERzlcsM4Kivw3X3McCYWIUSkfiXfiSTzg98ws4DRwDo0PgkXh7aSYtphUivFBWRIntjwUZufm1JML93QzdaNKgRYiIBFbqIFMGe9CO0GvlRMF/U+hRGX9Y2xESSmwpdRKLy1LS13Pf+ymCeOrwHjWpXDTGR5KVCF5Gj+m7vIX58X85iWkO6NeauC88OMZEURIUuIgV64IOV/L9P1wbz3Dt6U/cELaYVr1ToIvIDX28/QPdHchbTurV/c67r0STERBINFbqIfM8fXlnMW4s2BfOSEf2oUbl8iIkkWip0EQFgxeY9DBg9PZgf/lkrLv3xqSEmkqJSoYuUcu7O5U/NYdba7NU6qlcsx7w7+1CpvBbTSjQqdJFSbM7a7fw8bXYwp13Rnn4/qhdiIjkeKnSRUigjM4t+/5jG2u/2A9CkTlUm3tSdclpMK6Gp0EVKmYnLv+Ga5xcE8yvDOtHx9FohJpJYUaGLlBLpRzJpf+8k9h/OBKDrGbV4YUhHslfIlmSgQhcpBV6dt4E/vbE0mD+48RzOqn9CiImkOKjQRZLY7oNHaH1PzmJaP23bgL//vE14gaRYqdBFktSTU9fw0IergnnaLT1JqVUlxERS3FToIklm6550Otz/STBf0/10bh9wVoiJpKSo0EWSyKh3V/Dsf9cF87w/96FO9YohJpKSpEIXSQLrtu2n51+nBvOfB5zF0O6nhxdIQqFCF0lg7s4N4xfx3tItwX2fjexH9UpaTKs0UqGLJKhlm3Zz4T9nBPOjl7bm4nYNQ0wkYVOhiySYrCxncNps5q7fAcBJVSsw87ZeWkxLCi90MzsVGAecDDiQ5u6P5dnHgMeAAcAB4Cp3Xxj7uCKl28w127j8qTnB/OxVqfRqfnKIiSSeRHOEngHc7O4Lzaw6sMDMJrn7ilz7nA80jXx0BJ6M/CkiMXAkM4tef5vKhh0HAWherzr/+f05lC2jl+1LjkIL3d23AFsit/ea2UqgAZC70AcC49zdgdlmVtPM6kc+V0SOwwefbeG6F3N+4H3jus60P+2kEBNJvCrSOXQzawS0Bebk2dQA2JBr3hi573uFbmbDgGEAKSkpRYwqUrocPJxJ61EfcTgjC4AeZ9bhX1f9WItpSYGiLnQzqwa8Adzk7nuO5cHcPQ1IA0hNTfVj+TtESoOX5nzNHW99FswTb+rOmfWqh5hIEkFUhW5m5cku8xfd/c18dtkE5H7zwYaR+0SkCHYdOEybUZOC+dLUhjw8qHWIiSSRRHOViwHPACvd/dECdpsAXG9mL5P9y9DdOn8uUjT//ORL/jbpi2CecWtPGp6oxbQketEcoXcFrgA+M7PFkfvuAFIA3H0s8D7ZlyyuJvuyxatjnlQkSX2zO51OD+QspvW7nk245bzmISaSRBXNVS4zgKP+FiZydcvvYhVKpLS4+51ljJv1VTAvuLMPtappMS05NnqlqEgI1ny3j95/+zSYR/zkbK7u2jjERJIMVOgiJcjdufaFBUxc/m1w37J7zqNaRX0ryvHTV5FICVm6cRcXjflvMD82uA0D2zQIMZEkGxW6SDHLynIufnImizfsAqBu9YpMv7UnFctpMS2JLRW6SDGa/uV3XPHM3GB+7tcdOLdZnRATSTJToYsUg8MZWZz7yBS27E4HoGWDGrz9u65aTEuKlQpdJMbeXbKZG8YvCua3ftuFtiknhphISgsVukiM7D+UQcuRE8mKrFLU56yTeerK9lpMS0qMCl0kBp6ftZ673lkezB//sTtn1NViWlKyVOgix2HH/sO0uzdnMa3LO6Zw/09bhphISjMVusgxenTSF4z+5MtgnnlbL06pWTnERFLaqdBFimjTroN0fXByMN/Yuyl/6NssxEQi2VToIkVw+5tLGT835825Ft3VlxOrVggxkUgOFbpIFL78di99/z4tmO8d+COu6NwovEAi+VChixyFu/Ob5+bzyaqtAJQrYywd2Y8qFfStI/FHX5UiBVj49U4ufmJmMD9+eTsuaFU/xEQiR6dCF8kjM8u5aMwMlm/Ofi/0BjUrM2V4DyqUKxNyMpGjU6GL5DLl861c/a95wfzCkI50a1o7xEQi0VOhiwCHMjLp+uAUtu07BEC7lJq8fm0XymgxLUkgKnQp9d5etImbXlkczBOu70qrhjVDyyNyrFToUmrtO5RBixETg3lAy3o8fnk7LaYlCUuFLqXSMzPWce97K4J58s3ncnqdaiEmEjl+hRa6mT0LXAhsdfcW+WzvAbwDrIvc9aa7j4phRpGY2bbvEKl/+TiYf9X5NO4Z+IMva5GEFM0R+r+BMcC4o+wz3d0vjEkikWLy8IereGLqmmCefXtv6tWoFGIikdgqtNDdfZqZNSqBLCLFYsOOA5zz8JRgHt6vGdf3ahpiIpHiEatz6J3NbAmwGRju7svz28nMhgHDAFJSUmL00CIFu+W1Jby2YGMwL7m7HzWqlA8xkUjxiUWhLwROc/d9ZjYAeBvI9/DH3dOANIDU1FSPwWOL5GvVN3vo/4/pwfzAxS25rIMOIiS5HXehu/ueXLffN7MnzKy2u2873r9bpKjcnSufncv0L7O//CqXL8vCu/pSuULZkJOJFL/jLnQzqwd86+5uZh2AMsD2404mUkTz1+9g0NhZwTz2l+3o30KLaUnpEc1li+OBHkBtM9sIjADKA7j7WGAQcJ2ZZQAHgcHurtMpUmIyMrMYMHo6X3y7D4BGtaow6Y/nUr6sFtOS0iWaq1wuK2T7GLIvaxQpcZ+s/JYhz80P5vFDO9G5Sa0QE4mER68UlYSUfiSTjvd/wu6DRwDo2Pgkxg/tpMW0pFRToUvCeX3BRoa/tiSY37uhGy0a1AgxkUh8UKFLwtiTfoRWIz8K5otan8Loy9qGmEgkvqjQJSGkTVvD/e+vCuapw3vQqHbVEBOJxB8VusS1rXvT6XDfJ8E8pFtj7rrw7BATicQvFbrErfvfX0natLXBPPeO3tQ9QYtpiRREhS5x5+vtB+j+SM5iWred35xrz20SYiKRxKBCl7hy08uLeHvx5mBeMqIfNSprMS2RaKjQJS4s37ybC0bPCOaHB7Xi0tRTQ0wkknhU6BIqd+eyp2Yze+0OAKpXLMe8O/tQqbwW0xIpKhW6hGb22u0MTpsdzE9dmUrfs08OMZFIYlOhS4k7nJFFszs/COYz6lbjwxvPoZwW0xI5Lip0KVFPTl3DQx/mvEDo1Ws606HxSSEmEkkeKnQpEXvTj9Ay18v2AdbeP0CLaYnEkApdit3d7yxj3Kyvgvn5IR04p2mdEBOJJCcVuhSbvC/br1axHMvuOS/ERCLJTYUuxeLX/57H5FVbg1lL3IoUPxW6xNTa7/bR62+fBnPLBjV494ZuISYSKT1U6BIzfR79lNVb9wXztFt6klKrSoiJREoXFboct0Vf7+SnT8wM5gta1ufxX7QLMZFI6aRCl2Pm7px+x/u459y34M4+1KpWMbxQIqVYoS/NM7NnzWyrmS0rYLuZ2WgzW21mS81Mh2alwORV39L49pwyH3pOY9Y/eIHKXCRE0Ryh/xsYA4wrYPv5QNPIR0fgycifkoSysrKPynNbMeo8qlTQD3siYSv0CN3dpwE7jrLLQGCcZ5sN1DSz+rEKKPHj1Xkbvlfmd194NusfvEBlLhInYvGd2ADYkGveGLlvSwz+bokDhzIyOfPOD7933+r7ztdiWiJxpkQPrcxsGDAMICUlpSQfWo7RPz/5kr9N+iJnvqwtP2l9SoiJRKQgsSj0TUDut5ZpGLnvB9w9DUgDSE1N9fz2kfiw++ARWt/z/cW01j0wADMtpiUSr2JR6BOA683sZbJ/Gbrb3XW6JYHd9sZSXp6XcxbtpaEd6dKkdoiJRCQahRa6mY0HegC1zWwjMAIoD+DuY4H3gQHAauAAcHVxhZXi9c3udDo9kLOY1klVK7Dwrr4hJhKRoii00N39skK2O/C7mCWSUPzy6TnMWL0tmD+48RzOqn9CiIlEpKh0vVkpt3rrXvo8Oi2Y2592Im9c1yXERCJyrFTopVi3hyazcefBYJ5xa08anqjFtEQSlQq9FJq/fgeDxs4K5v9rcwr/GNw2xEQiEgsq9FLE3Wl8+/dftr/orr6cWLVCSIlEJJZU6KXExOXfcM3zC4L5tz2a8Kf+zUNMJCKxpkJPcplZTpM8i2mtHNWfyhXKhpRIRIqLCj2JTf/yO654Zm4w3zvwR1zRuVF4gUSkWKnQk9DhjCy6PzyFb/akB/dpMS2R5KdCTzLvLtnMDeMXBfNbv+1C25QTQ0wkIiVFhZ4k9h/KoMXIicE7CPU562SeurK9FtMSKUVU6EnguZnrGTFheTB//MfunFG3eoiJRCQMKvQEtmP/YdrdOymYf9Exhft+2jLERCISJhV6gnr0o88ZPXl1MM+8rRen1KwcYiIRCZsKPcFs2nWQrg9ODuab+jTlpj7NQkwkIvFChZ5Abn9zKePn5rzxhF62LyK5qdATwJff7qXv33OWuNULhEQkPyr0OObuDHluPpNXbQWgXBlj6ch+VKmg/2wi8kNqhji14Kud/OzJmcH8+OXtuKBV/RATiUi8U6HHmcws56IxM1i+eQ8ADWpWZsrwHlQop5fti8jRqdDjyJTPt3L1v+YF84u/6UjXM2qHmEhEEokKPQ4cysikywOT2b7/MADtUmry+rVdKFNGL9sXkeip0EP29qJN3PTK4mCecH1XWjWsGVoeEUlcURW6mfUHHgPKAk+7+4N5tl8FPAJsitw1xt2fjmHOpLM3/QgtR34UzOe3qMcTv2inxbRE5JgVWuhmVhZ4HOgLbATmmdkEd1+RZ9dX3P36YsiYdJ6ZsY5738t5+ibffC6n16kWYiIRSQbRHKF3AFa7+1oAM3sZGAjkLXQpxLZ9h0j9y8fBfFWXRoy86EchJhKRZBJNoTcANuSaNwId89nvZ2bWHfgC+IO7b8i7g5kNA4YBpKSkFD1tAnvow1U8OXVNMM++vTf1alQKMZGIJJtY/VL0XWC8ux8ys2uA54BeeXdy9zQgDSA1NdVj9NhxbcOOA5zz8JRgHt6vGdf3ahpiIhFJVtEU+ibg1FxzQ3J++QmAu2/PNT4NPHz80RLfza8u4Y2FG4N5yd39qFGlfIiJRCSZRVPo84CmZtaY7CIfDFyeewczq+/uWyLjRcDKmKZMMKu+2UP/f0wP5gcubsllHUrXKSYRKXmFFrq7Z5jZ9cBEsi9bfNbdl5vZKGC+u08Afm9mFwEZwA7gqmLMHLfcnSufncv0L7cBULl8WRbe1ZfKFcqGnExESgNzD+dUdmpqqs+fPz+Uxy4O89fvYNDYWcE89pft6N9Ci2mJSGyZ2QJ3T81vm14pepwyMrMYMHo6X3y7D4DGtavy0R+6U76sFtMSkZKlQj8OH6/4lt+My/kpY/zQTnRuUivERCJSmqnQj0H6kUw63Pcxe9IzAOjY+CTGD+2kxbREJFQq9CJ6fcFGhr+2JJjfu6EbLRrUCDGRiEg2FXqU9qQfoVWuxbQuan0Koy9rG2IiEZHvU6FHIW3aGu5/f1UwTx3eg0a1q4aYSETkh1ToR7F1bzod7vskmId0a8xdF54dYiIRkYKp0Atw339W8NT0dcE8947e1D1Bi2mJSPxSoefx1fb9nPvI1GC+tX9zruvRJLxAIiJRUqHncuPLi3hn8eZgXjKiHzUqazEtEUkMKnRg+ebdXDB6RjA/PKgVl6aeepTPEBGJP6W60N2dwWmzmbNuBwDVK5Vj3p/7UKm8FtMSkcRTagt99trtDE6bHcxPXZlK37NPDjGRiMjxKXWFnpGZRd+/T2Pdtv0AnFG3Gh/eeA7ltJiWiCS4UlXoHy77hmtfWBDMr17TmQ6NTwoxkYhI7JSKQk8/kkm7eydx4HAmAF3PqMULQzpipsW0RCR5JH2hvzLva25947Ng/uDGczir/gkhJhIRKR5JW+i7Dxyh9aicxbQubteARy9tE14gEZFilpSF/viU1Twy8fNgnv6nnpx6UpUQE4mIFL+kKvRv96TT8f6cxbSuPbcJt53fPMREIiIlJ2kKfeSE5fx75vpgnvfnPtSpXjG8QCIiJSzhC33dtv30/OvUYL7zgrP4zTmnhxdIRCQkURW6mfUHHgPKAk+7+4N5tlcExgHtge3Az919fWyjfp+7c/1Li/jPZ1uC+z4b2Y/qlbSYloiUToUWupmVBR4H+gIbgXlmNsHdV+TabQiw093PMLPBwEPAz4sjMMBnG3fzkzE5i2k9emlrLm7XsLgeTkQkIURzhN4BWO3uawHM7GVgIJC70AcCIyO3XwfGmJm5u8cwKwAbdhwIyrxW1Qr897ZeWkxLRIToCr0BsCHXvBHoWNA+7p5hZruBWsC23DuZ2TBgGEBKSsoxBa5WsRxdz6jFkG6N6dVci2mJiPxPif5S1N3TgDSA1NTUYzp6P7FqBV78TaeY5hIRSQbRLDG4Ccj9bg8NI/flu4+ZlQNqkP3LURERKSHRFPo8oKmZNTazCsBgYEKefSYAv4rcHgRMLo7z5yIiUrBCT7lEzolfD0wk+7LFZ919uZmNAua7+wTgGeB5M1sN7CC79EVEpARFdQ7d3d8H3s9z3925bqcDl8Q2moiIFIXepkdEJEmo0EVEkoQKXUQkSajQRUSShIV1daGZfQd8dYyfXps8r0JNMImcX9nDk8j5lT12TnP3OvltCK3Qj4eZzXf31LBzHKtEzq/s4Unk/MpeMnTKRUQkSajQRUSSRKIWelrYAY5TIudX9vAkcn5lLwEJeQ5dRER+KFGP0EVEJA8VuohIkojrQjez/mb2uZmtNrPb8tle0cxeiWyfY2aNQoiZryiyX2Vm35nZ4sjHb8LImR8ze9bMtprZsgK2m5mNjvzblppZu5LOWJAosvcws925nve789svDGZ2qplNMbMVZrbczG7MZ594fu6jyR+Xz7+ZVTKzuWa2JJL9nnz2idu+Cbh7XH6QvVTvGuB0oAKwBDg7zz6/BcZGbg8GXgk7dxGyXwWMCTtrAfm7A+2AZQVsHwB8ABjQCZgTduYiZO8BvBd2zgKy1QfaRW5XB77I5+smnp/7aPLH5fMfeT6rRW6XB+YAnfLsE5d9k/sjno/QgzendvfDwP/enDq3gcBzkduvA73NzEowY0GiyR633H0a2evaF2QgMM6zzQZqmln9kkl3dFFkj1vuvsXdF0Zu7wVWkv1+vbnF83MfTf64FHk+90XG8pGPvFeMxGvfBOK50PN7c+q8Xxzfe3Nq4H9vTh22aLID/CzyY/PrZnZqPtvjVbT/vnjVOfKj9Qdm9qOww+Qn8uN8W7KPFHNLiOf+KPkhTp9/MytrZouBrcAkdy/wuY+zvgnEc6Enu3eBRu7eCphEzv/5pXgtJHstjNbAP4G3w43zQ2ZWDXgDuMnd94Sdp6gKyR+3z7+7Z7p7G7LfN7mDmbUIOVKRxXOhJ/KbUxea3d23u/uhyPg00L6EssVCNP9t4pK77/nfj9ae/U5c5c2sdsixAmZWnuwyfNHd38xnl7h+7gvLH+/PP4C77wKmAP3zbIrXvgnEc6En8ptTF5o9z3nPi8g+35goJgBXRq646ATsdvctYYeKhpnV+995TzPrQPb3QFx8U0ZyPQOsdPdHC9gtbp/7aPLH6/NvZnXMrGbkdmWgL7Aqz27x2jeBqN5TNAyewG9OHWX235vZRUAG2dmvCi1wHmY2nuyrEWqb2UZgBNm/JMLdx5L9/rIDgNXAAeDqcJL+UBTZBwHXmVkGcBAYHEfflF2BK4DPIudyAe4AUiD+n3uiyx+vz3994DkzK0v2/2Redff3EqFvctNL/0VEkkQ8n3IREZEiUKGLiCQJFbqISJJQoYuIJAkVuohICShs4bh89r8010JnL0X1ObrKRUSk+JlZd2Af2WvxHPVVqGbWFHgV6OXuO82srrtvLewxdIQuIlIC8ls4zsyamNmHZrbAzKabWfPIpqHA4+6+M/K5hZY5qNBFRMKUBtzg7u2B4cATkfubAc3M7L9mNtvM8i5DkK+4faWoiEgyiyxi1gV4LdcqvBUjf5YDmpL9queGwDQzaxlZZ6ZAKnQRkXCUAXZFVnjMayPZb15yBFhnZl+QXfDzCvsLRUSkhEWWFl5nZpdA8PaCrSOb3yb76JzIapTNgLWF/Z0qdBGREhBZOG4WcKaZbTSzIcAvgCFmtgRYTs47m00EtpvZCrKX8r3F3QtdlVKXLYqIJAkdoYuIJAkVuohIklChi4gkCRW6iEiSUKGLiCQJFbqISJJQoYuIJIn/D7vX/gyUr6GMAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # Throughput (weighted by variance)\n",
    "df_throughput = df[['Throughput.1', 'Throughput.2', 'Throughput.3', 'Throughput.4', 'Throughput.5']].copy()\n",
    "df_throughput['var_throughput'] = df_throughput.var(axis=1)\n",
    "print(\"Plot old throughput (x-axis) vs new throughput (y-axis)\")\n",
    "plt.plot(df_throughput['var_throughput'], df_throughput['var_throughput'])\n",
    "df_throughput['var_throughput'] = df_throughput['var_throughput'] / df_throughput['var_throughput'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Throughput (weighted by inverted V-shape variance)\n",
    "# df_throughput = df[['Throughput.1', 'Throughput.2', 'Throughput.3', 'Throughput.4', 'Throughput.5']].copy()\n",
    "# df_throughput['var_throughput'] = df_throughput.var(axis=1)\n",
    "# max_val = df_throughput['var_throughput'].max()\n",
    "# min_val = df_throughput['var_throughput'].min()\n",
    "# tp_mid = ((max_val - min_val) // 2) + min_val\n",
    "# tp_to_list = df_throughput['var_throughput'].tolist()\n",
    "\n",
    "# amount_of_curve = 3\n",
    "\n",
    "# u_shaped_variance = []\n",
    "# for each in tp_to_list:\n",
    "#     if each > tp_mid:\n",
    "#         u_shaped_variance.append((2*tp_mid - each)**(1/amount_of_curve))\n",
    "#     else:\n",
    "#         u_shaped_variance.append(each**(1/amount_of_curve))\n",
    "        \n",
    "# df_throughput['var_throughput_u_shaped'] = u_shaped_variance\n",
    "# print(\"Plot old throughput (x-axis) vs new throughput (y-axis)\")\n",
    "# df_throughput.plot(x='var_throughput', y='var_throughput_u_shaped', style='o')\n",
    "# df_throughput['var_throughput_u_shaped'] = df_throughput['var_throughput_u_shaped'] / df_throughput['var_throughput_u_shaped'].max()\n",
    "# df_throughput = df_throughput.assign(var_throughput=df_throughput['var_throughput_u_shaped'])\n",
    "\n",
    "# WorkTime (weighted by variance)\n",
    "df_worktime = df[['WorkTime.1', 'WorkTime.2', 'WorkTime.3', 'WorkTime.4', 'WorkTime.5']].copy()\n",
    "df_worktime['var_worktime'] = df_worktime.var(axis=1)\n",
    "df_worktime['var_worktime'] = df_worktime['var_worktime'] / df_worktime['var_worktime'].max()\n",
    "\n",
    "# Percentage Agreement\n",
    "df_agreement = df[['Answer.1gamemove.yes_pc_agree', 'Answer.2reasoning.yes_pc_agree', 'Answer.4shareinformation.yes_pc_agree', 'Answer.3rapport.yes_pc_agree']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Throughput.1</th>\n",
       "      <th>Throughput.2</th>\n",
       "      <th>Throughput.3</th>\n",
       "      <th>Throughput.4</th>\n",
       "      <th>Throughput.5</th>\n",
       "      <th>var_throughput</th>\n",
       "      <th>var_throughput_u_shaped</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>390</td>\n",
       "      <td>2331</td>\n",
       "      <td>193</td>\n",
       "      <td>2139</td>\n",
       "      <td>162.0</td>\n",
       "      <td>0.905919</td>\n",
       "      <td>0.905919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>234</td>\n",
       "      <td>2134</td>\n",
       "      <td>2331</td>\n",
       "      <td>1022</td>\n",
       "      <td>1411.0</td>\n",
       "      <td>0.767038</td>\n",
       "      <td>0.767038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>521</td>\n",
       "      <td>2139</td>\n",
       "      <td>2660</td>\n",
       "      <td>1411</td>\n",
       "      <td>892.0</td>\n",
       "      <td>0.782763</td>\n",
       "      <td>0.782763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2632</td>\n",
       "      <td>2415</td>\n",
       "      <td>1482</td>\n",
       "      <td>892</td>\n",
       "      <td>3747.0</td>\n",
       "      <td>0.909788</td>\n",
       "      <td>0.909788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2905</td>\n",
       "      <td>95</td>\n",
       "      <td>528</td>\n",
       "      <td>892</td>\n",
       "      <td>300.0</td>\n",
       "      <td>0.928787</td>\n",
       "      <td>0.928787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13189</th>\n",
       "      <td>1168</td>\n",
       "      <td>2632</td>\n",
       "      <td>2415</td>\n",
       "      <td>19</td>\n",
       "      <td>2139.0</td>\n",
       "      <td>0.899110</td>\n",
       "      <td>0.899110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13190</th>\n",
       "      <td>1252</td>\n",
       "      <td>501</td>\n",
       "      <td>13</td>\n",
       "      <td>390</td>\n",
       "      <td>408.0</td>\n",
       "      <td>0.503678</td>\n",
       "      <td>0.503678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13191</th>\n",
       "      <td>575</td>\n",
       "      <td>1252</td>\n",
       "      <td>2660</td>\n",
       "      <td>1601</td>\n",
       "      <td>1014.0</td>\n",
       "      <td>0.727428</td>\n",
       "      <td>0.727428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13192</th>\n",
       "      <td>251</td>\n",
       "      <td>390</td>\n",
       "      <td>331</td>\n",
       "      <td>528</td>\n",
       "      <td>297.0</td>\n",
       "      <td>0.192362</td>\n",
       "      <td>0.192362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13193</th>\n",
       "      <td>2905</td>\n",
       "      <td>2632</td>\n",
       "      <td>2415</td>\n",
       "      <td>2139</td>\n",
       "      <td>619.0</td>\n",
       "      <td>0.793553</td>\n",
       "      <td>0.793553</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11366 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Throughput.1  Throughput.2  Throughput.3  Throughput.4  Throughput.5  \\\n",
       "5               390          2331           193          2139         162.0   \n",
       "6               234          2134          2331          1022        1411.0   \n",
       "7               521          2139          2660          1411         892.0   \n",
       "8              2632          2415          1482           892        3747.0   \n",
       "9              2905            95           528           892         300.0   \n",
       "...             ...           ...           ...           ...           ...   \n",
       "13189          1168          2632          2415            19        2139.0   \n",
       "13190          1252           501            13           390         408.0   \n",
       "13191           575          1252          2660          1601        1014.0   \n",
       "13192           251           390           331           528         297.0   \n",
       "13193          2905          2632          2415          2139         619.0   \n",
       "\n",
       "       var_throughput  var_throughput_u_shaped  \n",
       "5            0.905919                 0.905919  \n",
       "6            0.767038                 0.767038  \n",
       "7            0.782763                 0.782763  \n",
       "8            0.909788                 0.909788  \n",
       "9            0.928787                 0.928787  \n",
       "...               ...                      ...  \n",
       "13189        0.899110                 0.899110  \n",
       "13190        0.503678                 0.503678  \n",
       "13191        0.727428                 0.727428  \n",
       "13192        0.192362                 0.192362  \n",
       "13193        0.793553                 0.793553  \n",
       "\n",
       "[11366 rows x 7 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_throughput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = range(df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Individual Classifiers are LSTMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test, indices_train, indices_test = train_test_split(df, indices, test_size=0.2)\n",
    "\n",
    "new_deception_train = train[\"Input.deception_quadrant\"].copy()\n",
    "new_deception_train['Input.deception_quadrant'] = train[\"Input.deception_quadrant\"].apply(lambda x : 1 if x == \"Straightforward\" else 0)\n",
    "y_train_deception = new_deception_train['Input.deception_quadrant'].tolist()\n",
    "y_train_rapport = train['Answer.3rapport.yes_label'].tolist()\n",
    "y_train_share_information = train['Answer.4shareinformation.yes_label'].tolist()\n",
    "y_train_reasoning = train['Answer.2reasoning.yes_label'].tolist()\n",
    "y_train_gamemove = train['Answer.1gamemove.yes_label'].tolist()\n",
    "\n",
    "X_train_col = train['Input.full_text']\n",
    "\n",
    "new_deception_test = test[\"Input.deception_quadrant\"].copy()\n",
    "new_deception_test['Input.deception_quadrant'] = test[\"Input.deception_quadrant\"].apply(lambda x : 1 if x == \"Straightforward\" else 0)\n",
    "y_test_deception = new_deception_test['Input.deception_quadrant'].tolist()\n",
    "y_test_rapport = test['Answer.3rapport.yes_label'].tolist()\n",
    "y_test_share_information = test['Answer.4shareinformation.yes_label'].tolist()\n",
    "y_test_reasoning = test['Answer.2reasoning.yes_label'].tolist()\n",
    "y_test_gamemove = test['Answer.1gamemove.yes_label'].tolist()\n",
    "\n",
    "X_test_col = test['Input.full_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', min_delta=0, patience=0, verbose=0, mode='auto',\n",
    "    baseline=None, restore_best_weights=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lynne\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "\n",
    "y_train_deception = le.fit_transform(y_train_deception)\n",
    "y_train_deception = y_train_deception.reshape(-1,1)\n",
    "\n",
    "y_train_rapport = le.fit_transform(y_train_rapport)\n",
    "y_train_rapport = y_train_rapport.reshape(-1,1)\n",
    "\n",
    "y_train_share_information = le.fit_transform(y_train_share_information)\n",
    "y_train_share_information = y_train_share_information.reshape(-1,1)\n",
    "\n",
    "y_train_reasoning = le.fit_transform(y_train_reasoning)\n",
    "y_train_reasoning = y_train_reasoning.reshape(-1,1)\n",
    "\n",
    "y_train_gamemove = le.fit_transform(y_train_gamemove)\n",
    "y_train_gamemove = y_train_gamemove.reshape(-1,1)\n",
    "\n",
    "y_train_deception = le.fit_transform(y_train_deception)\n",
    "y_train_deception = y_train_deception.reshape(-1,1)\n",
    "\n",
    "y_test_rapport = le.fit_transform(y_test_rapport)\n",
    "y_test_rapport = y_test_rapport.reshape(-1,1)\n",
    "\n",
    "y_test_share_information = le.fit_transform(y_test_share_information)\n",
    "y_test_share_information = y_test_share_information.reshape(-1,1)\n",
    "\n",
    "y_test_reasoning = le.fit_transform(y_test_reasoning)\n",
    "y_test_reasoning = y_test_reasoning.reshape(-1,1)\n",
    "\n",
    "y_test_gamemove = le.fit_transform(y_test_gamemove)\n",
    "y_test_gamemove = y_test_gamemove.reshape(-1,1)\n",
    "\n",
    "y_test_deception = le.fit_transform(y_test_deception)\n",
    "y_test_deception = y_test_deception.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 1000\n",
    "max_len = 220\n",
    "\n",
    "tok = Tokenizer(num_words=max_words)\n",
    "\n",
    "tok.fit_on_texts(X_train_col)\n",
    "X_train_sequences = tok.texts_to_sequences(X_train_col)\n",
    "X_train = pad_sequences(X_train_sequences, maxlen=max_len)\n",
    "\n",
    "# tok.fit_on_texts(X_test_col)\n",
    "X_test_sequences = tok.texts_to_sequences(X_test_col)\n",
    "X_test = pad_sequences(X_test_sequences, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss',min_delta=0.00001)\n",
    "def create_lstm():\n",
    "    Inp = Input(name='inputs', shape=[max_len])\n",
    "    x = Embedding(max_words, 50, input_length=max_len)(Inp)\n",
    "    x = LSTM(64, name='LSTM_01')(x)\n",
    "    x = Dropout(0.5, name='Dropout')(x)\n",
    "    x = Dense(128, activation='relu',name='Dense_01')(x)\n",
    "    # x = Dropout(0.5,name='Dropout')(x)\n",
    "    out = Dense(1,activation='sigmoid', name='output')(x)\n",
    "    model = Model(inputs=Inp, outputs=out)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct individual LSTM models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "72/72 [==============================] - 3s 44ms/step - loss: 0.4243 - accuracy: 0.8565 - f1_m: 0.9209 - recall_m: 0.9906 - precision_m: 0.8655 - val_loss: 0.4138 - val_accuracy: 0.8624 - val_f1_m: 0.9262 - val_recall_m: 1.0000 - val_precision_m: 0.8628\n",
      "Epoch 2/15\n",
      "72/72 [==============================] - 3s 35ms/step - loss: 0.4058 - accuracy: 0.8626 - f1_m: 0.9250 - recall_m: 1.0000 - precision_m: 0.8611 - val_loss: 0.4099 - val_accuracy: 0.8624 - val_f1_m: 0.9262 - val_recall_m: 1.0000 - val_precision_m: 0.8628\n",
      "Epoch 3/15\n",
      "72/72 [==============================] - 3s 36ms/step - loss: 0.4020 - accuracy: 0.8626 - f1_m: 0.9251 - recall_m: 1.0000 - precision_m: 0.8611 - val_loss: 0.4137 - val_accuracy: 0.8624 - val_f1_m: 0.9262 - val_recall_m: 1.0000 - val_precision_m: 0.8628\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x17030d3ec48>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rapport model\n",
    "rapport_model = create_lstm()\n",
    "rapport_model.compile(loss='binary_crossentropy',optimizer=RMSprop(),metrics=['accuracy', f1_m, recall_m, precision_m])\n",
    "rapport_model.fit(X_train,y_train_rapport,\n",
    "          batch_size=128,\n",
    "          epochs=15,\n",
    "          validation_data=(X_test, y_test_rapport), callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rapport_pred = rapport_model.predict(X_train)\n",
    "rapport_pred_test = rapport_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lynne\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.43117854001759015, 0.5, 0.4630460448642267, None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rapport_pred_test_round = rapport_pred_test.round()\n",
    "precision_recall_fscore_support(y_test_rapport, rapport_pred_test_round, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "72/72 [==============================] - 3s 43ms/step - loss: 0.2863 - accuracy: 0.9258 - f1_m: 0.9615 - recall_m: 0.9963 - precision_m: 0.9297 - val_loss: 0.2325 - val_accuracy: 0.9380 - val_f1_m: 0.9680 - val_recall_m: 1.0000 - val_precision_m: 0.9383\n",
      "Epoch 2/15\n",
      "72/72 [==============================] - 3s 36ms/step - loss: 0.2621 - accuracy: 0.9289 - f1_m: 0.9616 - recall_m: 1.0000 - precision_m: 0.9265 - val_loss: 0.2530 - val_accuracy: 0.9380 - val_f1_m: 0.9680 - val_recall_m: 1.0000 - val_precision_m: 0.9383\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x172106a16c8>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Game move model\n",
    "gamemove_model = create_lstm()\n",
    "gamemove_model.compile(loss='binary_crossentropy',optimizer=RMSprop(),metrics=['accuracy', f1_m, recall_m, precision_m])\n",
    "gamemove_model.fit(X_train,y_train_gamemove,\n",
    "          batch_size=128,\n",
    "          epochs=15,\n",
    "          validation_data=(X_test, y_test_gamemove), callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamemove_pred = gamemove_model.predict(X_train)\n",
    "gamemove_pred_test = gamemove_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.46899736147757254, 0.5, 0.484002722940776, None)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gamemove_pred_test_round = gamemove_pred_test.round()\n",
    "precision_recall_fscore_support(y_test_gamemove, gamemove_pred_test_round, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "72/72 [==============================] - 3s 43ms/step - loss: 0.4826 - accuracy: 0.8209 - f1_m: 0.8976 - recall_m: 0.9877 - precision_m: 0.8318 - val_loss: 0.4721 - val_accuracy: 0.8298 - val_f1_m: 0.9063 - val_recall_m: 1.0000 - val_precision_m: 0.8292\n",
      "Epoch 2/15\n",
      "72/72 [==============================] - 3s 36ms/step - loss: 0.4623 - accuracy: 0.8291 - f1_m: 0.9055 - recall_m: 1.0000 - precision_m: 0.8280 - val_loss: 0.4631 - val_accuracy: 0.8298 - val_f1_m: 0.9063 - val_recall_m: 1.0000 - val_precision_m: 0.8292\n",
      "Epoch 3/15\n",
      "72/72 [==============================] - 3s 36ms/step - loss: 0.4540 - accuracy: 0.8291 - f1_m: 0.9029 - recall_m: 1.0000 - precision_m: 0.8247 - val_loss: 0.4730 - val_accuracy: 0.8298 - val_f1_m: 0.9063 - val_recall_m: 1.0000 - val_precision_m: 0.8292\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1722302c8c8>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reasoning model\n",
    "reasoning_model = create_lstm()\n",
    "reasoning_model.compile(loss='binary_crossentropy',optimizer=RMSprop(),metrics=['accuracy', f1_m, recall_m, precision_m])\n",
    "reasoning_model.fit(X_train,y_train_reasoning,\n",
    "          batch_size=128,\n",
    "          epochs=15,\n",
    "          validation_data=(X_test, y_test_reasoning), callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "reasoning_pred = reasoning_model.predict(X_train)\n",
    "reasoning_pred_test = reasoning_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.41490765171503957, 0.5, 0.4534967555875991, None)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reasoning_pred_test_round = reasoning_pred_test.round()\n",
    "precision_recall_fscore_support(y_test_reasoning, reasoning_pred_test_round, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "72/72 [==============================] - 3s 45ms/step - loss: 0.4595 - accuracy: 0.8337 - f1_m: 0.9088 - recall_m: 0.9926 - precision_m: 0.8409 - val_loss: 0.4364 - val_accuracy: 0.8478 - val_f1_m: 0.9175 - val_recall_m: 1.0000 - val_precision_m: 0.8481\n",
      "Epoch 2/15\n",
      "72/72 [==============================] - 3s 39ms/step - loss: 0.4458 - accuracy: 0.8388 - f1_m: 0.9132 - recall_m: 1.0000 - precision_m: 0.8409 - val_loss: 0.4699 - val_accuracy: 0.8478 - val_f1_m: 0.9175 - val_recall_m: 1.0000 - val_precision_m: 0.8481\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x172293c8b08>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Share Information model\n",
    "shareinfo_model = create_lstm()\n",
    "shareinfo_model.compile(loss='binary_crossentropy',optimizer=RMSprop(),metrics=['accuracy', f1_m, recall_m, precision_m])\n",
    "shareinfo_model.fit(X_train,y_train_share_information,\n",
    "          batch_size=128,\n",
    "          epochs=15,\n",
    "          validation_data=(X_test, y_test_share_information), callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "shareinfo_pred = shareinfo_model.predict(X_train)\n",
    "shareinfo_pred_test = shareinfo_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4239226033421284, 0.5, 0.45882912898619704, None)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shareinfo_pred_test_round = shareinfo_pred_test.round()\n",
    "precision_recall_fscore_support(y_test_share_information, shareinfo_pred_test_round, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "72/72 [==============================] - 3s 48ms/step - loss: 0.2272 - accuracy: 0.9442 - f1_m: 0.9703 - recall_m: 0.9924 - precision_m: 0.9522 - val_loss: 0.2137 - val_accuracy: 0.9485 - val_f1_m: 0.9734 - val_recall_m: 1.0000 - val_precision_m: 0.9483\n",
      "Epoch 2/15\n",
      "72/72 [==============================] - 3s 35ms/step - loss: 0.1990 - accuracy: 0.9515 - f1_m: 0.9754 - recall_m: 1.0000 - precision_m: 0.9521 - val_loss: 0.2085 - val_accuracy: 0.9485 - val_f1_m: 0.9734 - val_recall_m: 1.0000 - val_precision_m: 0.9483\n",
      "Epoch 3/15\n",
      "72/72 [==============================] - 3s 35ms/step - loss: 0.1932 - accuracy: 0.9515 - f1_m: 0.9754 - recall_m: 1.0000 - precision_m: 0.9521 - val_loss: 0.2130 - val_accuracy: 0.9485 - val_f1_m: 0.9734 - val_recall_m: 1.0000 - val_precision_m: 0.9483\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1722f4b0d48>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Deception model\n",
    "deception_model = create_lstm()\n",
    "deception_model.compile(loss='binary_crossentropy',optimizer=RMSprop(),metrics=['accuracy', f1_m, recall_m, precision_m])\n",
    "deception_model.fit(X_train,y_train_deception,\n",
    "          batch_size=128,\n",
    "          epochs=15,\n",
    "          validation_data=(X_test, y_test_deception), callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4742744063324538, 0.5, 0.48679756262694657, None)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deception_pred = deception_model.predict(X_train)\n",
    "deception_pred_test = deception_model.predict(X_test)\n",
    "deception_pred_test_round = deception_pred_test.round()\n",
    "precision_recall_fscore_support(y_test_deception, deception_pred_test_round, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One hot encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train encodings\n",
    "pred_df_arr_full = []\n",
    "pred_df_arr = []\n",
    "for i in range(0, len(gamemove_pred)):\n",
    "    pred_obj_1 = {}\n",
    "    pred_obj_1['gamemove'] = gamemove_pred[i][0]\n",
    "    pred_obj_1['reasoning'] = reasoning_pred[i][0]\n",
    "    pred_obj_1['shareinfo'] = shareinfo_pred[i][0]\n",
    "    pred_df_arr.append(pred_obj_1)\n",
    "    \n",
    "    pred_obj_2 = pred_obj_1.copy()\n",
    "    pred_obj_2['rapport'] = rapport_pred[i][0]\n",
    "    pred_df_arr_full.append(pred_obj_2)\n",
    "    \n",
    "pred_df_full = pd.DataFrame(pred_df_arr_full)\n",
    "pred_df = pd.DataFrame(pred_df_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test encodings\n",
    "pred_test_df_arr_full = []\n",
    "pred_test_df_arr = []\n",
    "\n",
    "for i in range(0, len(gamemove_pred_test)):\n",
    "    pred_obj_1 = {}\n",
    "    pred_obj_1['gamemove'] = gamemove_pred_test[i][0]\n",
    "    pred_obj_1['reasoning'] = reasoning_pred_test[i][0]\n",
    "    pred_obj_1['shareinfo'] = shareinfo_pred_test[i][0]\n",
    "    pred_test_df_arr.append(pred_obj_1)\n",
    "    \n",
    "    pred_obj_2 = pred_obj_1.copy()\n",
    "    pred_obj_2['rapport'] = rapport_pred_test[i][0]\n",
    "    pred_test_df_arr_full.append(pred_obj_2)\n",
    "    \n",
    "pred_test_df_full = pd.DataFrame(pred_test_df_arr_full)\n",
    "pred_test_df = pd.DataFrame(pred_test_df_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joint Model with one hot encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_joint_model(df):\n",
    "    inputB = Input(shape=(df.shape[1],))\n",
    "    c = Dense(2, activation='relu')(inputB)\n",
    "    c = Dense(4, activation='relu')(c)\n",
    "    c = Dense(1, activation='softmax')(c)\n",
    "    full_model = Model(inputs=inputB, outputs=c)\n",
    "\n",
    "    full_model.compile(loss='binary_crossentropy', optimizer='adam', \n",
    "                          metrics=['acc',f1_m,precision_m, recall_m])\n",
    "    \n",
    "    return full_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joint full model with one hot encoding, predicting deception\n",
      "Model: \"functional_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 4)]               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 4)                 12        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 27\n",
      "Trainable params: 27\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/32\n",
      "143/143 [==============================] - 1s 5ms/step - loss: 0.7397 - acc: 0.9515 - f1_m: 0.9752 - precision_m: 0.9518 - recall_m: 1.0000 - val_loss: 0.7846 - val_acc: 0.9485 - val_f1_m: 0.9729 - val_precision_m: 0.9477 - val_recall_m: 1.0000\n",
      "Epoch 2/32\n",
      "143/143 [==============================] - 1s 4ms/step - loss: 0.7397 - acc: 0.9515 - f1_m: 0.9751 - precision_m: 0.9518 - recall_m: 1.0000 - val_loss: 0.7846 - val_acc: 0.9485 - val_f1_m: 0.9729 - val_precision_m: 0.9477 - val_recall_m: 1.0000\n"
     ]
    }
   ],
   "source": [
    "print('Joint full model with one hot encoding, predicting deception')\n",
    "joint_full_model = create_joint_model(pred_df_full)\n",
    "joint_full_model.summary()\n",
    "history = joint_full_model.fit(x=pred_df_full, y=y_train_deception, epochs=32, \n",
    "                    batch_size=64, \n",
    "                    validation_data=(pred_test_df_full,y_test_deception), callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lynne\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.025725593667546173, 0.5, 0.04893350062735258, None)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joint_predict = joint_full_model.predict(pred_test_df_full)\n",
    "joint_predict_round = []\n",
    "for a in joint_predict:\n",
    "    joint_predict_round.append([np.argmax(a)])\n",
    "precision_recall_fscore_support(y_test_deception, np.array(joint_predict_round), average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joint full model with one hot encoding, predicting rapport\n",
      "Model: \"functional_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 3)]               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 8         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 4)                 12        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 25\n",
      "Trainable params: 25\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/32\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 2.0948 - acc: 0.8626 - f1_m: 0.9261 - precision_m: 0.8635 - recall_m: 1.0000 - val_loss: 2.0989 - val_acc: 0.8624 - val_f1_m: 0.9261 - val_precision_m: 0.8638 - val_recall_m: 1.0000\n",
      "Epoch 2/32\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 2.0948 - acc: 0.8626 - f1_m: 0.9252 - precision_m: 0.8619 - recall_m: 1.0000 - val_loss: 2.0989 - val_acc: 0.8624 - val_f1_m: 0.9261 - val_precision_m: 0.8638 - val_recall_m: 1.0000\n"
     ]
    }
   ],
   "source": [
    "print('Joint full model with one hot encoding, predicting rapport')\n",
    "joint_full_model = create_joint_model(pred_df)\n",
    "joint_full_model.summary()\n",
    "history = joint_full_model.fit(x=pred_df, y=y_train_rapport, epochs=32, \n",
    "                    batch_size=64, \n",
    "                    validation_data=(pred_test_df,y_test_rapport), callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaiyuan/anaconda3/envs/TF2/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.06882145998240985, 0.5, 0.12098956320061847, None)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joint_predict = joint_full_model.predict(pred_test_df)\n",
    "joint_predict_round = []\n",
    "for a in joint_predict:\n",
    "    joint_predict_round.append([np.argmax(a)])\n",
    "precision_recall_fscore_support(y_test_rapport, np.array(joint_predict_round), average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joint Model by Keras Concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_concatenate_keras_model(models_arr):\n",
    "    commonInput = Input(shape=[max_len])\n",
    "\n",
    "    input_model_arr = []\n",
    "    for model in models_arr: \n",
    "        outmodel = model(commonInput)\n",
    "        input_model_arr.append(outmodel)\n",
    "    \n",
    "    mergedOut = Concatenate()(input_model_arr)\n",
    "\n",
    "    mergedOut = Flatten()(mergedOut)    \n",
    "    mergedOut = Dense(256, activation='relu')(mergedOut)\n",
    "    mergedOut = Dropout(.5)(mergedOut)\n",
    "    mergedOut = Dense(128, activation='relu')(mergedOut)\n",
    "    mergedOut = Dropout(.35)(mergedOut)\n",
    "    mergedOut = Dense(1, activation='softmax')(mergedOut)  #Cuz binary\n",
    "\n",
    "    mergedModel = Model(commonInput, mergedOut)\n",
    "    mergedModel.compile(loss='binary_crossentropy', optimizer=RMSprop(), metrics=['accuracy', f1_m, recall_m, precision_m])\n",
    "    \n",
    "    return mergedModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joint model by concatenate, predicting deception\n",
      "Model: \"functional_19\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            [(None, 220)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "functional_3 (Functional)       (None, 1)            87889       input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "functional_5 (Functional)       (None, 1)            87889       input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "functional_7 (Functional)       (None, 1)            87889       input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "functional_1 (Functional)       (None, 1)            87889       input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 4)            0           functional_3[2][0]               \n",
      "                                                                 functional_5[2][0]               \n",
      "                                                                 functional_7[2][0]               \n",
      "                                                                 functional_1[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 4)            0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 256)          1280        flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 256)          0           dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 128)          32896       dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 128)          0           dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 1)            129         dropout_5[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 385,861\n",
      "Trainable params: 385,861\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/15\n",
      "72/72 [==============================] - 10s 133ms/step - loss: 0.7397 - accuracy: 0.9515 - f1_m: 0.9735 - recall_m: 1.0000 - precision_m: 0.9488 - val_loss: 0.7846 - val_accuracy: 0.9485 - val_f1_m: 0.9734 - val_recall_m: 1.0000 - val_precision_m: 0.9483\n",
      "Epoch 2/15\n",
      "72/72 [==============================] - 8s 117ms/step - loss: 0.7397 - accuracy: 0.9515 - f1_m: 0.9754 - recall_m: 1.0000 - precision_m: 0.9521 - val_loss: 0.7846 - val_accuracy: 0.9485 - val_f1_m: 0.9734 - val_recall_m: 1.0000 - val_precision_m: 0.9483\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x17259842c88>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Joint model by concatenate, predicting deception')\n",
    "merged_model = create_concatenate_keras_model([gamemove_model, reasoning_model, shareinfo_model, rapport_model])\n",
    "merged_model.summary()\n",
    "merged_model.fit(X_train,y_train_deception,\n",
    "          batch_size=128,\n",
    "          epochs=15,\n",
    "          validation_data=(X_test,y_test_deception), callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.06882145998240985, 0.5, 0.12098956320061847, None)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joint_predict = merged_model.predict(X_test)\n",
    "joint_predict_round = []\n",
    "for a in joint_predict:\n",
    "    joint_predict_round.append([np.argmax(a)])\n",
    "precision_recall_fscore_support(y_test_rapport, np.array(joint_predict_round), average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joint model by concatenate, predicting rapport\n",
      "Model: \"functional_17\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 220)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "functional_3 (Functional)       (None, 1)            87889       input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "functional_5 (Functional)       (None, 1)            87889       input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "functional_7 (Functional)       (None, 1)            87889       input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 3)            0           functional_3[1][0]               \n",
      "                                                                 functional_5[1][0]               \n",
      "                                                                 functional_7[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 3)            0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 256)          1024        flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 256)          0           dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 128)          32896       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 128)          0           dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 1)            129         dropout_3[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 297,716\n",
      "Trainable params: 297,716\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/15\n",
      "72/72 [==============================] - 8s 115ms/step - loss: 2.0948 - accuracy: 0.8626 - f1_m: 0.9251 - recall_m: 1.0000 - precision_m: 0.8611 - val_loss: 2.0989 - val_accuracy: 0.8624 - val_f1_m: 0.9262 - val_recall_m: 1.0000 - val_precision_m: 0.8628\n",
      "Epoch 2/15\n",
      "72/72 [==============================] - 6s 85ms/step - loss: 2.0948 - accuracy: 0.8626 - f1_m: 0.9250 - recall_m: 1.0000 - precision_m: 0.8611 - val_loss: 2.0989 - val_accuracy: 0.8624 - val_f1_m: 0.9262 - val_recall_m: 1.0000 - val_precision_m: 0.8628\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x172496b4888>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Joint model by concatenate, predicting rapport')\n",
    "merged_model = create_concatenate_keras_model([gamemove_model, reasoning_model, shareinfo_model])\n",
    "merged_model.summary()\n",
    "merged_model.fit(X_train,y_train_rapport,\n",
    "          batch_size=128,\n",
    "          epochs=15,\n",
    "          validation_data=(X_test,y_test_rapport), callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lynne\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.06882145998240985, 0.5, 0.12098956320061847, None)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joint_predict = merged_model.predict(X_test)\n",
    "joint_predict_round = []\n",
    "for a in joint_predict:\n",
    "    joint_predict_round.append([np.argmax(a)])\n",
    "precision_recall_fscore_support(y_test_rapport, np.array(joint_predict_round), average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weighted against Throughput, WorkTime, & PC Agreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train weighted encodings\n",
    "pred_df_full_throughput = pred_df_full.copy()\n",
    "pred_df_full_worktime = pred_df_full.copy()\n",
    "pred_df_throughput = pred_df.copy()\n",
    "pred_df_worktime = pred_df.copy()\n",
    "\n",
    "throughput_values = df_throughput['var_throughput'].take(indices_train).values\n",
    "pred_df_full_throughput = pred_df_full_throughput.mul(throughput_values, axis=0)\n",
    "pred_df_throughput = pred_df_throughput.mul(throughput_values, axis=0)\n",
    "\n",
    "worktime_values = df_worktime['var_worktime'].take(indices_train).values\n",
    "pred_df_full_worktime = pred_df_full_worktime.mul(worktime_values, axis=0)\n",
    "pred_df_worktime = pred_df_worktime.mul(worktime_values, axis=0)\n",
    "\n",
    "agreement_values = df_agreement.take(indices_train)\n",
    "pred_df_full_agreement = np.multiply(pred_df_full_throughput, agreement_values)\n",
    "agreement_values_wo_rapport = agreement_values.drop(columns=['Answer.3rapport.yes_pc_agree'])\n",
    "pred_df_agreement = np.multiply(pred_df_throughput, agreement_values_wo_rapport)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gamemove</th>\n",
       "      <th>reasoning</th>\n",
       "      <th>shareinfo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.694944</td>\n",
       "      <td>0.624336</td>\n",
       "      <td>0.529629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.756293</td>\n",
       "      <td>0.576350</td>\n",
       "      <td>0.581992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.685997</td>\n",
       "      <td>0.469354</td>\n",
       "      <td>0.821573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.673292</td>\n",
       "      <td>0.598521</td>\n",
       "      <td>0.648484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.747960</td>\n",
       "      <td>0.354421</td>\n",
       "      <td>0.720138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gamemove  reasoning  shareinfo\n",
       "0  0.694944   0.624336   0.529629\n",
       "1  0.756293   0.576350   0.581992\n",
       "2  0.685997   0.469354   0.821573\n",
       "3  0.673292   0.598521   0.648484\n",
       "4  0.747960   0.354421   0.720138"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df_agreement.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test weighted encodings\n",
    "pred_df_full_throughput_test = pred_test_df_full.copy()\n",
    "pred_df_full_worktime_test = pred_test_df_full.copy()\n",
    "pred_df_throughput_test = pred_test_df.copy()\n",
    "pred_df_worktime_test = pred_test_df.copy()\n",
    "\n",
    "throughput_values_test = df_throughput['var_throughput'].take(indices_test).values\n",
    "pred_df_full_throughput_test = pred_df_full_throughput_test.mul(throughput_values_test, axis=0)\n",
    "pred_df_throughput_test = pred_df_throughput_test.mul(throughput_values_test, axis=0)\n",
    "\n",
    "worktime_values_test = df_worktime['var_worktime'].take(indices_test).values\n",
    "pred_df_full_worktime_test = pred_df_full_worktime_test.mul(worktime_values_test, axis=0)\n",
    "pred_df_worktime_test = pred_df_worktime_test.mul(worktime_values_test, axis=0)\n",
    "\n",
    "agreement_values_test = df_agreement.take(indices_test)\n",
    "pred_df_full_agreement_test = np.multiply(pred_df_full_throughput_test, agreement_values_test)\n",
    "agreement_values_wo_rapport_test = agreement_values_test.drop(columns=['Answer.3rapport.yes_pc_agree'])\n",
    "pred_df_agreement_test = np.multiply(pred_df_throughput_test, agreement_values_wo_rapport_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Throughput only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joint Model with one hot encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_joint_model(df):\n",
    "    inputB = Input(shape=(df.shape[1],))\n",
    "    c = Dense(2, activation='relu')(inputB)\n",
    "    c = Dense(4, activation='relu')(c)\n",
    "    c = Dense(1, activation='softmax')(c)\n",
    "    full_model = Model(inputs=inputB, outputs=c)\n",
    "\n",
    "    full_model.compile(loss='binary_crossentropy', optimizer='adam', \n",
    "                          metrics=['acc',f1_m,precision_m, recall_m])\n",
    "    \n",
    "    return full_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joint full model with one hot encoding, predicting deception, weighted by throughput\n",
      "Model: \"functional_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         [(None, 4)]               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 4)                 12        \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 27\n",
      "Trainable params: 27\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/32\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.7397 - acc: 0.9515 - f1_m: 0.9742 - precision_m: 0.9502 - recall_m: 1.0000 - val_loss: 0.7846 - val_acc: 0.9485 - val_f1_m: 0.9733 - val_precision_m: 0.9485 - val_recall_m: 1.0000\n",
      "Epoch 2/32\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.7397 - acc: 0.9515 - f1_m: 0.9742 - precision_m: 0.9502 - recall_m: 1.0000 - val_loss: 0.7846 - val_acc: 0.9485 - val_f1_m: 0.9733 - val_precision_m: 0.9485 - val_recall_m: 1.0000\n"
     ]
    }
   ],
   "source": [
    "print('Joint full model with one hot encoding, predicting deception, weighted by throughput')\n",
    "joint_full_model = create_joint_model(pred_df_full_throughput)\n",
    "joint_full_model.summary()\n",
    "history = joint_full_model.fit(x=pred_df_full_throughput, y=y_train_deception, epochs=32, \n",
    "                    batch_size=64, \n",
    "                    validation_data=(pred_df_full_throughput_test,y_test_deception), callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaiyuan/anaconda3/envs/TF2/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.025725593667546173, 0.5, 0.04893350062735258, None)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joint_predict = joint_full_model.predict(pred_df_full_throughput_test)\n",
    "joint_predict_round = []\n",
    "for a in joint_predict:\n",
    "    joint_predict_round.append([np.argmax(a)])\n",
    "precision_recall_fscore_support(y_test_deception, np.array(joint_predict_round), average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_rapport = np.asarray(y_test_rapport)\n",
    "y_train_rapport = np.asarray(y_train_rapport)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joint full model with one hot encoding, predicting rapport, weighted by throughput\n",
      "Model: \"functional_23\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         [(None, 3)]               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 2)                 8         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 4)                 12        \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 25\n",
      "Trainable params: 25\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/32\n",
      "143/143 [==============================] - 1s 5ms/step - loss: 2.0948 - acc: 0.8626 - f1_m: 0.9260 - precision_m: 0.8635 - recall_m: 1.0000 - val_loss: 2.0990 - val_acc: 0.8624 - val_f1_m: 0.9253 - val_precision_m: 0.8619 - val_recall_m: 1.0000\n",
      "Epoch 2/32\n",
      "143/143 [==============================] - 1s 4ms/step - loss: 2.0948 - acc: 0.8626 - f1_m: 0.9252 - precision_m: 0.8619 - recall_m: 1.0000 - val_loss: 2.0990 - val_acc: 0.8624 - val_f1_m: 0.9253 - val_precision_m: 0.8619 - val_recall_m: 1.0000\n"
     ]
    }
   ],
   "source": [
    "print('Joint full model with one hot encoding, predicting rapport, weighted by throughput')\n",
    "joint_full_model = create_joint_model(pred_df_throughput)\n",
    "joint_full_model.summary()\n",
    "history = joint_full_model.fit(x=pred_df_throughput, y=y_train_rapport, epochs=32, \n",
    "                    batch_size=64, \n",
    "                    validation_data=(pred_df_throughput_test,y_test_rapport), callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lynne\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.06882145998240985, 0.5, 0.12098956320061847, None)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joint_predict = joint_full_model.predict(pred_df_throughput_test)\n",
    "joint_predict_round = []\n",
    "for a in joint_predict:\n",
    "    joint_predict_round.append([np.argmax(a)])\n",
    "precision_recall_fscore_support(y_test_rapport, np.array(joint_predict_round), average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PC Agreement only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joint Model with one hot encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_joint_model(df):\n",
    "    inputB = Input(shape=(df.shape[1],))\n",
    "    c = Dense(2, activation='relu')(inputB)\n",
    "    c = Dense(4, activation='relu')(c)\n",
    "    c = Dense(1, activation='softmax')(c)\n",
    "    full_model = Model(inputs=inputB, outputs=c)\n",
    "\n",
    "    full_model.compile(loss='binary_crossentropy', optimizer='adam', \n",
    "                          metrics=['acc',f1_m,precision_m, recall_m])\n",
    "    \n",
    "    return full_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joint full model with one hot encoding, predicting deception, weighted by PC Agreement\n",
      "Model: \"functional_25\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_8 (InputLayer)         [(None, 4)]               0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 4)                 12        \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 27\n",
      "Trainable params: 27\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/32\n",
      "143/143 [==============================] - 1s 5ms/step - loss: 0.7397 - acc: 0.9515 - f1_m: 0.9751 - precision_m: 0.9518 - recall_m: 1.0000 - val_loss: 0.7846 - val_acc: 0.9485 - val_f1_m: 0.9729 - val_precision_m: 0.9477 - val_recall_m: 1.0000\n",
      "Epoch 2/32\n",
      "143/143 [==============================] - 1s 4ms/step - loss: 0.7397 - acc: 0.9515 - f1_m: 0.9751 - precision_m: 0.9518 - recall_m: 1.0000 - val_loss: 0.7846 - val_acc: 0.9485 - val_f1_m: 0.9729 - val_precision_m: 0.9477 - val_recall_m: 1.0000\n"
     ]
    }
   ],
   "source": [
    "print('Joint full model with one hot encoding, predicting deception, weighted by PC Agreement')\n",
    "joint_full_model = create_joint_model(pred_df_full_agreement)\n",
    "joint_full_model.summary()\n",
    "history = joint_full_model.fit(x=pred_df_full_agreement, y=y_train_deception, epochs=32, \n",
    "                    batch_size=64, \n",
    "                    validation_data=(pred_df_full_agreement_test,y_test_deception), callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lynne\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.06882145998240985, 0.5, 0.12098956320061847, None)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joint_predict = joint_full_model.predict(pred_df_full_throughput_test)\n",
    "joint_predict_round = []\n",
    "for a in joint_predict:\n",
    "    joint_predict_round.append([np.argmax(a)])\n",
    "precision_recall_fscore_support(y_test_rapport, np.array(joint_predict_round), average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_rapport = np.asarray(y_test_rapport)\n",
    "y_train_rapport = np.asarray(y_train_rapport)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joint full model with one hot encoding, predicting rapport, weighted by PC Agreement\n",
      "Model: \"functional_27\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         [(None, 3)]               0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 2)                 8         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 4)                 12        \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 25\n",
      "Trainable params: 25\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/32\n",
      "143/143 [==============================] - 1s 5ms/step - loss: 2.0948 - acc: 0.8626 - f1_m: 0.9262 - precision_m: 0.8635 - recall_m: 1.0000 - val_loss: 2.0990 - val_acc: 0.8624 - val_f1_m: 0.9253 - val_precision_m: 0.8619 - val_recall_m: 1.0000\n",
      "Epoch 2/32\n",
      "143/143 [==============================] - 1s 4ms/step - loss: 2.0948 - acc: 0.8626 - f1_m: 0.9251 - precision_m: 0.8619 - recall_m: 1.0000 - val_loss: 2.0990 - val_acc: 0.8624 - val_f1_m: 0.9253 - val_precision_m: 0.8619 - val_recall_m: 1.0000\n"
     ]
    }
   ],
   "source": [
    "print('Joint full model with one hot encoding, predicting rapport, weighted by PC Agreement')\n",
    "joint_full_model = create_joint_model(pred_df_agreement)\n",
    "joint_full_model.summary()\n",
    "history = joint_full_model.fit(x=pred_df_agreement, y=y_train_rapport, epochs=32, \n",
    "                    batch_size=64, \n",
    "                    validation_data=(pred_df_agreement_test,y_test_rapport), callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lynne\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.06882145998240985, 0.5, 0.12098956320061847, None)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joint_predict = joint_full_model.predict(pred_df_throughput_test)\n",
    "joint_predict_round = []\n",
    "for a in joint_predict:\n",
    "    joint_predict_round.append([np.argmax(a)])\n",
    "precision_recall_fscore_support(y_test_rapport, np.array(joint_predict_round), average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WorkTime only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joint Model with one hot encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_joint_model(df):\n",
    "    inputB = Input(shape=(df.shape[1],))\n",
    "    c = Dense(2, activation='relu')(inputB)\n",
    "    c = Dense(4, activation='relu')(c)\n",
    "    c = Dense(1, activation='softmax')(c)\n",
    "    full_model = Model(inputs=inputB, outputs=c)\n",
    "\n",
    "    full_model.compile(loss='binary_crossentropy', optimizer='adam', \n",
    "                          metrics=['acc',f1_m,precision_m, recall_m])\n",
    "    \n",
    "    return full_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joint full model with one hot encoding, predicting deception, weighted by throughput\n",
      "Model: \"functional_27\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         [(None, 4)]               0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 4)                 12        \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 27\n",
      "Trainable params: 27\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/32\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.7397 - acc: 0.9515 - f1_m: 0.9751 - precision_m: 0.9518 - recall_m: 1.0000 - val_loss: 0.7846 - val_acc: 0.9485 - val_f1_m: 0.9733 - val_precision_m: 0.9485 - val_recall_m: 1.0000\n",
      "Epoch 2/32\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.7397 - acc: 0.9515 - f1_m: 0.9751 - precision_m: 0.9518 - recall_m: 1.0000 - val_loss: 0.7846 - val_acc: 0.9485 - val_f1_m: 0.9733 - val_precision_m: 0.9485 - val_recall_m: 1.0000\n"
     ]
    }
   ],
   "source": [
    "print('Joint full model with one hot encoding, predicting deception, weighted by throughput')\n",
    "joint_full_model = create_joint_model(pred_df_full_worktime)\n",
    "joint_full_model.summary()\n",
    "history = joint_full_model.fit(x=pred_df_full_worktime, y=y_train_deception, epochs=32, \n",
    "                    batch_size=64, \n",
    "                    validation_data=(pred_df_full_worktime_test,y_test_deception), callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_rapport = np.asarray(y_test_rapport)\n",
    "y_train_rapport = np.asarray(y_train_rapport)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joint full model with one hot encoding, predicting rapport, weighted by throughput\n",
      "Model: \"functional_29\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_10 (InputLayer)        [(None, 3)]               0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 2)                 8         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 4)                 12        \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 25\n",
      "Trainable params: 25\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/32\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 2.0948 - acc: 0.8626 - f1_m: 0.9262 - precision_m: 0.8635 - recall_m: 1.0000 - val_loss: 2.0989 - val_acc: 0.8624 - val_f1_m: 0.9261 - val_precision_m: 0.8638 - val_recall_m: 1.0000\n",
      "Epoch 2/32\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 2.0948 - acc: 0.8626 - f1_m: 0.9261 - precision_m: 0.8635 - recall_m: 1.0000 - val_loss: 2.0989 - val_acc: 0.8624 - val_f1_m: 0.9261 - val_precision_m: 0.8638 - val_recall_m: 1.0000\n"
     ]
    }
   ],
   "source": [
    "print('Joint full model with one hot encoding, predicting rapport, weighted by throughput')\n",
    "joint_full_model = create_joint_model(pred_df_worktime)\n",
    "joint_full_model.summary()\n",
    "history = joint_full_model.fit(x=pred_df_worktime, y=y_train_rapport, epochs=32, \n",
    "                    batch_size=64, \n",
    "                    validation_data=(pred_df_worktime_test,y_test_rapport), callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfgpu",
   "language": "python",
   "name": "tfgpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
