{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import LSTM, Input, InputLayer, Dropout, Dense, Flatten, Embedding, Add, Concatenate\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "import torch\n",
    "from sklearn.metrics import precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Good data\n",
    "# df = pd.read_csv('./data/kokil dec 6 reprepare/affcon_final_with_linguistics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Messy data\n",
    "# df = pd.read_csv('./data/affcon_final_politeness_strategies_merge.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data with Throughput & WorkTime\n",
    "df = pd.read_csv('./data/kokil dec 6 reprepare/conf_pc_worker_sem.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4013"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_small = df[0:500]\n",
    "df = df_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_throughput' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-7c1a4c92c02b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_throughput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df_throughput' is not defined"
     ]
    }
   ],
   "source": [
    "max(df_throughput.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Throughput\n",
    "df_throughput = df[['Throughput.1', 'Throughput.2', 'Throughput.3', 'Throughput.4', 'Throughput.5']].copy()\n",
    "df_throughput['avg_throughput'] = df_throughput.mean(axis=1) / max(df_throughput.max())\n",
    "\n",
    "# WorkTime\n",
    "df_worktime = df[['WorkTime.1', 'WorkTime.2', 'WorkTime.3', 'WorkTime.4', 'WorkTime.5']].copy()\n",
    "df_worktime['avg_worktime'] = df_worktime.mean(axis=1) / max(df_worktime.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = range(df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Individual Classifiers are LSTMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test, indices_train, indices_test = train_test_split(df, indices, test_size=0.2)\n",
    "\n",
    "new_deception_train = train[\"Input.deception_quadrant\"].copy()\n",
    "new_deception_train['Input.deception_quadrant'] = train[\"Input.deception_quadrant\"].apply(lambda x : 1 if x == \"Straightforward\" else 0)\n",
    "y_train_deception = new_deception_train['Input.deception_quadrant'].tolist()\n",
    "y_train_rapport = train['Answer.3rapport.yes_label'].tolist()\n",
    "y_train_share_information = train['Answer.4shareinformation.yes_label'].tolist()\n",
    "y_train_reasoning = train['Answer.2reasoning.yes_label'].tolist()\n",
    "y_train_gamemove = train['Answer.1gamemove.yes_label'].tolist()\n",
    "\n",
    "X_train_col = train['Input.full_text']\n",
    "\n",
    "new_deception_test = test[\"Input.deception_quadrant\"].copy()\n",
    "new_deception_test['Input.deception_quadrant'] = test[\"Input.deception_quadrant\"].apply(lambda x : 1 if x == \"Straightforward\" else 0)\n",
    "y_test_deception = new_deception_test['Input.deception_quadrant'].tolist()\n",
    "y_test_rapport = test['Answer.3rapport.yes_label'].tolist()\n",
    "y_test_share_information = test['Answer.4shareinformation.yes_label'].tolist()\n",
    "y_test_reasoning = test['Answer.2reasoning.yes_label'].tolist()\n",
    "y_test_gamemove = test['Answer.1gamemove.yes_label'].tolist()\n",
    "\n",
    "X_test_col = test['Input.full_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', min_delta=0, patience=0, verbose=0, mode='auto',\n",
    "    baseline=None, restore_best_weights=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lynne\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "\n",
    "y_train_deception = le.fit_transform(y_train_deception)\n",
    "y_train_deception = y_train_deception.reshape(-1,1)\n",
    "\n",
    "y_train_rapport = le.fit_transform(y_train_rapport)\n",
    "y_train_rapport = y_train_rapport.reshape(-1,1)\n",
    "\n",
    "y_train_share_information = le.fit_transform(y_train_share_information)\n",
    "y_train_share_information = y_train_share_information.reshape(-1,1)\n",
    "\n",
    "y_train_reasoning = le.fit_transform(y_train_reasoning)\n",
    "y_train_reasoning = y_train_reasoning.reshape(-1,1)\n",
    "\n",
    "y_train_gamemove = le.fit_transform(y_train_gamemove)\n",
    "y_train_gamemove = y_train_gamemove.reshape(-1,1)\n",
    "\n",
    "y_train_deception = le.fit_transform(y_train_deception)\n",
    "y_train_deception = y_train_deception.reshape(-1,1)\n",
    "\n",
    "y_test_rapport = le.fit_transform(y_test_rapport)\n",
    "y_test_rapport = y_test_rapport.reshape(-1,1)\n",
    "\n",
    "y_test_share_information = le.fit_transform(y_test_share_information)\n",
    "y_test_share_information = y_test_share_information.reshape(-1,1)\n",
    "\n",
    "y_test_reasoning = le.fit_transform(y_test_reasoning)\n",
    "y_test_reasoning = y_test_reasoning.reshape(-1,1)\n",
    "\n",
    "y_test_gamemove = le.fit_transform(y_test_gamemove)\n",
    "y_test_gamemove = y_test_gamemove.reshape(-1,1)\n",
    "\n",
    "y_test_deception = le.fit_transform(y_test_deception)\n",
    "y_test_deception = y_test_deception.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 1000\n",
    "max_len = 220\n",
    "\n",
    "tok = Tokenizer(num_words=max_words)\n",
    "\n",
    "tok.fit_on_texts(X_train_col)\n",
    "X_train_sequences = tok.texts_to_sequences(X_train_col)\n",
    "X_train = pad_sequences(X_train_sequences, maxlen=max_len)\n",
    "\n",
    "tok.fit_on_texts(X_test_col)\n",
    "X_test_sequences = tok.texts_to_sequences(X_test_col)\n",
    "X_test = pad_sequences(X_test_sequences, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss',min_delta=0.00001)\n",
    "def create_lstm():\n",
    "    Inp = Input(name='inputs', shape=[max_len])\n",
    "    x = Embedding(max_words, 50, input_length=max_len)(Inp)\n",
    "    x = LSTM(64, name='LSTM_01')(x)\n",
    "    x = Dropout(0.5, name='Dropout')(x)\n",
    "    x = Dense(128, activation='relu',name='Dense_01')(x)\n",
    "    # x = Dropout(0.5,name='Dropout')(x)\n",
    "    out = Dense(1,activation='sigmoid', name='output')(x)\n",
    "    model = Model(inputs=Inp, outputs=out)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct individual LSTM models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "4/4 [==============================] - 1s 172ms/step - loss: 0.6746 - accuracy: 0.6450 - f1_m: 0.7314 - recall_m: 0.7705 - precision_m: 0.8510 - val_loss: 0.3908 - val_accuracy: 0.8700 - val_f1_m: 0.9305 - val_recall_m: 1.0000 - val_precision_m: 0.8700\n",
      "Epoch 2/15\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.4664 - accuracy: 0.8575 - f1_m: 0.9324 - recall_m: 1.0000 - precision_m: 0.8750 - val_loss: 0.4220 - val_accuracy: 0.8700 - val_f1_m: 0.9305 - val_recall_m: 1.0000 - val_precision_m: 0.8700\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x224e5cce708>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rapport model\n",
    "rapport_model = create_lstm()\n",
    "rapport_model.compile(loss='binary_crossentropy',optimizer=RMSprop(),metrics=['accuracy', f1_m, recall_m, precision_m])\n",
    "rapport_model.fit(X_train,y_train_rapport,\n",
    "          batch_size=128,\n",
    "          epochs=15,\n",
    "          validation_data=(X_test, y_test_rapport), callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "rapport_pred = rapport_model.predict(X_train)\n",
    "rapport_pred_test = rapport_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lynne\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.435, 0.5, 0.4652406417112299, None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rapport_pred_test_round = rapport_pred_test.round()\n",
    "precision_recall_fscore_support(y_test_rapport, rapport_pred_test_round, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "4/4 [==============================] - 1s 162ms/step - loss: 0.6612 - accuracy: 0.7925 - f1_m: 0.8918 - recall_m: 0.8969 - precision_m: 0.9022 - val_loss: 0.2544 - val_accuracy: 0.9300 - val_f1_m: 0.9637 - val_recall_m: 1.0000 - val_precision_m: 0.9300\n",
      "Epoch 2/15\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.3538 - accuracy: 0.9025 - f1_m: 0.9529 - recall_m: 1.0000 - precision_m: 0.9102 - val_loss: 0.2550 - val_accuracy: 0.9300 - val_f1_m: 0.9637 - val_recall_m: 1.0000 - val_precision_m: 0.9300\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x22516f8d508>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Game move model\n",
    "gamemove_model = create_lstm()\n",
    "gamemove_model.compile(loss='binary_crossentropy',optimizer=RMSprop(),metrics=['accuracy', f1_m, recall_m, precision_m])\n",
    "gamemove_model.fit(X_train,y_train_gamemove,\n",
    "          batch_size=128,\n",
    "          epochs=15,\n",
    "          validation_data=(X_test, y_test_gamemove), callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamemove_pred = gamemove_model.predict(X_train)\n",
    "gamemove_pred_test = gamemove_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.465, 0.5, 0.48186528497409326, None)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gamemove_pred_test_round = gamemove_pred_test.round()\n",
    "precision_recall_fscore_support(y_test_gamemove, gamemove_pred_test_round, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "4/4 [==============================] - 1s 160ms/step - loss: 0.6649 - accuracy: 0.7750 - f1_m: 0.8817 - recall_m: 0.9393 - precision_m: 0.8337 - val_loss: 0.5271 - val_accuracy: 0.8100 - val_f1_m: 0.8950 - val_recall_m: 1.0000 - val_precision_m: 0.8100\n",
      "Epoch 2/15\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.4879 - accuracy: 0.8275 - f1_m: 0.9115 - recall_m: 1.0000 - precision_m: 0.8379 - val_loss: 0.4899 - val_accuracy: 0.8100 - val_f1_m: 0.8950 - val_recall_m: 1.0000 - val_precision_m: 0.8100\n",
      "Epoch 3/15\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.4629 - accuracy: 0.8275 - f1_m: 0.9036 - recall_m: 1.0000 - precision_m: 0.8242 - val_loss: 0.4875 - val_accuracy: 0.8100 - val_f1_m: 0.8950 - val_recall_m: 1.0000 - val_precision_m: 0.8100\n",
      "Epoch 4/15\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.4642 - accuracy: 0.8275 - f1_m: 0.9114 - recall_m: 1.0000 - precision_m: 0.8379 - val_loss: 0.4889 - val_accuracy: 0.8100 - val_f1_m: 0.8950 - val_recall_m: 1.0000 - val_precision_m: 0.8100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2251f277888>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reasoning model\n",
    "reasoning_model = create_lstm()\n",
    "reasoning_model.compile(loss='binary_crossentropy',optimizer=RMSprop(),metrics=['accuracy', f1_m, recall_m, precision_m])\n",
    "reasoning_model.fit(X_train,y_train_reasoning,\n",
    "          batch_size=128,\n",
    "          epochs=15,\n",
    "          validation_data=(X_test, y_test_reasoning), callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "reasoning_pred = reasoning_model.predict(X_train)\n",
    "reasoning_pred_test = reasoning_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.405, 0.5, 0.44751381215469616, None)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reasoning_pred_test_round = reasoning_pred_test.round()\n",
    "precision_recall_fscore_support(y_test_reasoning, reasoning_pred_test_round, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "4/4 [==============================] - 1s 172ms/step - loss: 0.6718 - accuracy: 0.7400 - f1_m: 0.8375 - recall_m: 0.8915 - precision_m: 0.8170 - val_loss: 0.5294 - val_accuracy: 0.7900 - val_f1_m: 0.8827 - val_recall_m: 1.0000 - val_precision_m: 0.7900\n",
      "Epoch 2/15\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.4914 - accuracy: 0.8225 - f1_m: 0.9090 - recall_m: 1.0000 - precision_m: 0.8340 - val_loss: 0.5706 - val_accuracy: 0.7900 - val_f1_m: 0.8827 - val_recall_m: 1.0000 - val_precision_m: 0.7900\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x225244fb508>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Share Information model\n",
    "shareinfo_model = create_lstm()\n",
    "shareinfo_model.compile(loss='binary_crossentropy',optimizer=RMSprop(),metrics=['accuracy', f1_m, recall_m, precision_m])\n",
    "shareinfo_model.fit(X_train,y_train_share_information,\n",
    "          batch_size=128,\n",
    "          epochs=15,\n",
    "          validation_data=(X_test, y_test_share_information), callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "shareinfo_pred = shareinfo_model.predict(X_train)\n",
    "shareinfo_pred_test = shareinfo_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.395, 0.5, 0.44134078212290506, None)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shareinfo_pred_test_round = shareinfo_pred_test.round()\n",
    "precision_recall_fscore_support(y_test_share_information, shareinfo_pred_test_round, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6644 - accuracy: 0.8385 - f1_m: 0.8912 - recall_m: 0.8360 - precision_m: 1.0000WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000002252D76E8B8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "4/4 [==============================] - 1s 263ms/step - loss: 0.6604 - accuracy: 0.8450 - f1_m: 0.9184 - recall_m: 0.8770 - precision_m: 1.0000 - val_loss: 1.5548 - val_accuracy: 0.0000e+00 - val_f1_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_precision_m: 0.0000e+00\n",
      "Epoch 2/15\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.1139 - accuracy: 0.9950 - f1_m: 0.9980 - recall_m: 1.0000 - precision_m: 0.9961 - val_loss: 4.9670 - val_accuracy: 0.0000e+00 - val_f1_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_precision_m: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2252a58db08>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Deception model\n",
    "deception_model = create_lstm()\n",
    "deception_model.compile(loss='binary_crossentropy',optimizer=RMSprop(),metrics=['accuracy', f1_m, recall_m, precision_m])\n",
    "deception_model.fit(X_train,y_train_deception,\n",
    "          batch_size=128,\n",
    "          epochs=15,\n",
    "          validation_data=(X_test, y_test_deception), callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lynne\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0, 0.0, 0.0, None)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deception_pred = deception_model.predict(X_train)\n",
    "deception_pred_test = deception_model.predict(X_test)\n",
    "deception_pred_test_round = deception_pred_test.round()\n",
    "precision_recall_fscore_support(y_test_deception, deception_pred_test_round, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One hot encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train encodings\n",
    "pred_df_arr_full = []\n",
    "pred_df_arr = []\n",
    "for i in range(0, len(gamemove_pred)):\n",
    "    pred_obj_1 = {}\n",
    "    pred_obj_1['gamemove'] = gamemove_pred[i][0]\n",
    "    pred_obj_1['reasoning'] = reasoning_pred[i][0]\n",
    "    pred_obj_1['shareinfo'] = shareinfo_pred[i][0]\n",
    "    pred_df_arr.append(pred_obj_1)\n",
    "    \n",
    "    pred_obj_2 = pred_obj_1.copy()\n",
    "    pred_obj_2['rapport'] = rapport_pred[i][0]\n",
    "    pred_df_arr_full.append(pred_obj_2)\n",
    "    \n",
    "pred_df_full = pd.DataFrame(pred_df_arr_full)\n",
    "pred_df = pd.DataFrame(pred_df_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test encodings\n",
    "pred_test_df_arr_full = []\n",
    "pred_test_df_arr = []\n",
    "\n",
    "for i in range(0, len(gamemove_pred_test)):\n",
    "    pred_obj_1 = {}\n",
    "    pred_obj_1['gamemove'] = gamemove_pred_test[i][0]\n",
    "    pred_obj_1['reasoning'] = reasoning_pred_test[i][0]\n",
    "    pred_obj_1['shareinfo'] = shareinfo_pred_test[i][0]\n",
    "    pred_test_df_arr.append(pred_obj_1)\n",
    "    \n",
    "    pred_obj_2 = pred_obj_1.copy()\n",
    "    pred_obj_2['rapport'] = rapport_pred_test[i][0]\n",
    "    pred_test_df_arr_full.append(pred_obj_2)\n",
    "    \n",
    "pred_test_df_full = pd.DataFrame(pred_test_df_arr_full)\n",
    "pred_test_df = pd.DataFrame(pred_test_df_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joint Model with one hot encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_joint_model(df):\n",
    "    inputB = Input(shape=(df.shape[1],))\n",
    "    c = Dense(2, activation='relu')(inputB)\n",
    "    c = Dense(4, activation='relu')(c)\n",
    "    c = Dense(2, activation='softmax')(c)\n",
    "    full_model = Model(inputs=inputB, outputs=c)\n",
    "\n",
    "    full_model.compile(loss='binary_crossentropy', optimizer='adam', \n",
    "                          metrics=['acc',f1_m,precision_m, recall_m])\n",
    "    \n",
    "    return full_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joint full model with one hot encoding, predicting deception\n",
      "Model: \"functional_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 4)]               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 12        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 10        \n",
      "=================================================================\n",
      "Total params: 32\n",
      "Trainable params: 32\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/32\n",
      "7/7 [==============================] - 0s 40ms/step - loss: 0.8845 - acc: 0.0025 - f1_m: 0.9989 - precision_m: 0.9978 - recall_m: 1.0000 - val_loss: 0.8654 - val_acc: 0.0100 - val_f1_m: 0.9961 - val_precision_m: 0.9922 - val_recall_m: 1.0000\n",
      "Epoch 2/32\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.8532 - acc: 0.0025 - f1_m: 0.9989 - precision_m: 0.9978 - recall_m: 1.0000 - val_loss: 0.8365 - val_acc: 0.0100 - val_f1_m: 0.9961 - val_precision_m: 0.9922 - val_recall_m: 1.0000\n",
      "Epoch 3/32\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.8259 - acc: 0.0025 - f1_m: 0.9989 - precision_m: 0.9978 - recall_m: 1.0000 - val_loss: 0.8116 - val_acc: 0.0100 - val_f1_m: 0.9961 - val_precision_m: 0.9922 - val_recall_m: 1.0000\n",
      "Epoch 4/32\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.8026 - acc: 0.0025 - f1_m: 0.9989 - precision_m: 0.9978 - recall_m: 1.0000 - val_loss: 0.7904 - val_acc: 0.0100 - val_f1_m: 0.9961 - val_precision_m: 0.9922 - val_recall_m: 1.0000\n",
      "Epoch 5/32\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.7828 - acc: 0.0025 - f1_m: 0.9989 - precision_m: 0.9978 - recall_m: 1.0000 - val_loss: 0.7727 - val_acc: 0.0100 - val_f1_m: 0.9961 - val_precision_m: 0.9922 - val_recall_m: 1.0000\n",
      "Epoch 6/32\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.7663 - acc: 0.0025 - f1_m: 0.9989 - precision_m: 0.9978 - recall_m: 1.0000 - val_loss: 0.7579 - val_acc: 0.0100 - val_f1_m: 0.9961 - val_precision_m: 0.9922 - val_recall_m: 1.0000\n",
      "Epoch 7/32\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.7526 - acc: 0.0025 - f1_m: 0.9989 - precision_m: 0.9978 - recall_m: 1.0000 - val_loss: 0.7457 - val_acc: 0.0100 - val_f1_m: 0.9961 - val_precision_m: 0.9922 - val_recall_m: 1.0000\n",
      "Epoch 8/32\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.7414 - acc: 0.0025 - f1_m: 0.9989 - precision_m: 0.9978 - recall_m: 1.0000 - val_loss: 0.7357 - val_acc: 0.0100 - val_f1_m: 0.9961 - val_precision_m: 0.9922 - val_recall_m: 1.0000\n",
      "Epoch 9/32\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.7321 - acc: 0.0025 - f1_m: 0.9989 - precision_m: 0.9978 - recall_m: 1.0000 - val_loss: 0.7274 - val_acc: 0.0100 - val_f1_m: 0.9961 - val_precision_m: 0.9922 - val_recall_m: 1.0000\n",
      "Epoch 10/32\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.7245 - acc: 0.0025 - f1_m: 0.9989 - precision_m: 0.9978 - recall_m: 1.0000 - val_loss: 0.7207 - val_acc: 0.0100 - val_f1_m: 0.9961 - val_precision_m: 0.9922 - val_recall_m: 1.0000\n",
      "Epoch 11/32\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.7183 - acc: 0.0025 - f1_m: 0.9989 - precision_m: 0.9978 - recall_m: 1.0000 - val_loss: 0.7152 - val_acc: 0.0100 - val_f1_m: 0.9961 - val_precision_m: 0.9922 - val_recall_m: 1.0000\n",
      "Epoch 12/32\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.7132 - acc: 0.0025 - f1_m: 0.9989 - precision_m: 0.9978 - recall_m: 1.0000 - val_loss: 0.7107 - val_acc: 0.0100 - val_f1_m: 0.9961 - val_precision_m: 0.9922 - val_recall_m: 1.0000\n",
      "Epoch 13/32\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.7091 - acc: 0.0025 - f1_m: 0.9989 - precision_m: 0.9978 - recall_m: 1.0000 - val_loss: 0.7071 - val_acc: 0.0100 - val_f1_m: 0.9961 - val_precision_m: 0.9922 - val_recall_m: 1.0000\n",
      "Epoch 14/32\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.7057 - acc: 0.0025 - f1_m: 0.9989 - precision_m: 0.9978 - recall_m: 1.0000 - val_loss: 0.7041 - val_acc: 0.0100 - val_f1_m: 0.9961 - val_precision_m: 0.9922 - val_recall_m: 1.0000\n",
      "Epoch 15/32\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.7030 - acc: 0.0025 - f1_m: 0.9989 - precision_m: 0.9978 - recall_m: 1.0000 - val_loss: 0.7017 - val_acc: 0.0100 - val_f1_m: 0.9961 - val_precision_m: 0.9922 - val_recall_m: 1.0000\n",
      "Epoch 16/32\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.7009 - acc: 0.0025 - f1_m: 0.9989 - precision_m: 0.9978 - recall_m: 1.0000 - val_loss: 0.6998 - val_acc: 0.0100 - val_f1_m: 0.9961 - val_precision_m: 0.9922 - val_recall_m: 1.0000\n",
      "Epoch 17/32\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6991 - acc: 0.0025 - f1_m: 0.9989 - precision_m: 0.9978 - recall_m: 1.0000 - val_loss: 0.6983 - val_acc: 0.0100 - val_f1_m: 0.9961 - val_precision_m: 0.9922 - val_recall_m: 1.0000\n",
      "Epoch 18/32\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6978 - acc: 0.0025 - f1_m: 0.9989 - precision_m: 0.9978 - recall_m: 1.0000 - val_loss: 0.6971 - val_acc: 0.0100 - val_f1_m: 0.9961 - val_precision_m: 0.9922 - val_recall_m: 1.0000\n",
      "Epoch 19/32\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6967 - acc: 0.0025 - f1_m: 0.9989 - precision_m: 0.9978 - recall_m: 1.0000 - val_loss: 0.6962 - val_acc: 0.0100 - val_f1_m: 0.9961 - val_precision_m: 0.9922 - val_recall_m: 1.0000\n",
      "Epoch 20/32\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6958 - acc: 0.0025 - f1_m: 0.9989 - precision_m: 0.9978 - recall_m: 1.0000 - val_loss: 0.6954 - val_acc: 0.0100 - val_f1_m: 0.9961 - val_precision_m: 0.9922 - val_recall_m: 1.0000\n",
      "Epoch 21/32\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6952 - acc: 0.0025 - f1_m: 0.9989 - precision_m: 0.9978 - recall_m: 1.0000 - val_loss: 0.6949 - val_acc: 0.0100 - val_f1_m: 0.9961 - val_precision_m: 0.9922 - val_recall_m: 1.0000\n",
      "Epoch 22/32\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6947 - acc: 0.0025 - f1_m: 0.9989 - precision_m: 0.9978 - recall_m: 1.0000 - val_loss: 0.6944 - val_acc: 0.0100 - val_f1_m: 0.9961 - val_precision_m: 0.9922 - val_recall_m: 1.0000\n",
      "Epoch 23/32\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6943 - acc: 0.0025 - f1_m: 0.9989 - precision_m: 0.9978 - recall_m: 1.0000 - val_loss: 0.6941 - val_acc: 0.0100 - val_f1_m: 0.9961 - val_precision_m: 0.9922 - val_recall_m: 1.0000\n",
      "Epoch 24/32\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6940 - acc: 0.0025 - f1_m: 0.9989 - precision_m: 0.9978 - recall_m: 1.0000 - val_loss: 0.6938 - val_acc: 0.0100 - val_f1_m: 0.9961 - val_precision_m: 0.9922 - val_recall_m: 1.0000\n",
      "Epoch 25/32\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6937 - acc: 0.0025 - f1_m: 0.9989 - precision_m: 0.9978 - recall_m: 1.0000 - val_loss: 0.6936 - val_acc: 0.0100 - val_f1_m: 0.9961 - val_precision_m: 0.9922 - val_recall_m: 1.0000\n",
      "Epoch 26/32\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6936 - acc: 0.0075 - f1_m: 0.9989 - precision_m: 0.9978 - recall_m: 1.0000 - val_loss: 0.6935 - val_acc: 0.0100 - val_f1_m: 0.9961 - val_precision_m: 0.9922 - val_recall_m: 1.0000\n",
      "Epoch 27/32\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6935 - acc: 0.0100 - f1_m: 0.9989 - precision_m: 0.9978 - recall_m: 1.0000 - val_loss: 0.6934 - val_acc: 0.0100 - val_f1_m: 0.9961 - val_precision_m: 0.9922 - val_recall_m: 1.0000\n",
      "Epoch 28/32\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6934 - acc: 0.0175 - f1_m: 0.9954 - precision_m: 0.9911 - recall_m: 1.0000 - val_loss: 0.6933 - val_acc: 0.0100 - val_f1_m: 0.9961 - val_precision_m: 0.9922 - val_recall_m: 1.0000\n",
      "Epoch 29/32\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6933 - acc: 0.0225 - f1_m: 0.9989 - precision_m: 0.9978 - recall_m: 1.0000 - val_loss: 0.6933 - val_acc: 0.0300 - val_f1_m: 0.9961 - val_precision_m: 0.9922 - val_recall_m: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/32\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6933 - acc: 0.0400 - f1_m: 0.9989 - precision_m: 0.9978 - recall_m: 1.0000 - val_loss: 0.6932 - val_acc: 0.0300 - val_f1_m: 0.9961 - val_precision_m: 0.9922 - val_recall_m: 1.0000\n",
      "Epoch 31/32\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6932 - acc: 0.0600 - f1_m: 0.9989 - precision_m: 0.9978 - recall_m: 1.0000 - val_loss: 0.6932 - val_acc: 0.0500 - val_f1_m: 0.9961 - val_precision_m: 0.9922 - val_recall_m: 1.0000\n",
      "Epoch 32/32\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6932 - acc: 0.0775 - f1_m: 0.9989 - precision_m: 0.9978 - recall_m: 1.0000 - val_loss: 0.6932 - val_acc: 0.0500 - val_f1_m: 0.9961 - val_precision_m: 0.9922 - val_recall_m: 1.0000\n"
     ]
    }
   ],
   "source": [
    "print('Joint full model with one hot encoding, predicting deception')\n",
    "joint_full_model = create_joint_model(pred_df_full)\n",
    "joint_full_model.summary()\n",
    "history = joint_full_model.fit(x=pred_df_full, y=y_train_deception, epochs=32, \n",
    "                    batch_size=64, \n",
    "                    validation_data=(pred_test_df_full,y_test_deception), callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5052083333333334, 0.5202020202020202, 0.049144229806826145, None)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joint_predict = joint_full_model.predict(pred_test_df_full)\n",
    "joint_predict_round = []\n",
    "for a in joint_predict:\n",
    "    joint_predict_round.append([np.argmax(a)])\n",
    "precision_recall_fscore_support(y_test_deception, np.array(joint_predict_round), average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joint full model with one hot encoding, predicting rapport\n",
      "Model: \"functional_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 3)]               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 8         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 4)                 12        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2)                 10        \n",
      "=================================================================\n",
      "Total params: 30\n",
      "Trainable params: 30\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/32\n",
      "7/7 [==============================] - 0s 37ms/step - loss: 0.9949 - acc: 0.8750 - f1_m: 0.9329 - precision_m: 0.8750 - recall_m: 1.0000 - val_loss: 0.9730 - val_acc: 0.8000 - val_f1_m: 0.8858 - val_precision_m: 0.7951 - val_recall_m: 1.0000\n",
      "Epoch 2/32\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.9574 - acc: 0.8750 - f1_m: 0.9402 - precision_m: 0.8884 - recall_m: 1.0000 - val_loss: 0.9373 - val_acc: 0.8000 - val_f1_m: 0.8858 - val_precision_m: 0.7951 - val_recall_m: 1.0000\n",
      "Epoch 3/32\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.9231 - acc: 0.8750 - f1_m: 0.9331 - precision_m: 0.8750 - recall_m: 1.0000 - val_loss: 0.9047 - val_acc: 0.8000 - val_f1_m: 0.8858 - val_precision_m: 0.7951 - val_recall_m: 1.0000\n",
      "Epoch 4/32\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.8920 - acc: 0.8750 - f1_m: 0.9330 - precision_m: 0.8750 - recall_m: 1.0000 - val_loss: 0.8755 - val_acc: 0.8000 - val_f1_m: 0.8858 - val_precision_m: 0.7951 - val_recall_m: 1.0000\n",
      "Epoch 5/32\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.8642 - acc: 0.8750 - f1_m: 0.9331 - precision_m: 0.8750 - recall_m: 1.0000 - val_loss: 0.8496 - val_acc: 0.8000 - val_f1_m: 0.8858 - val_precision_m: 0.7951 - val_recall_m: 1.0000\n",
      "Epoch 6/32\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.8396 - acc: 0.8750 - f1_m: 0.9329 - precision_m: 0.8750 - recall_m: 1.0000 - val_loss: 0.8268 - val_acc: 0.8000 - val_f1_m: 0.8858 - val_precision_m: 0.7951 - val_recall_m: 1.0000\n",
      "Epoch 7/32\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.8180 - acc: 0.8750 - f1_m: 0.9287 - precision_m: 0.8683 - recall_m: 1.0000 - val_loss: 0.8069 - val_acc: 0.8000 - val_f1_m: 0.8858 - val_precision_m: 0.7951 - val_recall_m: 1.0000\n",
      "Epoch 8/32\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.7992 - acc: 0.8750 - f1_m: 0.9291 - precision_m: 0.8683 - recall_m: 1.0000 - val_loss: 0.7896 - val_acc: 0.8000 - val_f1_m: 0.8858 - val_precision_m: 0.7951 - val_recall_m: 1.0000\n",
      "Epoch 9/32\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.7830 - acc: 0.8750 - f1_m: 0.9326 - precision_m: 0.8750 - recall_m: 1.0000 - val_loss: 0.7747 - val_acc: 0.8000 - val_f1_m: 0.8858 - val_precision_m: 0.7951 - val_recall_m: 1.0000\n",
      "Epoch 10/32\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.7689 - acc: 0.8750 - f1_m: 0.9290 - precision_m: 0.8683 - recall_m: 1.0000 - val_loss: 0.7618 - val_acc: 0.8000 - val_f1_m: 0.8858 - val_precision_m: 0.7951 - val_recall_m: 1.0000\n",
      "Epoch 11/32\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.7569 - acc: 0.8750 - f1_m: 0.9290 - precision_m: 0.8683 - recall_m: 1.0000 - val_loss: 0.7509 - val_acc: 0.8000 - val_f1_m: 0.8858 - val_precision_m: 0.7951 - val_recall_m: 1.0000\n",
      "Epoch 12/32\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.7466 - acc: 0.8750 - f1_m: 0.9402 - precision_m: 0.8884 - recall_m: 1.0000 - val_loss: 0.7415 - val_acc: 0.8000 - val_f1_m: 0.8858 - val_precision_m: 0.7951 - val_recall_m: 1.0000\n",
      "Epoch 13/32\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.7379 - acc: 0.8750 - f1_m: 0.9331 - precision_m: 0.8750 - recall_m: 1.0000 - val_loss: 0.7335 - val_acc: 0.8000 - val_f1_m: 0.8858 - val_precision_m: 0.7951 - val_recall_m: 1.0000\n",
      "Epoch 14/32\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.7305 - acc: 0.8750 - f1_m: 0.9293 - precision_m: 0.8683 - recall_m: 1.0000 - val_loss: 0.7268 - val_acc: 0.8000 - val_f1_m: 0.8858 - val_precision_m: 0.7951 - val_recall_m: 1.0000\n",
      "Epoch 15/32\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.7242 - acc: 0.8750 - f1_m: 0.9201 - precision_m: 0.8549 - recall_m: 1.0000 - val_loss: 0.7211 - val_acc: 0.8000 - val_f1_m: 0.8858 - val_precision_m: 0.7951 - val_recall_m: 1.0000\n",
      "Epoch 16/32\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.7189 - acc: 0.8750 - f1_m: 0.9365 - precision_m: 0.8817 - recall_m: 1.0000 - val_loss: 0.7163 - val_acc: 0.8000 - val_f1_m: 0.8858 - val_precision_m: 0.7951 - val_recall_m: 1.0000\n",
      "Epoch 17/32\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.7144 - acc: 0.8750 - f1_m: 0.9330 - precision_m: 0.8750 - recall_m: 1.0000 - val_loss: 0.7122 - val_acc: 0.8000 - val_f1_m: 0.8858 - val_precision_m: 0.7951 - val_recall_m: 1.0000\n",
      "Epoch 18/32\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.7107 - acc: 0.8750 - f1_m: 0.9367 - precision_m: 0.8817 - recall_m: 1.0000 - val_loss: 0.7089 - val_acc: 0.8000 - val_f1_m: 0.8858 - val_precision_m: 0.7951 - val_recall_m: 1.0000\n",
      "Epoch 19/32\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.7075 - acc: 0.8750 - f1_m: 0.9331 - precision_m: 0.8750 - recall_m: 1.0000 - val_loss: 0.7060 - val_acc: 0.8000 - val_f1_m: 0.8858 - val_precision_m: 0.7951 - val_recall_m: 1.0000\n",
      "Epoch 20/32\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.7049 - acc: 0.8750 - f1_m: 0.9330 - precision_m: 0.8750 - recall_m: 1.0000 - val_loss: 0.7037 - val_acc: 0.8000 - val_f1_m: 0.8858 - val_precision_m: 0.7951 - val_recall_m: 1.0000\n",
      "Epoch 21/32\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.7027 - acc: 0.8750 - f1_m: 0.9363 - precision_m: 0.8817 - recall_m: 1.0000 - val_loss: 0.7017 - val_acc: 0.8000 - val_f1_m: 0.8858 - val_precision_m: 0.7951 - val_recall_m: 1.0000\n",
      "Epoch 22/32\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.7009 - acc: 0.8750 - f1_m: 0.9327 - precision_m: 0.8750 - recall_m: 1.0000 - val_loss: 0.7001 - val_acc: 0.8000 - val_f1_m: 0.8858 - val_precision_m: 0.7951 - val_recall_m: 1.0000\n",
      "Epoch 23/32\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6994 - acc: 0.8750 - f1_m: 0.9397 - precision_m: 0.8884 - recall_m: 1.0000 - val_loss: 0.6988 - val_acc: 0.8000 - val_f1_m: 0.8858 - val_precision_m: 0.7951 - val_recall_m: 1.0000\n",
      "Epoch 24/32\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6982 - acc: 0.8750 - f1_m: 0.9330 - precision_m: 0.8750 - recall_m: 1.0000 - val_loss: 0.6977 - val_acc: 0.8000 - val_f1_m: 0.8858 - val_precision_m: 0.7951 - val_recall_m: 1.0000\n",
      "Epoch 25/32\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6972 - acc: 0.8750 - f1_m: 0.9288 - precision_m: 0.8683 - recall_m: 1.0000 - val_loss: 0.6968 - val_acc: 0.8000 - val_f1_m: 0.8858 - val_precision_m: 0.7951 - val_recall_m: 1.0000\n",
      "Epoch 26/32\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6964 - acc: 0.8750 - f1_m: 0.9239 - precision_m: 0.8616 - recall_m: 1.0000 - val_loss: 0.6960 - val_acc: 0.8000 - val_f1_m: 0.8858 - val_precision_m: 0.7951 - val_recall_m: 1.0000\n",
      "Epoch 27/32\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6957 - acc: 0.8750 - f1_m: 0.9368 - precision_m: 0.8817 - recall_m: 1.0000 - val_loss: 0.6955 - val_acc: 0.8000 - val_f1_m: 0.8858 - val_precision_m: 0.7951 - val_recall_m: 1.0000\n",
      "Epoch 28/32\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6952 - acc: 0.8750 - f1_m: 0.9366 - precision_m: 0.8817 - recall_m: 1.0000 - val_loss: 0.6950 - val_acc: 0.8000 - val_f1_m: 0.8858 - val_precision_m: 0.7951 - val_recall_m: 1.0000\n",
      "Epoch 29/32\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6948 - acc: 0.8750 - f1_m: 0.9332 - precision_m: 0.8750 - recall_m: 1.0000 - val_loss: 0.6946 - val_acc: 0.8000 - val_f1_m: 0.8858 - val_precision_m: 0.7951 - val_recall_m: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/32\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6944 - acc: 0.8750 - f1_m: 0.9249 - precision_m: 0.8616 - recall_m: 1.0000 - val_loss: 0.6943 - val_acc: 0.8000 - val_f1_m: 0.8858 - val_precision_m: 0.7951 - val_recall_m: 1.0000\n",
      "Epoch 31/32\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6941 - acc: 0.8750 - f1_m: 0.9367 - precision_m: 0.8817 - recall_m: 1.0000 - val_loss: 0.6940 - val_acc: 0.8000 - val_f1_m: 0.8858 - val_precision_m: 0.7951 - val_recall_m: 1.0000\n",
      "Epoch 32/32\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6939 - acc: 0.8750 - f1_m: 0.9197 - precision_m: 0.8549 - recall_m: 1.0000 - val_loss: 0.6938 - val_acc: 0.8000 - val_f1_m: 0.8858 - val_precision_m: 0.7951 - val_recall_m: 1.0000\n"
     ]
    }
   ],
   "source": [
    "print('Joint full model with one hot encoding, predicting rapport')\n",
    "joint_full_model = create_joint_model(pred_df)\n",
    "joint_full_model.summary()\n",
    "history = joint_full_model.fit(x=pred_df, y=y_train_rapport, epochs=32, \n",
    "                    batch_size=64, \n",
    "                    validation_data=(pred_test_df,y_test_rapport), callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lynne\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4, 0.5, 0.4444444444444445, None)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joint_predict = joint_full_model.predict(pred_test_df)\n",
    "joint_predict_round = []\n",
    "for a in joint_predict:\n",
    "    joint_predict_round.append([np.argmax(a)])\n",
    "precision_recall_fscore_support(y_test_rapport, np.array(joint_predict_round), average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joint Model by Keras Concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_concatenate_keras_model(models_arr):\n",
    "    commonInput = Input(shape=[max_len])\n",
    "\n",
    "    input_model_arr = []\n",
    "    for model in models_arr: \n",
    "        outmodel = model(commonInput)\n",
    "        input_model_arr.append(outmodel)\n",
    "    \n",
    "    mergedOut = Concatenate()(input_model_arr)\n",
    "\n",
    "    mergedOut = Flatten()(mergedOut)    \n",
    "    mergedOut = Dense(256, activation='relu')(mergedOut)\n",
    "    mergedOut = Dropout(.5)(mergedOut)\n",
    "    mergedOut = Dense(128, activation='relu')(mergedOut)\n",
    "    mergedOut = Dropout(.35)(mergedOut)\n",
    "    mergedOut = Dense(2, activation='softmax')(mergedOut)  #Cuz binary\n",
    "\n",
    "    mergedModel = Model(commonInput, mergedOut)\n",
    "    mergedModel.compile(loss='binary_crossentropy', optimizer=RMSprop(), metrics=['accuracy', f1_m, recall_m, precision_m])\n",
    "    \n",
    "    return mergedModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joint model by concatenate, predicting deception\n",
      "Epoch 1/15\n",
      "72/72 [==============================] - 6s 80ms/step - loss: 0.6942 - accuracy: 0.5033 - f1_m: 0.9751 - recall_m: 1.0000 - precision_m: 0.9517 - val_loss: 0.6931 - val_accuracy: 0.9503 - val_f1_m: 0.9744 - val_recall_m: 1.0000 - val_precision_m: 0.9502\n",
      "Epoch 2/15\n",
      "72/72 [==============================] - 5s 68ms/step - loss: 0.6931 - accuracy: 0.5021 - f1_m: 0.9732 - recall_m: 0.9999 - precision_m: 0.9483 - val_loss: 0.6931 - val_accuracy: 0.9503 - val_f1_m: 0.9744 - val_recall_m: 1.0000 - val_precision_m: 0.9502\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff3d45f0518>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Joint model by concatenate, predicting deception')\n",
    "merged_model = create_concatenate_keras_model([gamemove_model, reasoning_model, shareinfo_model, rapport_model])\n",
    "merged_model.fit(X_train,y_train_deception,\n",
    "          batch_size=128,\n",
    "          epochs=15,\n",
    "          validation_data=(X_test,y_test_deception), callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joint model by concatenate, predicting rapport\n",
      "Epoch 1/15\n",
      "72/72 [==============================] - 4s 62ms/step - loss: 0.6932 - accuracy: 0.4965 - f1_m: 0.9278 - recall_m: 1.0000 - precision_m: 0.8660 - val_loss: 0.6931 - val_accuracy: 0.8562 - val_f1_m: 0.9223 - val_recall_m: 1.0000 - val_precision_m: 0.8563\n",
      "Epoch 2/15\n",
      "72/72 [==============================] - 4s 52ms/step - loss: 0.6931 - accuracy: 0.5045 - f1_m: 0.9279 - recall_m: 1.0000 - precision_m: 0.8660 - val_loss: 0.6931 - val_accuracy: 0.8562 - val_f1_m: 0.9223 - val_recall_m: 1.0000 - val_precision_m: 0.8563\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff3bc1b26a0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Joint model by concatenate, predicting rapport')\n",
    "merged_model = create_concatenate_keras_model([gamemove_model, reasoning_model, shareinfo_model])\n",
    "merged_model.fit(X_train,y_train_rapport,\n",
    "          batch_size=128,\n",
    "          epochs=15,\n",
    "          validation_data=(X_test,y_test_rapport), callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weighted against Throughput & WorkTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train weighted encodings\n",
    "pred_df_full_throughput = pred_df_full.copy()\n",
    "pred_df_full_worktime = pred_df_full.copy()\n",
    "pred_df_throughput = pred_df.copy()\n",
    "pred_df_worktime = pred_df.copy()\n",
    "\n",
    "throughput_values = df_throughput['avg_throughput'].take(indices_train).values\n",
    "pred_df_full_throughput = pred_df_full_throughput.mul(throughput_values, axis=0)\n",
    "pred_df_throughput = pred_df_throughput.mul(throughput_values, axis=0)\n",
    "\n",
    "worktime_values = df_worktime['avg_worktime'].take(indices_train).values\n",
    "pred_df_full_worktime = pred_df_full_worktime.mul(worktime_values, axis=0)\n",
    "pred_df_worktime = pred_df_worktime.mul(worktime_values, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test weighted encodings\n",
    "pred_df_full_throughput_test = pred_test_df_full.copy()\n",
    "pred_df_full_worktime_test = pred_test_df_full.copy()\n",
    "pred_df_throughput_test = pred_test_df.copy()\n",
    "pred_df_worktime_test = pred_test_df.copy()\n",
    "\n",
    "throughput_values_test = df_throughput['avg_throughput'].take(indices_test).values\n",
    "pred_df_full_throughput_test = pred_df_full_throughput_test.mul(throughput_values_test, axis=0)\n",
    "pred_df_throughput_test = pred_df_throughput_test.mul(throughput_values_test, axis=0)\n",
    "\n",
    "worktime_values_test = df_worktime['avg_worktime'].take(indices_test).values\n",
    "pred_df_full_worktime_test = pred_df_full_worktime_test.mul(worktime_values_test, axis=0)\n",
    "pred_df_worktime_test = pred_df_worktime_test.mul(worktime_values_test, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Throughput only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joint Model with one hot encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_joint_model(df):\n",
    "    inputB = Input(shape=(df.shape[1],))\n",
    "    c = Dense(2, activation='relu')(inputB)\n",
    "    c = Dense(4, activation='relu')(c)\n",
    "    c = Dense(2, activation='softmax')(c)\n",
    "    full_model = Model(inputs=inputB, outputs=c)\n",
    "\n",
    "    full_model.compile(loss='binary_crossentropy', optimizer='adam', \n",
    "                          metrics=['acc',f1_m,precision_m, recall_m])\n",
    "    \n",
    "    return full_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joint full model with one hot encoding, predicting deception, weighted by throughput\n",
      "Model: \"functional_25\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_8 (InputLayer)         [(None, 4)]               0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 4)                 12        \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 2)                 10        \n",
      "=================================================================\n",
      "Total params: 32\n",
      "Trainable params: 32\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/32\n",
      "7/7 [==============================] - 0s 36ms/step - loss: 0.6936 - acc: 0.9875 - f1_m: 0.9978 - precision_m: 0.9955 - recall_m: 1.0000 - val_loss: 0.6934 - val_acc: 0.1000 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 2/32\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6933 - acc: 0.7875 - f1_m: 0.9978 - precision_m: 0.9955 - recall_m: 1.0000 - val_loss: 0.6932 - val_acc: 0.3300 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 3/32\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6932 - acc: 0.5250 - f1_m: 0.9978 - precision_m: 0.9955 - recall_m: 1.0000 - val_loss: 0.6932 - val_acc: 0.5800 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 4/32\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6932 - acc: 0.3400 - f1_m: 0.9978 - precision_m: 0.9955 - recall_m: 1.0000 - val_loss: 0.6932 - val_acc: 0.6800 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "print('Joint full model with one hot encoding, predicting deception, weighted by throughput')\n",
    "joint_full_model = create_joint_model(pred_df_full_throughput)\n",
    "joint_full_model.summary()\n",
    "history = joint_full_model.fit(x=pred_df_full_throughput, y=y_train_deception, epochs=32, \n",
    "                    batch_size=64, \n",
    "                    validation_data=(pred_df_full_throughput_test,y_test_deception), callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lynne\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5, 0.34, 0.40476190476190477, None)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joint_predict = joint_full_model.predict(pred_df_full_throughput_test)\n",
    "joint_predict_round = []\n",
    "for a in joint_predict:\n",
    "    joint_predict_round.append([np.argmax(a)])\n",
    "precision_recall_fscore_support(y_test_deception, np.array(joint_predict_round), average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_rapport = np.asarray(y_test_rapport)\n",
    "y_train_rapport = np.asarray(y_train_rapport)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joint full model with one hot encoding, predicting rapport, weighted by throughput\n",
      "Model: \"functional_31\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_11 (InputLayer)        [(None, 3)]               0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 2)                 8         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 4)                 12        \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 2)                 10        \n",
      "=================================================================\n",
      "Total params: 30\n",
      "Trainable params: 30\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/32\n",
      "7/7 [==============================] - 0s 36ms/step - loss: 0.6969 - acc: 0.1425 - f1_m: 0.9277 - precision_m: 0.8661 - recall_m: 1.0000 - val_loss: 0.6963 - val_acc: 0.1300 - val_f1_m: 0.9328 - val_precision_m: 0.8741 - val_recall_m: 1.0000\n",
      "Epoch 2/32\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6958 - acc: 0.1550 - f1_m: 0.9274 - precision_m: 0.8661 - recall_m: 1.0000 - val_loss: 0.6953 - val_acc: 0.1800 - val_f1_m: 0.9328 - val_precision_m: 0.8741 - val_recall_m: 1.0000\n",
      "Epoch 3/32\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6949 - acc: 0.2000 - f1_m: 0.9154 - precision_m: 0.8460 - recall_m: 1.0000 - val_loss: 0.6946 - val_acc: 0.2500 - val_f1_m: 0.9328 - val_precision_m: 0.8741 - val_recall_m: 1.0000\n",
      "Epoch 4/32\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6943 - acc: 0.2800 - f1_m: 0.9242 - precision_m: 0.8594 - recall_m: 1.0000 - val_loss: 0.6941 - val_acc: 0.3300 - val_f1_m: 0.9328 - val_precision_m: 0.8741 - val_recall_m: 1.0000\n",
      "Epoch 5/32\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6940 - acc: 0.3475 - f1_m: 0.9275 - precision_m: 0.8661 - recall_m: 1.0000 - val_loss: 0.6938 - val_acc: 0.3900 - val_f1_m: 0.9328 - val_precision_m: 0.8741 - val_recall_m: 1.0000\n",
      "Epoch 6/32\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6937 - acc: 0.4125 - f1_m: 0.9198 - precision_m: 0.8527 - recall_m: 1.0000 - val_loss: 0.6937 - val_acc: 0.4400 - val_f1_m: 0.9328 - val_precision_m: 0.8741 - val_recall_m: 1.0000\n",
      "Epoch 7/32\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6936 - acc: 0.4675 - f1_m: 0.9157 - precision_m: 0.8460 - recall_m: 1.0000 - val_loss: 0.6936 - val_acc: 0.5100 - val_f1_m: 0.9328 - val_precision_m: 0.8741 - val_recall_m: 1.0000\n",
      "Epoch 8/32\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6935 - acc: 0.5375 - f1_m: 0.9277 - precision_m: 0.8661 - recall_m: 1.0000 - val_loss: 0.6935 - val_acc: 0.5400 - val_f1_m: 0.9328 - val_precision_m: 0.8741 - val_recall_m: 1.0000\n",
      "Epoch 9/32\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6935 - acc: 0.5725 - f1_m: 0.9112 - precision_m: 0.8393 - recall_m: 1.0000 - val_loss: 0.6935 - val_acc: 0.5600 - val_f1_m: 0.9328 - val_precision_m: 0.8741 - val_recall_m: 1.0000\n",
      "Epoch 10/32\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6935 - acc: 0.5850 - f1_m: 0.9234 - precision_m: 0.8594 - recall_m: 1.0000 - val_loss: 0.6935 - val_acc: 0.5600 - val_f1_m: 0.9328 - val_precision_m: 0.8741 - val_recall_m: 1.0000\n",
      "Epoch 11/32\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6935 - acc: 0.6000 - f1_m: 0.9156 - precision_m: 0.8460 - recall_m: 1.0000 - val_loss: 0.6935 - val_acc: 0.5700 - val_f1_m: 0.9328 - val_precision_m: 0.8741 - val_recall_m: 1.0000\n",
      "Epoch 12/32\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6935 - acc: 0.6125 - f1_m: 0.9274 - precision_m: 0.8661 - recall_m: 1.0000 - val_loss: 0.6935 - val_acc: 0.5800 - val_f1_m: 0.9328 - val_precision_m: 0.8741 - val_recall_m: 1.0000\n",
      "Epoch 13/32\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6935 - acc: 0.6125 - f1_m: 0.9238 - precision_m: 0.8594 - recall_m: 1.0000 - val_loss: 0.6935 - val_acc: 0.5900 - val_f1_m: 0.9328 - val_precision_m: 0.8741 - val_recall_m: 1.0000\n",
      "Epoch 14/32\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6935 - acc: 0.6125 - f1_m: 0.9104 - precision_m: 0.8393 - recall_m: 1.0000 - val_loss: 0.6935 - val_acc: 0.5800 - val_f1_m: 0.9328 - val_precision_m: 0.8741 - val_recall_m: 1.0000\n",
      "Epoch 15/32\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6935 - acc: 0.6125 - f1_m: 0.9195 - precision_m: 0.8527 - recall_m: 1.0000 - val_loss: 0.6935 - val_acc: 0.5800 - val_f1_m: 0.9328 - val_precision_m: 0.8741 - val_recall_m: 1.0000\n",
      "Epoch 16/32\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6935 - acc: 0.6100 - f1_m: 0.9158 - precision_m: 0.8460 - recall_m: 1.0000 - val_loss: 0.6935 - val_acc: 0.5600 - val_f1_m: 0.9328 - val_precision_m: 0.8741 - val_recall_m: 1.0000\n",
      "Epoch 17/32\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6934 - acc: 0.6025 - f1_m: 0.9199 - precision_m: 0.8527 - recall_m: 1.0000 - val_loss: 0.6935 - val_acc: 0.5600 - val_f1_m: 0.9328 - val_precision_m: 0.8741 - val_recall_m: 1.0000\n",
      "Epoch 18/32\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6934 - acc: 0.6000 - f1_m: 0.9241 - precision_m: 0.8594 - recall_m: 1.0000 - val_loss: 0.6934 - val_acc: 0.5600 - val_f1_m: 0.9328 - val_precision_m: 0.8741 - val_recall_m: 1.0000\n",
      "Epoch 19/32\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6934 - acc: 0.6000 - f1_m: 0.9192 - precision_m: 0.8527 - recall_m: 1.0000 - val_loss: 0.6934 - val_acc: 0.5600 - val_f1_m: 0.9328 - val_precision_m: 0.8741 - val_recall_m: 1.0000\n",
      "Epoch 20/32\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6934 - acc: 0.6000 - f1_m: 0.9307 - precision_m: 0.8728 - recall_m: 1.0000 - val_loss: 0.6934 - val_acc: 0.5600 - val_f1_m: 0.9328 - val_precision_m: 0.8741 - val_recall_m: 1.0000\n",
      "Epoch 21/32\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6934 - acc: 0.6000 - f1_m: 0.9240 - precision_m: 0.8594 - recall_m: 1.0000 - val_loss: 0.6934 - val_acc: 0.5600 - val_f1_m: 0.9328 - val_precision_m: 0.8741 - val_recall_m: 1.0000\n",
      "Epoch 22/32\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6934 - acc: 0.6000 - f1_m: 0.9156 - precision_m: 0.8460 - recall_m: 1.0000 - val_loss: 0.6934 - val_acc: 0.5600 - val_f1_m: 0.9328 - val_precision_m: 0.8741 - val_recall_m: 1.0000\n",
      "Epoch 23/32\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6934 - acc: 0.6000 - f1_m: 0.9199 - precision_m: 0.8527 - recall_m: 1.0000 - val_loss: 0.6934 - val_acc: 0.5600 - val_f1_m: 0.9328 - val_precision_m: 0.8741 - val_recall_m: 1.0000\n",
      "Epoch 24/32\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6934 - acc: 0.6025 - f1_m: 0.9144 - precision_m: 0.8460 - recall_m: 1.0000 - val_loss: 0.6934 - val_acc: 0.5600 - val_f1_m: 0.9328 - val_precision_m: 0.8741 - val_recall_m: 1.0000\n",
      "Epoch 25/32\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6934 - acc: 0.6025 - f1_m: 0.9159 - precision_m: 0.8460 - recall_m: 1.0000 - val_loss: 0.6934 - val_acc: 0.5600 - val_f1_m: 0.9328 - val_precision_m: 0.8741 - val_recall_m: 1.0000\n",
      "Epoch 26/32\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6934 - acc: 0.6000 - f1_m: 0.9304 - precision_m: 0.8728 - recall_m: 1.0000 - val_loss: 0.6934 - val_acc: 0.5600 - val_f1_m: 0.9328 - val_precision_m: 0.8741 - val_recall_m: 1.0000\n",
      "Epoch 27/32\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6934 - acc: 0.6025 - f1_m: 0.9241 - precision_m: 0.8594 - recall_m: 1.0000 - val_loss: 0.6934 - val_acc: 0.5600 - val_f1_m: 0.9328 - val_precision_m: 0.8741 - val_recall_m: 1.0000\n",
      "Epoch 28/32\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6934 - acc: 0.6025 - f1_m: 0.9198 - precision_m: 0.8527 - recall_m: 1.0000 - val_loss: 0.6934 - val_acc: 0.5600 - val_f1_m: 0.9328 - val_precision_m: 0.8741 - val_recall_m: 1.0000\n",
      "Epoch 29/32\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6934 - acc: 0.6025 - f1_m: 0.9201 - precision_m: 0.8527 - recall_m: 1.0000 - val_loss: 0.6934 - val_acc: 0.5600 - val_f1_m: 0.9328 - val_precision_m: 0.8741 - val_recall_m: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/32\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6934 - acc: 0.6000 - f1_m: 0.9242 - precision_m: 0.8594 - recall_m: 1.0000 - val_loss: 0.6934 - val_acc: 0.5600 - val_f1_m: 0.9328 - val_precision_m: 0.8741 - val_recall_m: 1.0000\n",
      "Epoch 31/32\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6934 - acc: 0.6000 - f1_m: 0.9273 - precision_m: 0.8661 - recall_m: 1.0000 - val_loss: 0.6934 - val_acc: 0.5600 - val_f1_m: 0.9328 - val_precision_m: 0.8741 - val_recall_m: 1.0000\n",
      "Epoch 32/32\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6933 - acc: 0.6000 - f1_m: 0.9275 - precision_m: 0.8661 - recall_m: 1.0000 - val_loss: 0.6934 - val_acc: 0.5600 - val_f1_m: 0.9328 - val_precision_m: 0.8741 - val_recall_m: 1.0000\n"
     ]
    }
   ],
   "source": [
    "print('Joint full model with one hot encoding, predicting rapport, weighted by throughput')\n",
    "joint_full_model = create_joint_model(pred_df_throughput)\n",
    "joint_full_model.summary()\n",
    "history = joint_full_model.fit(x=pred_df_throughput, y=y_train_rapport, epochs=32, \n",
    "                    batch_size=64, \n",
    "                    validation_data=(pred_df_throughput_test,y_test_rapport), callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5526210484193678, 0.6162687886825817, 0.48574100046750823, None)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joint_predict = joint_full_model.predict(pred_df_throughput_test)\n",
    "joint_predict_round = []\n",
    "for a in joint_predict:\n",
    "    joint_predict_round.append([np.argmax(a)])\n",
    "precision_recall_fscore_support(y_test_rapport, np.array(joint_predict_round), average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WorkTime only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joint Model with one hot encoding "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joint Model with one hot encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_joint_model(df):\n",
    "    inputB = Input(shape=(df.shape[1],))\n",
    "    c = Dense(2, activation='relu')(inputB)\n",
    "    c = Dense(4, activation='relu')(c)\n",
    "    c = Dense(2, activation='softmax')(c)\n",
    "    full_model = Model(inputs=inputB, outputs=c)\n",
    "\n",
    "    full_model.compile(loss='binary_crossentropy', optimizer='adam', \n",
    "                          metrics=['acc',f1_m,precision_m, recall_m])\n",
    "    \n",
    "    return full_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joint full model with one hot encoding, predicting deception, weighted by throughput\n",
      "Model: \"functional_33\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_12 (InputLayer)        [(None, 4)]               0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 4)                 12        \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 2)                 10        \n",
      "=================================================================\n",
      "Total params: 32\n",
      "Trainable params: 32\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/32\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6932 - acc: 0.6332 - f1_m: 0.9754 - precision_m: 0.9523 - recall_m: 1.0000 - val_loss: 0.6931 - val_acc: 0.8610 - val_f1_m: 0.9718 - val_precision_m: 0.9456 - val_recall_m: 1.0000\n",
      "Epoch 2/32\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6931 - acc: 0.6828 - f1_m: 0.9754 - precision_m: 0.9523 - recall_m: 1.0000 - val_loss: 0.6931 - val_acc: 0.9006 - val_f1_m: 0.9718 - val_precision_m: 0.9456 - val_recall_m: 1.0000\n",
      "Epoch 3/32\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6931 - acc: 0.6249 - f1_m: 0.9754 - precision_m: 0.9523 - recall_m: 1.0000 - val_loss: 0.6931 - val_acc: 0.0602 - val_f1_m: 0.9718 - val_precision_m: 0.9456 - val_recall_m: 1.0000\n",
      "Epoch 4/32\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6931 - acc: 0.5914 - f1_m: 0.9754 - precision_m: 0.9523 - recall_m: 1.0000 - val_loss: 0.6931 - val_acc: 0.0572 - val_f1_m: 0.9718 - val_precision_m: 0.9456 - val_recall_m: 1.0000\n",
      "Epoch 5/32\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6931 - acc: 0.6614 - f1_m: 0.9753 - precision_m: 0.9523 - recall_m: 1.0000 - val_loss: 0.6931 - val_acc: 0.9314 - val_f1_m: 0.9718 - val_precision_m: 0.9456 - val_recall_m: 1.0000\n",
      "Epoch 6/32\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6931 - acc: 0.4989 - f1_m: 0.9744 - precision_m: 0.9506 - recall_m: 1.0000 - val_loss: 0.6931 - val_acc: 0.0686 - val_f1_m: 0.9718 - val_precision_m: 0.9456 - val_recall_m: 1.0000\n"
     ]
    }
   ],
   "source": [
    "print('Joint full model with one hot encoding, predicting deception, weighted by throughput')\n",
    "joint_full_model = create_joint_model(pred_df_full_worktime)\n",
    "joint_full_model.summary()\n",
    "history = joint_full_model.fit(x=pred_df_full_worktime, y=y_train_deception, epochs=32, \n",
    "                    batch_size=64, \n",
    "                    validation_data=(pred_df_full_worktime_test,y_test_deception), callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_rapport = np.asarray(y_test_rapport)\n",
    "y_train_rapport = np.asarray(y_train_rapport)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joint full model with one hot encoding, predicting rapport, weighted by throughput\n",
      "Model: \"functional_35\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_13 (InputLayer)        [(None, 3)]               0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 2)                 8         \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 4)                 12        \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 2)                 10        \n",
      "=================================================================\n",
      "Total params: 30\n",
      "Trainable params: 30\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/32\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6932 - acc: 0.2500 - f1_m: 0.9244 - precision_m: 0.8611 - recall_m: 0.9999 - val_loss: 0.6931 - val_acc: 0.1658 - val_f1_m: 0.9231 - val_precision_m: 0.8580 - val_recall_m: 1.0000\n",
      "Epoch 2/32\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6931 - acc: 0.2122 - f1_m: 0.9258 - precision_m: 0.8628 - recall_m: 1.0000 - val_loss: 0.6931 - val_acc: 0.1513 - val_f1_m: 0.9231 - val_precision_m: 0.8580 - val_recall_m: 1.0000\n",
      "Epoch 3/32\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6931 - acc: 0.3079 - f1_m: 0.9243 - precision_m: 0.8611 - recall_m: 1.0000 - val_loss: 0.6931 - val_acc: 0.8588 - val_f1_m: 0.9231 - val_precision_m: 0.8580 - val_recall_m: 1.0000\n",
      "Epoch 4/32\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6931 - acc: 0.2918 - f1_m: 0.9258 - precision_m: 0.8628 - recall_m: 1.0000 - val_loss: 0.6931 - val_acc: 0.8588 - val_f1_m: 0.9231 - val_precision_m: 0.8580 - val_recall_m: 1.0000\n",
      "Epoch 5/32\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6931 - acc: 0.4132 - f1_m: 0.9200 - precision_m: 0.8581 - recall_m: 0.9930 - val_loss: 0.6931 - val_acc: 0.1429 - val_f1_m: 0.9231 - val_precision_m: 0.8580 - val_recall_m: 1.0000\n"
     ]
    }
   ],
   "source": [
    "print('Joint full model with one hot encoding, predicting rapport, weighted by throughput')\n",
    "joint_full_model = create_joint_model(pred_df_worktime)\n",
    "joint_full_model.summary()\n",
    "history = joint_full_model.fit(x=pred_df_worktime, y=y_train_rapport, epochs=32, \n",
    "                    batch_size=64, \n",
    "                    validation_data=(pred_df_worktime_test,y_test_rapport), callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfgpu",
   "language": "python",
   "name": "tfgpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
