{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from metadata_options.ipynb\n",
      "importing Jupyter notebook from individual_nn.ipynb\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import LSTM, Input, InputLayer, Dropout, Dense, Flatten, Embedding, Add, Concatenate\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "## Own code \n",
    "import import_ipynb\n",
    "import metadata_options\n",
    "import individual_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data with Throughput & WorkTime\n",
    "df = pd.read_csv('./data/kokil dec 6 reprepare/conf_pc_worker_sem.csv')\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP1: weighted by 1 average per set of OHE, i.e. (a, b, c, d) -> (w*a, w*b, w*c, w*d)\n",
      "WT1: weighted by 1 average per set of OHE, i.e. (a, b, c, d) -> (w*a, w*b, w*c, w*d)\n",
      "PC1: weighted by 1 average per set of OHE, i.e. (a, b, c, d) -> (w*a, w*b, w*c, w*d)\n",
      "TL1: weighted by 1 normalised number of characters per set of OHE, i.e. (a, b, c, d) -> (w*a, w*b, w*c, w*d)\n"
     ]
    }
   ],
   "source": [
    "######################################\n",
    "## Weighted Onehot Encoding options ##\n",
    "######################################\n",
    "\n",
    "# Select 1 option from each of the 3 variants above, e.g. TP2, WT1, PC3, and input into function\n",
    "# set_OHE_pipeline_options. If not selecting TP3 or TP4, input k (option_k) will be ignored. After\n",
    "# editing the options, run the entire notebook for results accordingly.\n",
    "\n",
    "df_throughput, df_worktime, df_agreement, df_textlenght = metadata_options.set_OHE_pipeline_options(df, 'TP1', 'WT1', 'PC1', 'TL1', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################\n",
    "## Model Options ##\n",
    "######################################\n",
    "# options: lstm, cnn, lstm-attn\n",
    "\n",
    "model_name = 'cnn'\n",
    "individual_nn.MODEL_NAME = model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input.sentence_id</th>\n",
       "      <th>HITId</th>\n",
       "      <th>Input.convo_id</th>\n",
       "      <th>Input.train_test_val</th>\n",
       "      <th>Input.msg_id</th>\n",
       "      <th>Input.timestamp</th>\n",
       "      <th>Input.full_text</th>\n",
       "      <th>Input.speaker</th>\n",
       "      <th>Input.reply_to</th>\n",
       "      <th>Input.speaker_intention</th>\n",
       "      <th>...</th>\n",
       "      <th>prt</th>\n",
       "      <th>punct</th>\n",
       "      <th>purpcl</th>\n",
       "      <th>quantmod</th>\n",
       "      <th>rcmod</th>\n",
       "      <th>rel</th>\n",
       "      <th>root</th>\n",
       "      <th>tmod</th>\n",
       "      <th>xcomp</th>\n",
       "      <th>xsubj</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11</td>\n",
       "      <td>3MG8450X2OASXZ0WO9O5AH70GU3UPA</td>\n",
       "      <td>Game1-italy-germany</td>\n",
       "      <td>Train</td>\n",
       "      <td>Game1-italy-germany-3</td>\n",
       "      <td>87</td>\n",
       "      <td>It seems like there are a lot of ways that cou...</td>\n",
       "      <td>germany-Game1</td>\n",
       "      <td>Game1-italy-germany-2</td>\n",
       "      <td>Truth</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>12</td>\n",
       "      <td>38G0E1M85M552JXSALX4G9WI2I6UVX</td>\n",
       "      <td>Game1-italy-germany</td>\n",
       "      <td>Train</td>\n",
       "      <td>Game1-italy-germany-7</td>\n",
       "      <td>117</td>\n",
       "      <td>Sorry Italy I've been away doing, um, German t...</td>\n",
       "      <td>germany-Game1</td>\n",
       "      <td>Game1-italy-germany-6</td>\n",
       "      <td>Truth</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>14</td>\n",
       "      <td>3HYV4299H0WQ2B4TCS7PKDQ75WHE81</td>\n",
       "      <td>Game1-italy-germany</td>\n",
       "      <td>Train</td>\n",
       "      <td>Game1-italy-germany-8</td>\n",
       "      <td>119</td>\n",
       "      <td>I don't think I'm ready to go for that idea, h...</td>\n",
       "      <td>germany-Game1</td>\n",
       "      <td>Game1-italy-germany-7</td>\n",
       "      <td>Truth</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>15</td>\n",
       "      <td>3XU9MCX6VOC4P079IHIO9TCNYLGR2P</td>\n",
       "      <td>Game1-italy-germany</td>\n",
       "      <td>Train</td>\n",
       "      <td>Game1-italy-germany-9</td>\n",
       "      <td>121</td>\n",
       "      <td>I am pretty conflicted about whether to guess ...</td>\n",
       "      <td>italy-Game1</td>\n",
       "      <td>Game1-italy-germany-8</td>\n",
       "      <td>Truth</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>16</td>\n",
       "      <td>3FVBZG9CLJEK4WQS7P2GC1H2EEQH0Q</td>\n",
       "      <td>Game1-italy-germany</td>\n",
       "      <td>Train</td>\n",
       "      <td>Game1-italy-germany-9</td>\n",
       "      <td>121</td>\n",
       "      <td>I am going to take it literally and say  even ...</td>\n",
       "      <td>italy-Game1</td>\n",
       "      <td>Game1-italy-germany-8</td>\n",
       "      <td>Truth</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 862 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Input.sentence_id                           HITId       Input.convo_id  \\\n",
       "5                 11  3MG8450X2OASXZ0WO9O5AH70GU3UPA  Game1-italy-germany   \n",
       "6                 12  38G0E1M85M552JXSALX4G9WI2I6UVX  Game1-italy-germany   \n",
       "7                 14  3HYV4299H0WQ2B4TCS7PKDQ75WHE81  Game1-italy-germany   \n",
       "8                 15  3XU9MCX6VOC4P079IHIO9TCNYLGR2P  Game1-italy-germany   \n",
       "9                 16  3FVBZG9CLJEK4WQS7P2GC1H2EEQH0Q  Game1-italy-germany   \n",
       "\n",
       "  Input.train_test_val           Input.msg_id  Input.timestamp  \\\n",
       "5                Train  Game1-italy-germany-3               87   \n",
       "6                Train  Game1-italy-germany-7              117   \n",
       "7                Train  Game1-italy-germany-8              119   \n",
       "8                Train  Game1-italy-germany-9              121   \n",
       "9                Train  Game1-italy-germany-9              121   \n",
       "\n",
       "                                     Input.full_text  Input.speaker  \\\n",
       "5  It seems like there are a lot of ways that cou...  germany-Game1   \n",
       "6  Sorry Italy I've been away doing, um, German t...  germany-Game1   \n",
       "7  I don't think I'm ready to go for that idea, h...  germany-Game1   \n",
       "8  I am pretty conflicted about whether to guess ...    italy-Game1   \n",
       "9  I am going to take it literally and say  even ...    italy-Game1   \n",
       "\n",
       "          Input.reply_to Input.speaker_intention  ...  prt punct  purpcl  \\\n",
       "5  Game1-italy-germany-2                   Truth  ...  0.0   0.0     0.0   \n",
       "6  Game1-italy-germany-6                   Truth  ...  0.0   0.0     0.0   \n",
       "7  Game1-italy-germany-7                   Truth  ...  0.0   0.0     0.0   \n",
       "8  Game1-italy-germany-8                   Truth  ...  0.0   0.0     0.0   \n",
       "9  Game1-italy-germany-8                   Truth  ...  0.0   0.0     0.0   \n",
       "\n",
       "   quantmod  rcmod  rel  root  tmod xcomp  xsubj  \n",
       "5       0.0    1.0  0.0   1.0   0.0   0.0    0.0  \n",
       "6       0.0    0.0  0.0   1.0   0.0   0.0    0.0  \n",
       "7       0.0    0.0  0.0   1.0   0.0   1.0    0.0  \n",
       "8       0.0    0.0  0.0   1.0   0.0   0.0    0.0  \n",
       "9       0.0    0.0  0.0   1.0   0.0   2.0    1.0  \n",
       "\n",
       "[5 rows x 862 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = range(df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test, indices_train, indices_test = train_test_split(df, indices, test_size=0.2)\n",
    "\n",
    "new_deception_train = train[\"Input.deception_quadrant\"].copy()\n",
    "new_deception_train['Input.deception_quadrant'] = train[\"Input.deception_quadrant\"].apply(lambda x : 1 if x == \"Straightforward\" else 0)\n",
    "y_train_deception = new_deception_train['Input.deception_quadrant'].tolist()\n",
    "y_train_rapport = train['Answer.3rapport.yes_label'].tolist()\n",
    "y_train_share_information = train['Answer.4shareinformation.yes_label'].tolist()\n",
    "y_train_reasoning = train['Answer.2reasoning.yes_label'].tolist()\n",
    "y_train_gamemove = train['Answer.1gamemove.yes_label'].tolist()\n",
    "\n",
    "X_train_col = train['Input.full_text']\n",
    "\n",
    "new_deception_test = test[\"Input.deception_quadrant\"].copy()\n",
    "new_deception_test['Input.deception_quadrant'] = test[\"Input.deception_quadrant\"].apply(lambda x : 1 if x == \"Straightforward\" else 0)\n",
    "y_test_deception = new_deception_test['Input.deception_quadrant'].tolist()\n",
    "y_test_rapport = test['Answer.3rapport.yes_label'].tolist()\n",
    "y_test_share_information = test['Answer.4shareinformation.yes_label'].tolist()\n",
    "y_test_reasoning = test['Answer.2reasoning.yes_label'].tolist()\n",
    "y_test_gamemove = test['Answer.1gamemove.yes_label'].tolist()\n",
    "\n",
    "X_test_col = test['Input.full_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lynne\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "\n",
    "y_train_deception = le.fit_transform(y_train_deception)\n",
    "y_train_deception = y_train_deception.reshape(-1,1)\n",
    "\n",
    "y_train_rapport = le.fit_transform(y_train_rapport)\n",
    "y_train_rapport = y_train_rapport.reshape(-1,1)\n",
    "\n",
    "y_train_share_information = le.fit_transform(y_train_share_information)\n",
    "y_train_share_information = y_train_share_information.reshape(-1,1)\n",
    "\n",
    "y_train_reasoning = le.fit_transform(y_train_reasoning)\n",
    "y_train_reasoning = y_train_reasoning.reshape(-1,1)\n",
    "\n",
    "y_train_gamemove = le.fit_transform(y_train_gamemove)\n",
    "y_train_gamemove = y_train_gamemove.reshape(-1,1)\n",
    "\n",
    "y_train_deception = le.fit_transform(y_train_deception)\n",
    "y_train_deception = y_train_deception.reshape(-1,1)\n",
    "\n",
    "y_test_rapport = le.fit_transform(y_test_rapport)\n",
    "y_test_rapport = y_test_rapport.reshape(-1,1)\n",
    "\n",
    "y_test_share_information = le.fit_transform(y_test_share_information)\n",
    "y_test_share_information = y_test_share_information.reshape(-1,1)\n",
    "\n",
    "y_test_reasoning = le.fit_transform(y_test_reasoning)\n",
    "y_test_reasoning = y_test_reasoning.reshape(-1,1)\n",
    "\n",
    "y_test_gamemove = le.fit_transform(y_test_gamemove)\n",
    "y_test_gamemove = y_test_gamemove.reshape(-1,1)\n",
    "\n",
    "y_test_deception = le.fit_transform(y_test_deception)\n",
    "y_test_deception = y_test_deception.reshape(-1,1)\n",
    "\n",
    "y_test_rapport = np.asarray(y_test_rapport)\n",
    "y_train_rapport = np.asarray(y_train_rapport)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct individual  models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'create_cnn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-ff4cddb54b2e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Rapport model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mrapport_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindividual_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_nn_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m rapport_model.compile(loss='binary_crossentropy',optimizer=RMSprop(),metrics=['accuracy', individual_nn.f1_m, \n\u001b[0;32m      4\u001b[0m                                                                               individual_nn.recall_m, individual_nn.precision_m])\n\u001b[0;32m      5\u001b[0m rapport_model.fit(X_train,y_train_rapport,\n",
      "\u001b[1;32m~\\Documents\\diplomacy-betrayal\\individual_nn.ipynb\u001b[0m in \u001b[0;36mcreate_nn_model\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'create_cnn' is not defined"
     ]
    }
   ],
   "source": [
    "# Rapport model\n",
    "rapport_model = individual_nn.create_nn_model()\n",
    "rapport_model.compile(loss='binary_crossentropy',optimizer=RMSprop(),metrics=['accuracy', individual_nn.f1_m, \n",
    "                                                                              individual_nn.recall_m, individual_nn.precision_m])\n",
    "rapport_model.fit(X_train,y_train_rapport,\n",
    "          batch_size=128,\n",
    "          epochs=15,\n",
    "          validation_data=(X_test, y_test_rapport), callbacks=[individual_nn.early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rapport_pred = rapport_model.predict(X_train)\n",
    "rapport_pred_test = rapport_model.predict(X_test)\n",
    "\n",
    "rapport_pred_test_round = rapport_pred_test.round()\n",
    "precision_recall_fscore_support(y_test_rapport, rapport_pred_test_round, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Game move model\n",
    "gamemove_model = create_nn_model()\n",
    "gamemove_model.compile(loss='binary_crossentropy',optimizer=RMSprop(),metrics=['accuracy', f1_m, recall_m, precision_m])\n",
    "gamemove_model.fit(X_train,y_train_gamemove,\n",
    "          batch_size=128,\n",
    "          epochs=15,\n",
    "          validation_data=(X_test, y_test_gamemove), callbacks=[individual_nn.early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamemove_pred = gamemove_model.predict(X_train)\n",
    "gamemove_pred_test = gamemove_model.predict(X_test)\n",
    "\n",
    "gamemove_pred_test_round = gamemove_pred_test.round()\n",
    "precision_recall_fscore_support(y_test_gamemove, gamemove_pred_test_round, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reasoning model\n",
    "reasoning_model = create_nn_model()\n",
    "reasoning_model.compile(loss='binary_crossentropy',optimizer=RMSprop(),metrics=['accuracy', f1_m, recall_m, precision_m])\n",
    "reasoning_model.fit(X_train,y_train_reasoning,\n",
    "          batch_size=128,\n",
    "          epochs=15,\n",
    "          validation_data=(X_test, y_test_reasoning), callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reasoning_pred = reasoning_model.predict(X_train)\n",
    "reasoning_pred_test = reasoning_model.predict(X_test)\n",
    "\n",
    "reasoning_pred_test_round = reasoning_pred_test.round()\n",
    "precision_recall_fscore_support(y_test_reasoning, reasoning_pred_test_round, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Share Information model\n",
    "shareinfo_model = create_nn_model()\n",
    "shareinfo_model.compile(loss='binary_crossentropy',optimizer=RMSprop(),metrics=['accuracy', f1_m, recall_m, precision_m])\n",
    "shareinfo_model.fit(X_train,y_train_share_information,\n",
    "          batch_size=128,\n",
    "          epochs=15,\n",
    "          validation_data=(X_test, y_test_share_information), callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shareinfo_pred = shareinfo_model.predict(X_train)\n",
    "shareinfo_pred_test = shareinfo_model.predict(X_test)\n",
    "\n",
    "shareinfo_pred_test_round = shareinfo_pred_test.round()\n",
    "precision_recall_fscore_support(y_test_share_information, shareinfo_pred_test_round, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deception model\n",
    "deception_model = create_nn_model()\n",
    "deception_model.compile(loss='binary_crossentropy',optimizer=RMSprop(),metrics=['accuracy', f1_m, recall_m, precision_m])\n",
    "deception_model.fit(X_train,y_train_deception,\n",
    "          batch_size=128,\n",
    "          epochs=15,\n",
    "          validation_data=(X_test, y_test_deception), callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deception_pred = deception_model.predict(X_train)\n",
    "deception_pred_test = deception_model.predict(X_test)\n",
    "deception_pred_test_round = deception_pred_test.round()\n",
    "precision_recall_fscore_support(y_test_deception, deception_pred_test_round, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One hot encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train encodings\n",
    "pred_df_arr_full = []\n",
    "pred_df_arr = []\n",
    "for i in range(0, len(gamemove_pred)):\n",
    "    pred_obj_1 = {}\n",
    "    pred_obj_1['gamemove'] = gamemove_pred[i][0]\n",
    "    pred_obj_1['reasoning'] = reasoning_pred[i][0]\n",
    "    pred_obj_1['shareinfo'] = shareinfo_pred[i][0]\n",
    "    pred_df_arr.append(pred_obj_1)\n",
    "    \n",
    "    pred_obj_2 = pred_obj_1.copy()\n",
    "    pred_obj_2['rapport'] = rapport_pred[i][0]\n",
    "    pred_df_arr_full.append(pred_obj_2)\n",
    "    \n",
    "pred_df_full = pd.DataFrame(pred_df_arr_full)\n",
    "pred_df = pd.DataFrame(pred_df_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test encodings\n",
    "pred_test_df_arr_full = []\n",
    "pred_test_df_arr = []\n",
    "\n",
    "for i in range(0, len(gamemove_pred_test)):\n",
    "    pred_obj_1 = {}\n",
    "    pred_obj_1['gamemove'] = gamemove_pred_test[i][0]\n",
    "    pred_obj_1['reasoning'] = reasoning_pred_test[i][0]\n",
    "    pred_obj_1['shareinfo'] = shareinfo_pred_test[i][0]\n",
    "    pred_test_df_arr.append(pred_obj_1)\n",
    "    \n",
    "    pred_obj_2 = pred_obj_1.copy()\n",
    "    pred_obj_2['rapport'] = rapport_pred_test[i][0]\n",
    "    pred_test_df_arr_full.append(pred_obj_2)\n",
    "    \n",
    "pred_test_df_full = pd.DataFrame(pred_test_df_arr_full)\n",
    "pred_test_df = pd.DataFrame(pred_test_df_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joint Model with one hot encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_joint_model(df):\n",
    "    inputB = Input(shape=(df.shape[1],))\n",
    "    c = Dense(2, activation='relu')(inputB)\n",
    "    c = Dense(4, activation='relu')(c)\n",
    "    c = Dense(1, activation='softmax')(c)\n",
    "    full_model = Model(inputs=inputB, outputs=c)\n",
    "\n",
    "    full_model.compile(loss='binary_crossentropy', optimizer='adam', \n",
    "                          metrics=['acc',f1_m,precision_m, recall_m])\n",
    "    \n",
    "    return full_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Joint full model with one hot encoding, predicting deception')\n",
    "joint_full_model = create_joint_model(pred_df_full)\n",
    "joint_full_model.summary()\n",
    "history = joint_full_model.fit(x=pred_df_full, y=y_train_deception, epochs=32, \n",
    "                    batch_size=64, \n",
    "                    validation_data=(pred_test_df_full,y_test_deception), callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_predict = joint_full_model.predict(pred_test_df_full)\n",
    "joint_predict_round = []\n",
    "for a in joint_predict:\n",
    "    joint_predict_round.append([np.argmax(a)])\n",
    "precision_recall_fscore_support(y_test_deception, np.array(joint_predict_round), average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Joint full model with one hot encoding, predicting rapport')\n",
    "joint_full_model = create_joint_model(pred_df)\n",
    "joint_full_model.summary()\n",
    "history = joint_full_model.fit(x=pred_df, y=y_train_rapport, epochs=32, \n",
    "                    batch_size=64, \n",
    "                    validation_data=(pred_test_df,y_test_rapport), callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_predict = joint_full_model.predict(pred_test_df)\n",
    "joint_predict_round = []\n",
    "for a in joint_predict:\n",
    "    joint_predict_round.append([np.argmax(a)])\n",
    "precision_recall_fscore_support(y_test_rapport, np.array(joint_predict_round), average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weighted against Throughput, WorkTime, PC Agreement & Text Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train weighted encodings\n",
    "pred_df_full_throughput = pred_df_full.copy()\n",
    "pred_df_full_worktime = pred_df_full.copy()\n",
    "pred_df_throughput = pred_df.copy()\n",
    "pred_df_worktime = pred_df.copy()\n",
    "\n",
    "df_throughput_keys = df_throughput.keys().to_list()\n",
    "throughput_values = df_throughput[df_throughput_keys[-1]].take(indices_train).values\n",
    "pred_df_full_throughput = pred_df_full_throughput.mul(throughput_values, axis=0)\n",
    "pred_df_throughput = pred_df_throughput.mul(throughput_values, axis=0)\n",
    "\n",
    "df_worktime_keys = df_worktime.keys().to_list()\n",
    "worktime_values = df_worktime[df_worktime_keys[-1]].take(indices_train).values\n",
    "pred_df_full_worktime = pred_df_full_worktime.mul(worktime_values, axis=0)\n",
    "pred_df_worktime = pred_df_worktime.mul(worktime_values, axis=0)\n",
    "\n",
    "df_agreement_keys = df_agreement.keys().to_list()\n",
    "if len(df_agreement_keys) == 5:\n",
    "    agreement_values = df_agreement[df_agreement_keys[-1]].take(indices_train).values\n",
    "    pred_df_full_agreement = pred_df_full_throughput.mul(agreement_values, axis=0)\n",
    "    pred_df_agreement = pred_df_throughput.mul(agreement_values, axis=0)\n",
    "elif len(df_agreement_keys) == 4:\n",
    "    agreement_values = df_agreement.take(indices_train)\n",
    "    pred_df_full_agreement = np.multiply(pred_df_full_throughput, agreement_values)\n",
    "    agreement_values_wo_rapport = agreement_values.drop(columns=['Answer.3rapport.yes_pc_agree'])\n",
    "    pred_df_agreement = np.multiply(pred_df_throughput, agreement_values_wo_rapport)\n",
    "    \n",
    "textlenght_values = df_textlenght.take(indices_train).values\n",
    "pred_df_full_textlenght = pred_df_full_throughput.mul(textlenght_values, axis=0)\n",
    "pred_df_textlenght = pred_df_throughput.mul(textlenght_values, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test weighted encodings\n",
    "pred_df_full_throughput_test = pred_test_df_full.copy()\n",
    "pred_df_full_worktime_test = pred_test_df_full.copy()\n",
    "pred_df_throughput_test = pred_test_df.copy()\n",
    "pred_df_worktime_test = pred_test_df.copy()\n",
    "\n",
    "df_throughput_keys = df_throughput.keys().to_list()\n",
    "throughput_values_test = df_throughput[df_throughput_keys[-1]].take(indices_test).values\n",
    "pred_df_full_throughput_test = pred_df_full_throughput_test.mul(throughput_values_test, axis=0)\n",
    "pred_df_throughput_test = pred_df_throughput_test.mul(throughput_values_test, axis=0)\n",
    "\n",
    "df_worktime_keys = df_worktime.keys().to_list()\n",
    "worktime_values_test = df_worktime[df_worktime_keys[-1]].take(indices_test).values\n",
    "pred_df_full_worktime_test = pred_df_full_worktime_test.mul(worktime_values_test, axis=0)\n",
    "pred_df_worktime_test = pred_df_worktime_test.mul(worktime_values_test, axis=0)\n",
    "\n",
    "df_agreement_keys = df_agreement.keys().to_list()\n",
    "if len(df_agreement_keys) == 5:\n",
    "    agreement_values_test = df_agreement[df_agreement_keys[-1]].take(indices_test).values\n",
    "    pred_df_full_agreement_test = pred_df_full_throughput_test.mul(agreement_values_test, axis=0)\n",
    "    pred_df_agreement_test = pred_df_throughput_test.mul(agreement_values_test, axis=0)\n",
    "elif len(df_agreement_keys) == 4:\n",
    "    agreement_values_test = df_agreement.take(indices_test)\n",
    "    pred_df_full_agreement_test = np.multiply(pred_df_full_throughput_test, agreement_values_test)\n",
    "    agreement_values_wo_rapport_test = agreement_values_test.drop(columns=['Answer.3rapport.yes_pc_agree'])\n",
    "    pred_df_agreement_test = np.multiply(pred_df_throughput_test, agreement_values_wo_rapport_test)\n",
    "    \n",
    "textlenght_values_test = df_textlenght.take(indices_test).values\n",
    "pred_df_full_textlenght_test = pred_df_full_throughput_test.mul(textlenght_values_test, axis=0)\n",
    "pred_df_textlenght_test = pred_df_throughput_test.mul(textlenght_values_test, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Throughput only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joint Model with one hot encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Joint full model with one hot encoding, predicting deception, weighted by throughput')\n",
    "joint_full_model = create_joint_model(pred_df_full_throughput)\n",
    "joint_full_model.summary()\n",
    "history = joint_full_model.fit(x=pred_df_full_throughput, y=y_train_deception, epochs=32, \n",
    "                    batch_size=64, \n",
    "                    validation_data=(pred_df_full_throughput_test,y_test_deception), callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_predict = joint_full_model.predict(pred_df_full_throughput_test)\n",
    "joint_predict_round = []\n",
    "for a in joint_predict:\n",
    "    joint_predict_round.append([np.argmax(a)])\n",
    "precision_recall_fscore_support(y_test_deception, np.array(joint_predict_round), average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_rapport = np.asarray(y_test_rapport)\n",
    "y_train_rapport = np.asarray(y_train_rapport)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Joint full model with one hot encoding, predicting rapport, weighted by throughput')\n",
    "joint_full_model = create_joint_model(pred_df_throughput)\n",
    "joint_full_model.summary()\n",
    "history = joint_full_model.fit(x=pred_df_throughput, y=y_train_rapport, epochs=32, \n",
    "                    batch_size=64, \n",
    "                    validation_data=(pred_df_throughput_test,y_test_rapport), callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "joint_predict = joint_full_model.predict(pred_df_throughput_test)\n",
    "joint_predict_round = []\n",
    "for a in joint_predict:\n",
    "    joint_predict_round.append([np.argmax(a)])\n",
    "precision_recall_fscore_support(y_test_rapport, np.array(joint_predict_round), average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PC Agreement only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joint Model with one hot encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Joint full model with one hot encoding, predicting deception, weighted by PC Agreement')\n",
    "joint_full_model = create_joint_model(pred_df_full_agreement)\n",
    "joint_full_model.summary()\n",
    "history = joint_full_model.fit(x=pred_df_full_agreement, y=y_train_deception, epochs=32, \n",
    "                    batch_size=64, \n",
    "                    validation_data=(pred_df_full_agreement_test,y_test_deception), callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_predict = joint_full_model.predict(pred_df_full_throughput_test)\n",
    "joint_predict_round = []\n",
    "for a in joint_predict:\n",
    "    joint_predict_round.append([np.argmax(a)])\n",
    "precision_recall_fscore_support(y_test_rapport, np.array(joint_predict_round), average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_rapport = np.asarray(y_test_rapport)\n",
    "y_train_rapport = np.asarray(y_train_rapport)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('Joint full model with one hot encoding, predicting rapport, weighted by PC Agreement')\n",
    "joint_full_model = create_joint_model(pred_df_agreement)\n",
    "joint_full_model.summary()\n",
    "history = joint_full_model.fit(x=pred_df_agreement, y=y_train_rapport, epochs=32, \n",
    "                    batch_size=64, \n",
    "                    validation_data=(pred_df_agreement_test,y_test_rapport), callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_predict = joint_full_model.predict(pred_df_throughput_test)\n",
    "joint_predict_round = []\n",
    "for a in joint_predict:\n",
    "    joint_predict_round.append([np.argmax(a)])\n",
    "precision_recall_fscore_support(y_test_rapport, np.array(joint_predict_round), average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WorkTime only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joint Model with one hot encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Joint full model with one hot encoding, predicting deception, weighted by throughput')\n",
    "joint_full_model = create_joint_model(pred_df_full_worktime)\n",
    "joint_full_model.summary()\n",
    "history = joint_full_model.fit(x=pred_df_full_worktime, y=y_train_deception, epochs=32, \n",
    "                    batch_size=64, \n",
    "                    validation_data=(pred_df_full_worktime_test,y_test_deception), callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('Joint full model with one hot encoding, predicting rapport, weighted by throughput')\n",
    "joint_full_model = create_joint_model(pred_df_worktime)\n",
    "joint_full_model.summary()\n",
    "history = joint_full_model.fit(x=pred_df_worktime, y=y_train_rapport, epochs=32, \n",
    "                    batch_size=64, \n",
    "                    validation_data=(pred_df_worktime_test,y_test_rapport), callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_predict = joint_full_model.predict(pred_df_worktime_test)\n",
    "joint_predict_round = []\n",
    "for a in joint_predict:\n",
    "    joint_predict_round.append([np.argmax(a)])\n",
    "precision_recall_fscore_support(y_test_rapport, np.array(joint_predict_round), average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Length only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joint Model with one hot encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Joint full model with one hot encoding, predicting deception, weighted by text length')\n",
    "joint_full_model = create_joint_model(pred_df_full_textlenght)\n",
    "joint_full_model.summary()\n",
    "history = joint_full_model.fit(x=pred_df_full_textlenght, y=y_train_deception, epochs=32, \n",
    "                    batch_size=64, \n",
    "                    validation_data=(pred_df_full_textlenght_test,y_test_deception), callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_predict = joint_full_model.predict(pred_df_full_textlenght_test)\n",
    "joint_predict_round = []\n",
    "for a in joint_predict:\n",
    "    joint_predict_round.append([np.argmax(a)])\n",
    "precision_recall_fscore_support(y_test_deception, np.array(joint_predict_round), average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Joint full model with one hot encoding, predicting rapport, weighted by text length')\n",
    "joint_full_model = create_joint_model(pred_df_textlenght)\n",
    "joint_full_model.summary()\n",
    "history = joint_full_model.fit(x=pred_df_textlenght, y=y_train_rapport, epochs=32, \n",
    "                    batch_size=64, \n",
    "                    validation_data=(pred_df_textlenght_test,y_test_rapport), callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "joint_predict = joint_full_model.predict(pred_df_textlenght_test)\n",
    "joint_predict_round = []\n",
    "for a in joint_predict:\n",
    "    joint_predict_round.append([np.argmax(a)])\n",
    "precision_recall_fscore_support(y_test_rapport, np.array(joint_predict_round), average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfgpu",
   "language": "python",
   "name": "tfgpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
