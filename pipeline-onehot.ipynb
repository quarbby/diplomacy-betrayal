{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import LSTM, Input, InputLayer, Dropout, Dense, Flatten, Embedding, Add, Concatenate\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Good data\n",
    "df = pd.read_csv('./data/kokil dec 6 reprepare/affcon_final_with_linguistics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Messy data\n",
    "df = pd.read_csv('./data/affcon_final_politeness_strategies_merge.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Individual Classifiers are LSTMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size=0.2)\n",
    "\n",
    "y_train_deception = train['Input.deception_quadrant_cat'].tolist()\n",
    "y_train_rapport = train['affcon_rapport'].tolist()\n",
    "y_train_share_information = train['affcon_shareinformation'].tolist()\n",
    "y_train_reasoning = train['affcon_reasoning'].tolist()\n",
    "y_train_gamemove = train['affcon_gamemove'].tolist()\n",
    "\n",
    "y_test_deception = test['Input.deception_quadrant_cat'].tolist()\n",
    "y_test_rapport = test['affcon_rapport'].tolist()\n",
    "y_test_share_information = test['affcon_shareinformation'].tolist()\n",
    "y_test_reasoning = test['affcon_reasoning'].tolist()\n",
    "y_test_gamemove = test['affcon_gamemove'].tolist()\n",
    "\n",
    "X_train_col = train['Input.full_text']\n",
    "\n",
    "X_test_col = test['Input.full_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', min_delta=0, patience=0, verbose=0, mode='auto',\n",
    "    baseline=None, restore_best_weights=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lynne\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "\n",
    "y_train_deception = le.fit_transform(y_train_deception)\n",
    "y_train_deception = y_train_deception.reshape(-1,1)\n",
    "\n",
    "y_train_rapport = le.fit_transform(y_train_rapport)\n",
    "y_train_rapport = y_train_rapport.reshape(-1,1)\n",
    "\n",
    "y_train_share_information = le.fit_transform(y_train_share_information)\n",
    "y_train_share_information = y_train_share_information.reshape(-1,1)\n",
    "\n",
    "y_train_reasoning = le.fit_transform(y_train_reasoning)\n",
    "y_train_reasoning = y_train_reasoning.reshape(-1,1)\n",
    "\n",
    "y_train_gamemove = le.fit_transform(y_train_gamemove)\n",
    "y_train_gamemove = y_train_gamemove.reshape(-1,1)\n",
    "\n",
    "y_train_deception = le.fit_transform(y_train_deception)\n",
    "y_train_deception = y_train_deception.reshape(-1,1)\n",
    "\n",
    "y_test_rapport = le.fit_transform(y_test_rapport)\n",
    "y_test_rapport = y_test_rapport.reshape(-1,1)\n",
    "\n",
    "y_test_share_information = le.fit_transform(y_test_share_information)\n",
    "y_test_share_information = y_test_share_information.reshape(-1,1)\n",
    "\n",
    "y_test_reasoning = le.fit_transform(y_test_reasoning)\n",
    "y_test_reasoning = y_test_reasoning.reshape(-1,1)\n",
    "\n",
    "y_test_gamemove = le.fit_transform(y_test_gamemove)\n",
    "y_test_gamemove = y_test_gamemove.reshape(-1,1)\n",
    "\n",
    "y_test_deception = le.fit_transform(y_test_deception)\n",
    "y_test_deception = y_test_deception.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 1000\n",
    "max_len = 220\n",
    "\n",
    "tok = Tokenizer(num_words=max_words)\n",
    "\n",
    "tok.fit_on_texts(X_train_col)\n",
    "X_train_sequences = tok.texts_to_sequences(X_train_col)\n",
    "X_train = pad_sequences(X_train_sequences, maxlen=max_len)\n",
    "\n",
    "tok.fit_on_texts(X_test_col)\n",
    "X_test_sequences = tok.texts_to_sequences(X_test_col)\n",
    "X_test = pad_sequences(X_test_sequences, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss',min_delta=0.00001)\n",
    "def create_lstm():\n",
    "    Inp = Input(name='inputs', shape=[max_len])\n",
    "    x = Embedding(max_words, 50, input_length=max_len)(Inp)\n",
    "    x = LSTM(64, name='LSTM_01')(x)\n",
    "    x = Dropout(0.5, name='Dropout')(x)\n",
    "    x = Dense(128, activation='relu',name='Dense_01')(x)\n",
    "    # x = Dropout(0.5,name='Dropout')(x)\n",
    "    out = Dense(1,activation='sigmoid', name='output')(x)\n",
    "    model = Model(inputs=Inp, outputs=out)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct individual LSTM models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "85/85 [==============================] - 3s 41ms/step - loss: 0.6625 - accuracy: 0.6235 - f1_m: 0.7635 - recall_m: 0.9901 - precision_m: 0.6239 - val_loss: 0.6685 - val_accuracy: 0.6099 - val_f1_m: 0.7606 - val_recall_m: 1.0000 - val_precision_m: 0.6147\n",
      "Epoch 2/15\n",
      "85/85 [==============================] - 3s 35ms/step - loss: 0.6438 - accuracy: 0.6271 - f1_m: 0.7691 - recall_m: 0.9975 - precision_m: 0.6268 - val_loss: 0.6770 - val_accuracy: 0.5965 - val_f1_m: 0.7413 - val_recall_m: 0.9330 - val_precision_m: 0.6158\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a827932148>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rapport model\n",
    "rapport_model = create_lstm()\n",
    "rapport_model.compile(loss='binary_crossentropy',optimizer=RMSprop(),metrics=['accuracy', f1_m, recall_m, precision_m])\n",
    "rapport_model.fit(X_train,y_train_rapport,\n",
    "          batch_size=128,\n",
    "          epochs=15,\n",
    "          validation_data=(X_test, y_test_rapport), callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rapport_pred = rapport_model.predict(X_train)\n",
    "rapport_pred_test = rapport_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "85/85 [==============================] - 4s 44ms/step - loss: 0.5877 - accuracy: 0.7351 - f1_m: 0.8429 - recall_m: 0.9901 - precision_m: 0.7392 - val_loss: 0.5985 - val_accuracy: 0.7210 - val_f1_m: 0.8373 - val_recall_m: 1.0000 - val_precision_m: 0.7213\n",
      "Epoch 2/15\n",
      "85/85 [==============================] - 3s 35ms/step - loss: 0.5687 - accuracy: 0.7392 - f1_m: 0.8498 - recall_m: 1.0000 - precision_m: 0.7396 - val_loss: 0.5999 - val_accuracy: 0.7210 - val_f1_m: 0.8373 - val_recall_m: 1.0000 - val_precision_m: 0.7213\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a9ed718b08>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Game move model\n",
    "gamemove_model = create_lstm()\n",
    "gamemove_model.compile(loss='binary_crossentropy',optimizer=RMSprop(),metrics=['accuracy', f1_m, recall_m, precision_m])\n",
    "gamemove_model.fit(X_train,y_train_gamemove,\n",
    "          batch_size=128,\n",
    "          epochs=15,\n",
    "          validation_data=(X_test, y_test_gamemove), callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamemove_pred = gamemove_model.predict(X_train)\n",
    "gamemove_pred_test = gamemove_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "85/85 [==============================] - 4s 42ms/step - loss: 0.5253 - accuracy: 0.7879 - f1_m: 0.8787 - recall_m: 0.9921 - precision_m: 0.7920 - val_loss: 0.5375 - val_accuracy: 0.7707 - val_f1_m: 0.8713 - val_recall_m: 1.0000 - val_precision_m: 0.7726\n",
      "Epoch 2/15\n",
      "85/85 [==============================] - 3s 36ms/step - loss: 0.5083 - accuracy: 0.7926 - f1_m: 0.8840 - recall_m: 1.0000 - precision_m: 0.7929 - val_loss: 0.5408 - val_accuracy: 0.7707 - val_f1_m: 0.8713 - val_recall_m: 1.0000 - val_precision_m: 0.7726\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1aa175deec8>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reasoning model\n",
    "reasoning_model = create_lstm()\n",
    "reasoning_model.compile(loss='binary_crossentropy',optimizer=RMSprop(),metrics=['accuracy', f1_m, recall_m, precision_m])\n",
    "reasoning_model.fit(X_train,y_train_reasoning,\n",
    "          batch_size=128,\n",
    "          epochs=15,\n",
    "          validation_data=(X_test, y_test_reasoning), callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "reasoning_pred = reasoning_model.predict(X_train)\n",
    "reasoning_pred_test = reasoning_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "85/85 [==============================] - 4s 44ms/step - loss: 0.6822 - accuracy: 0.5553 - f1_m: 0.6526 - recall_m: 0.8274 - precision_m: 0.5636 - val_loss: 0.6879 - val_accuracy: 0.5413 - val_f1_m: 0.3637 - val_recall_m: 0.2529 - val_precision_m: 0.6665\n",
      "Epoch 2/15\n",
      "85/85 [==============================] - 3s 35ms/step - loss: 0.6370 - accuracy: 0.6272 - f1_m: 0.6263 - recall_m: 0.6014 - precision_m: 0.6729 - val_loss: 0.6884 - val_accuracy: 0.5606 - val_f1_m: 0.5407 - val_recall_m: 0.5017 - val_precision_m: 0.5927\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1aa1c865ec8>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Share Information model\n",
    "shareinfo_model = create_lstm()\n",
    "shareinfo_model.compile(loss='binary_crossentropy',optimizer=RMSprop(),metrics=['accuracy', f1_m, recall_m, precision_m])\n",
    "shareinfo_model.fit(X_train,y_train_share_information,\n",
    "          batch_size=128,\n",
    "          epochs=15,\n",
    "          validation_data=(X_test, y_test_share_information), callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "shareinfo_pred = shareinfo_model.predict(X_train)\n",
    "shareinfo_pred_test = shareinfo_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "85/85 [==============================] - 3s 41ms/step - loss: 0.2250 - accuracy: 0.9486 - f1_m: 0.9737 - recall_m: 0.9982 - precision_m: 0.9507 - val_loss: 0.2368 - val_accuracy: 0.9429 - val_f1_m: 0.9698 - val_recall_m: 1.0000 - val_precision_m: 0.9415\n",
      "Epoch 2/15\n",
      "85/85 [==============================] - 3s 35ms/step - loss: 0.2001 - accuracy: 0.9503 - f1_m: 0.9743 - recall_m: 1.0000 - precision_m: 0.9502 - val_loss: 0.2210 - val_accuracy: 0.9429 - val_f1_m: 0.9698 - val_recall_m: 1.0000 - val_precision_m: 0.9415\n",
      "Epoch 3/15\n",
      "85/85 [==============================] - 3s 35ms/step - loss: 0.1909 - accuracy: 0.9503 - f1_m: 0.9746 - recall_m: 1.0000 - precision_m: 0.9505 - val_loss: 0.2319 - val_accuracy: 0.9429 - val_f1_m: 0.9698 - val_recall_m: 1.0000 - val_precision_m: 0.9415\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1aa228f89c8>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Deception model\n",
    "deception_model = create_lstm()\n",
    "deception_model.compile(loss='binary_crossentropy',optimizer=RMSprop(),metrics=['accuracy', f1_m, recall_m, precision_m])\n",
    "deception_model.fit(X_train,y_train_deception,\n",
    "          batch_size=128,\n",
    "          epochs=15,\n",
    "          validation_data=(X_test, y_test_deception), callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One hot encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train encodings\n",
    "pred_df_arr_full = []\n",
    "pred_df_arr = []\n",
    "for i in range(0, len(gamemove_pred)):\n",
    "    pred_obj = {}\n",
    "    pred_obj['gamemove'] = gamemove_pred[i][0]\n",
    "    pred_obj['reasoning'] = reasoning_pred[i][0]\n",
    "    pred_obj['shareinfo'] = shareinfo_pred[i][0]\n",
    "    \n",
    "    pred_df_arr_full.append(pred_obj)\n",
    "    \n",
    "    pred_obj['rapport'] = rapport_pred[i][0]\n",
    "    pred_df_arr.append(pred_obj)\n",
    "    \n",
    "pred_df_full = pd.DataFrame(pred_df_arr_full)\n",
    "pred_df = pd.DataFrame(pred_df_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test encodings\n",
    "pred_test_df_arr_full = []\n",
    "pred_test_df_arr = []\n",
    "\n",
    "for i in range(0, len(gamemove_pred_test)):\n",
    "    pred_obj = {}\n",
    "    pred_obj['gamemove'] = gamemove_pred_test[i][0]\n",
    "    pred_obj['reasoning'] = reasoning_pred_test[i][0]\n",
    "    pred_obj['shareinfo'] = shareinfo_pred_test[i][0]\n",
    "    \n",
    "    pred_test_df_arr_full.append(pred_obj)\n",
    "    \n",
    "    pred_obj['rapport'] = rapport_pred_test[i][0]\n",
    "    pred_test_df_arr.append(pred_obj)\n",
    "    \n",
    "pred_test_df_full = pd.DataFrame(pred_test_df_arr_full)\n",
    "pred_test_df = pd.DataFrame(pred_test_df_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joint Model with one hot encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_joint_model(df):\n",
    "    inputB = Input(shape=(df.shape[1],))\n",
    "    c = Dense(2, activation='relu')(inputB)\n",
    "    c = Dense(4, activation='relu')(c)\n",
    "    c = Dense(2, activation='softmax')(c)\n",
    "    full_model = Model(inputs=inputB, outputs=c)\n",
    "\n",
    "    full_model.compile(loss='binary_crossentropy', optimizer='adam', \n",
    "                          metrics=['acc',f1_m,precision_m, recall_m])\n",
    "    \n",
    "    return full_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joint full model with one hot encoding, predicting deception\n",
      "Epoch 1/32\n",
      "169/169 [==============================] - 1s 5ms/step - loss: 0.7800 - acc: 0.0856 - f1_m: 0.9743 - precision_m: 0.9503 - recall_m: 1.0000 - val_loss: 0.6990 - val_acc: 0.2238 - val_f1_m: 0.9701 - val_precision_m: 0.9423 - val_recall_m: 1.0000\n",
      "Epoch 2/32\n",
      "169/169 [==============================] - 1s 3ms/step - loss: 0.6950 - acc: 0.3777 - f1_m: 0.9743 - precision_m: 0.9503 - recall_m: 1.0000 - val_loss: 0.6936 - val_acc: 0.5057 - val_f1_m: 0.9701 - val_precision_m: 0.9423 - val_recall_m: 1.0000\n",
      "Epoch 3/32\n",
      "169/169 [==============================] - 1s 3ms/step - loss: 0.6935 - acc: 0.5006 - f1_m: 0.9743 - precision_m: 0.9503 - recall_m: 1.0000 - val_loss: 0.6933 - val_acc: 0.5128 - val_f1_m: 0.9701 - val_precision_m: 0.9423 - val_recall_m: 1.0000\n",
      "Epoch 4/32\n",
      "169/169 [==============================] - 1s 3ms/step - loss: 0.6933 - acc: 0.4993 - f1_m: 0.9743 - precision_m: 0.9503 - recall_m: 1.0000 - val_loss: 0.6932 - val_acc: 0.3994 - val_f1_m: 0.9701 - val_precision_m: 0.9423 - val_recall_m: 1.0000\n",
      "Epoch 5/32\n",
      "169/169 [==============================] - 1s 3ms/step - loss: 0.6932 - acc: 0.4869 - f1_m: 0.9743 - precision_m: 0.9502 - recall_m: 1.0000 - val_loss: 0.6932 - val_acc: 0.4702 - val_f1_m: 0.9701 - val_precision_m: 0.9423 - val_recall_m: 1.0000\n",
      "Epoch 6/32\n",
      "169/169 [==============================] - 1s 4ms/step - loss: 0.6932 - acc: 0.4838 - f1_m: 0.9744 - precision_m: 0.9504 - recall_m: 1.0000 - val_loss: 0.6932 - val_acc: 0.4313 - val_f1_m: 0.9701 - val_precision_m: 0.9423 - val_recall_m: 1.0000\n",
      "Epoch 7/32\n",
      "169/169 [==============================] - 1s 3ms/step - loss: 0.6932 - acc: 0.4862 - f1_m: 0.9744 - precision_m: 0.9503 - recall_m: 1.0000 - val_loss: 0.6932 - val_acc: 0.4965 - val_f1_m: 0.9701 - val_precision_m: 0.9423 - val_recall_m: 1.0000\n",
      "Epoch 8/32\n",
      "169/169 [==============================] - 1s 3ms/step - loss: 0.6932 - acc: 0.4907 - f1_m: 0.9743 - precision_m: 0.9503 - recall_m: 1.0000 - val_loss: 0.6932 - val_acc: 0.4113 - val_f1_m: 0.9701 - val_precision_m: 0.9423 - val_recall_m: 1.0000\n",
      "Epoch 9/32\n",
      "169/169 [==============================] - 1s 3ms/step - loss: 0.6932 - acc: 0.4895 - f1_m: 0.9743 - precision_m: 0.9503 - recall_m: 1.0000 - val_loss: 0.6932 - val_acc: 0.5765 - val_f1_m: 0.9701 - val_precision_m: 0.9423 - val_recall_m: 1.0000\n",
      "Epoch 10/32\n",
      "169/169 [==============================] - 1s 3ms/step - loss: 0.6932 - acc: 0.4973 - f1_m: 0.9744 - precision_m: 0.9504 - recall_m: 0.9999 - val_loss: 0.6932 - val_acc: 0.6610 - val_f1_m: 0.9701 - val_precision_m: 0.9423 - val_recall_m: 1.0000\n",
      "Epoch 11/32\n",
      "169/169 [==============================] - 1s 3ms/step - loss: 0.6932 - acc: 0.5285 - f1_m: 0.9744 - precision_m: 0.9503 - recall_m: 1.0000 - val_loss: 0.6932 - val_acc: 0.1504 - val_f1_m: 0.9701 - val_precision_m: 0.9423 - val_recall_m: 1.0000\n",
      "Epoch 12/32\n",
      "169/169 [==============================] - 1s 4ms/step - loss: 0.6932 - acc: 0.5132 - f1_m: 0.9742 - precision_m: 0.9502 - recall_m: 0.9998 - val_loss: 0.6932 - val_acc: 0.6832 - val_f1_m: 0.9701 - val_precision_m: 0.9423 - val_recall_m: 1.0000\n",
      "Epoch 13/32\n",
      "169/169 [==============================] - 1s 3ms/step - loss: 0.6932 - acc: 0.5064 - f1_m: 0.9744 - precision_m: 0.9503 - recall_m: 1.0000 - val_loss: 0.6932 - val_acc: 0.1960 - val_f1_m: 0.9701 - val_precision_m: 0.9423 - val_recall_m: 1.0000\n",
      "Epoch 14/32\n",
      "169/169 [==============================] - 1s 3ms/step - loss: 0.6932 - acc: 0.5096 - f1_m: 0.9743 - precision_m: 0.9503 - recall_m: 0.9999 - val_loss: 0.6931 - val_acc: 0.3998 - val_f1_m: 0.9701 - val_precision_m: 0.9423 - val_recall_m: 1.0000\n",
      "Epoch 15/32\n",
      "169/169 [==============================] - 1s 3ms/step - loss: 0.6931 - acc: 0.5048 - f1_m: 0.9743 - precision_m: 0.9503 - recall_m: 1.0000 - val_loss: 0.6931 - val_acc: 0.3535 - val_f1_m: 0.9701 - val_precision_m: 0.9423 - val_recall_m: 1.0000\n",
      "Epoch 16/32\n",
      "169/169 [==============================] - 1s 4ms/step - loss: 0.6931 - acc: 0.5181 - f1_m: 0.9742 - precision_m: 0.9502 - recall_m: 0.9999 - val_loss: 0.6931 - val_acc: 0.1334 - val_f1_m: 0.9701 - val_precision_m: 0.9423 - val_recall_m: 1.0000\n",
      "Epoch 17/32\n",
      "169/169 [==============================] - 1s 3ms/step - loss: 0.6931 - acc: 0.5001 - f1_m: 0.9743 - precision_m: 0.9503 - recall_m: 0.9999 - val_loss: 0.6931 - val_acc: 0.1408 - val_f1_m: 0.9701 - val_precision_m: 0.9423 - val_recall_m: 1.0000\n",
      "Epoch 18/32\n",
      "169/169 [==============================] - 1s 3ms/step - loss: 0.6931 - acc: 0.4993 - f1_m: 0.9744 - precision_m: 0.9504 - recall_m: 1.0000 - val_loss: 0.6931 - val_acc: 0.6080 - val_f1_m: 0.9701 - val_precision_m: 0.9423 - val_recall_m: 1.0000\n",
      "Epoch 19/32\n",
      "169/169 [==============================] - 1s 3ms/step - loss: 0.6931 - acc: 0.5105 - f1_m: 0.9743 - precision_m: 0.9504 - recall_m: 0.9999 - val_loss: 0.6931 - val_acc: 0.1564 - val_f1_m: 0.9700 - val_precision_m: 0.9423 - val_recall_m: 0.9996\n",
      "Epoch 20/32\n",
      "169/169 [==============================] - 1s 3ms/step - loss: 0.6931 - acc: 0.4962 - f1_m: 0.9744 - precision_m: 0.9504 - recall_m: 1.0000 - val_loss: 0.6931 - val_acc: 0.1108 - val_f1_m: 0.9701 - val_precision_m: 0.9423 - val_recall_m: 1.0000\n",
      "Epoch 21/32\n",
      "169/169 [==============================] - 1s 3ms/step - loss: 0.6931 - acc: 0.4895 - f1_m: 0.9743 - precision_m: 0.9504 - recall_m: 0.9999 - val_loss: 0.6931 - val_acc: 0.1886 - val_f1_m: 0.9701 - val_precision_m: 0.9423 - val_recall_m: 1.0000\n",
      "Epoch 22/32\n",
      "169/169 [==============================] - 1s 3ms/step - loss: 0.6931 - acc: 0.5013 - f1_m: 0.9743 - precision_m: 0.9503 - recall_m: 0.9999 - val_loss: 0.6931 - val_acc: 0.1352 - val_f1_m: 0.9701 - val_precision_m: 0.9423 - val_recall_m: 1.0000\n"
     ]
    }
   ],
   "source": [
    "print('Joint full model with one hot encoding, predicting deception')\n",
    "joint_full_model = create_joint_model(pred_df_full)\n",
    "history = joint_full_model.fit(x=pred_df_full, y=y_train_deception, epochs=32, \n",
    "                    batch_size=64, \n",
    "                    validation_data=(pred_test_df_full,y_test_deception), callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joint full model with one hot encoding, predicting rapport\n",
      "Epoch 1/32\n",
      "169/169 [==============================] - 1s 5ms/step - loss: 0.6935 - acc: 0.4540 - f1_m: 0.7692 - precision_m: 0.6270 - recall_m: 1.0000 - val_loss: 0.6932 - val_acc: 0.5283 - val_f1_m: 0.7575 - val_precision_m: 0.6121 - val_recall_m: 1.0000\n",
      "Epoch 2/32\n",
      "169/169 [==============================] - 1s 3ms/step - loss: 0.6932 - acc: 0.5019 - f1_m: 0.7689 - precision_m: 0.6267 - recall_m: 1.0000 - val_loss: 0.6932 - val_acc: 0.4672 - val_f1_m: 0.7575 - val_precision_m: 0.6121 - val_recall_m: 1.0000\n",
      "Epoch 3/32\n",
      "169/169 [==============================] - 1s 3ms/step - loss: 0.6932 - acc: 0.4688 - f1_m: 0.7690 - precision_m: 0.6265 - recall_m: 1.0000 - val_loss: 0.6931 - val_acc: 0.4435 - val_f1_m: 0.7575 - val_precision_m: 0.6121 - val_recall_m: 1.0000\n",
      "Epoch 4/32\n",
      "169/169 [==============================] - 1s 3ms/step - loss: 0.6932 - acc: 0.4496 - f1_m: 0.7690 - precision_m: 0.6269 - recall_m: 1.0000 - val_loss: 0.6931 - val_acc: 0.4268 - val_f1_m: 0.7575 - val_precision_m: 0.6121 - val_recall_m: 1.0000\n",
      "Epoch 5/32\n",
      "169/169 [==============================] - 1s 3ms/step - loss: 0.6931 - acc: 0.4379 - f1_m: 0.7691 - precision_m: 0.6269 - recall_m: 1.0000 - val_loss: 0.6931 - val_acc: 0.4187 - val_f1_m: 0.7575 - val_precision_m: 0.6121 - val_recall_m: 1.0000\n",
      "Epoch 6/32\n",
      "169/169 [==============================] - 1s 4ms/step - loss: 0.6931 - acc: 0.4550 - f1_m: 0.7690 - precision_m: 0.6267 - recall_m: 1.0000 - val_loss: 0.6931 - val_acc: 0.4183 - val_f1_m: 0.7575 - val_precision_m: 0.6121 - val_recall_m: 1.0000\n",
      "Epoch 7/32\n",
      "169/169 [==============================] - 1s 4ms/step - loss: 0.6931 - acc: 0.4252 - f1_m: 0.7688 - precision_m: 0.6267 - recall_m: 1.0000 - val_loss: 0.6931 - val_acc: 0.4131 - val_f1_m: 0.7575 - val_precision_m: 0.6121 - val_recall_m: 1.0000\n",
      "Epoch 8/32\n",
      "169/169 [==============================] - 1s 3ms/step - loss: 0.6931 - acc: 0.4555 - f1_m: 0.7688 - precision_m: 0.6266 - recall_m: 1.0000 - val_loss: 0.6931 - val_acc: 0.4087 - val_f1_m: 0.7575 - val_precision_m: 0.6121 - val_recall_m: 1.0000\n",
      "Epoch 9/32\n",
      "169/169 [==============================] - 1s 3ms/step - loss: 0.6931 - acc: 0.4446 - f1_m: 0.7650 - precision_m: 0.6267 - recall_m: 0.9946 - val_loss: 0.6931 - val_acc: 0.4050 - val_f1_m: 0.7575 - val_precision_m: 0.6121 - val_recall_m: 1.0000\n"
     ]
    }
   ],
   "source": [
    "print('Joint full model with one hot encoding, predicting rapport')\n",
    "joint_full_model = create_joint_model(pred_df)\n",
    "history = joint_full_model.fit(x=pred_df, y=y_train_rapport, epochs=32, \n",
    "                    batch_size=64, \n",
    "                    validation_data=(pred_test_df,y_test_rapport), callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joint Model by Keras Concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_concatenate_keras_model(models_arr):\n",
    "    commonInput = Input(shape=[max_len])\n",
    "\n",
    "    input_model_arr = []\n",
    "    for model in models_arr: \n",
    "        outmodel = model(commonInput)\n",
    "        input_model_arr.append(outmodel)\n",
    "    \n",
    "    mergedOut = Concatenate()(input_model_arr)\n",
    "\n",
    "    mergedOut = Flatten()(mergedOut)    \n",
    "    mergedOut = Dense(256, activation='relu')(mergedOut)\n",
    "    mergedOut = Dropout(.5)(mergedOut)\n",
    "    mergedOut = Dense(128, activation='relu')(mergedOut)\n",
    "    mergedOut = Dropout(.35)(mergedOut)\n",
    "    mergedOut = Dense(2, activation='softmax')(mergedOut)  #Cuz binary\n",
    "\n",
    "    mergedModel = Model(commonInput, mergedOut)\n",
    "    mergedModel.compile(loss='binary_crossentropy', optimizer=RMSprop(), metrics=['accuracy', f1_m, recall_m, precision_m])\n",
    "    \n",
    "    return mergedModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joint model by concatenate, predicting deception\n",
      "Epoch 1/15\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.6932 - accuracy: 0.4996 - f1_m: 0.9745 - recall_m: 1.0000 - precision_m: 0.9504"
     ]
    }
   ],
   "source": [
    "print('Joint model by concatenate, predicting deception')\n",
    "merged_model = create_concatenate_keras_model([gamemove_model, reasoning_model, shareinfo_model, rapport_model])\n",
    "merged_model.fit(X_train,y_train_deception,\n",
    "          batch_size=128,\n",
    "          epochs=15,\n",
    "          validation_data=(X_test,y_test_deception), callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Joint model by concatenate, predicting rapport')\n",
    "merged_model = create_concatenate_keras_model([gamemove_model, reasoning_model, shareinfo_model])\n",
    "merged_model.fit(X_train,y_train_rapport,\n",
    "          batch_size=128,\n",
    "          epochs=15,\n",
    "          validation_data=(X_test,y_test_rapport), callbacks=[early_stop])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfgpu",
   "language": "python",
   "name": "tfgpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
