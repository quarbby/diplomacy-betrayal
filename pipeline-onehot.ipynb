{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import LSTM, Input, InputLayer, Dropout, Dense, Flatten, Embedding, Add, Concatenate\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "# import torch\n",
    "from sklearn.metrics import precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Good data\n",
    "# df = pd.read_csv('./data/kokil dec 6 reprepare/affcon_final_with_linguistics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Messy data\n",
    "# df = pd.read_csv('./data/affcon_final_politeness_strategies_merge.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data with Throughput & WorkTime\n",
    "df = pd.read_csv('./data/kokil dec 6 reprepare/conf_pc_worker_sem.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Throughput (weighted by variance)\n",
    "# df_throughput = df[['Throughput.1', 'Throughput.2', 'Throughput.3', 'Throughput.4', 'Throughput.5']].copy()\n",
    "# df_throughput['var_throughput'] = df_throughput.var(axis=1)\n",
    "# df_throughput['var_throughput'] = df_throughput['var_throughput'] / df_throughput['var_throughput'].max()\n",
    "\n",
    "#Throughput (weighted by inverted U-shape variance)\n",
    "df_throughput = df[['Throughput.1', 'Throughput.2', 'Throughput.3', 'Throughput.4', 'Throughput.5']].copy()\n",
    "df_throughput['var_throughput'] = df_throughput.var(axis=1)\n",
    "max_val = df_throughput['var_throughput'].max()\n",
    "min_val = df_throughput['var_throughput'].min()\n",
    "tp_mid = ((max_val - min_val) // 2) + min_val\n",
    "tp_to_list = df_throughput['var_throughput'].tolist()\n",
    "\n",
    "u_shaped_variance = []\n",
    "for each in tp_to_list:\n",
    "    if each > tp_mid:\n",
    "        u_shaped_variance.append(2*tp_mid - each)\n",
    "    else:\n",
    "        u_shaped_variance.append(each)\n",
    "        \n",
    "df_throughput['var_throughput_u_shaped'] = u_shaped_variance\n",
    "df_throughput['var_throughput_u_shaped'] = df_throughput['var_throughput_u_shaped'] / df_throughput['var_throughput_u_shaped'].max()\n",
    "df_throughput = df_throughput.assign(var_throughput=df_throughput['var_throughput_u_shaped'])\n",
    "\n",
    "# # WorkTime (weighted by variance)\n",
    "df_worktime = df[['WorkTime.1', 'WorkTime.2', 'WorkTime.3', 'WorkTime.4', 'WorkTime.5']].copy()\n",
    "df_worktime['var_worktime'] = df_worktime.var(axis=1)\n",
    "df_worktime['var_worktime'] = df_worktime['var_worktime'] / df_worktime['var_worktime'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Throughput.1</th>\n",
       "      <th>Throughput.2</th>\n",
       "      <th>Throughput.3</th>\n",
       "      <th>Throughput.4</th>\n",
       "      <th>Throughput.5</th>\n",
       "      <th>var_throughput</th>\n",
       "      <th>var_throughput_u_shaped</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>390</td>\n",
       "      <td>2331</td>\n",
       "      <td>193</td>\n",
       "      <td>2139</td>\n",
       "      <td>162.0</td>\n",
       "      <td>0.743479</td>\n",
       "      <td>0.743479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>234</td>\n",
       "      <td>2134</td>\n",
       "      <td>2331</td>\n",
       "      <td>1022</td>\n",
       "      <td>1411.0</td>\n",
       "      <td>0.451285</td>\n",
       "      <td>0.451285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>521</td>\n",
       "      <td>2139</td>\n",
       "      <td>2660</td>\n",
       "      <td>1411</td>\n",
       "      <td>892.0</td>\n",
       "      <td>0.479614</td>\n",
       "      <td>0.479614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2632</td>\n",
       "      <td>2415</td>\n",
       "      <td>1482</td>\n",
       "      <td>892</td>\n",
       "      <td>3747.0</td>\n",
       "      <td>0.753045</td>\n",
       "      <td>0.753045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2905</td>\n",
       "      <td>95</td>\n",
       "      <td>528</td>\n",
       "      <td>892</td>\n",
       "      <td>300.0</td>\n",
       "      <td>0.801213</td>\n",
       "      <td>0.801213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13189</th>\n",
       "      <td>1168</td>\n",
       "      <td>2632</td>\n",
       "      <td>2415</td>\n",
       "      <td>19</td>\n",
       "      <td>2139.0</td>\n",
       "      <td>0.726839</td>\n",
       "      <td>0.726839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13190</th>\n",
       "      <td>1252</td>\n",
       "      <td>501</td>\n",
       "      <td>13</td>\n",
       "      <td>390</td>\n",
       "      <td>408.0</td>\n",
       "      <td>0.127779</td>\n",
       "      <td>0.127779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13191</th>\n",
       "      <td>575</td>\n",
       "      <td>1252</td>\n",
       "      <td>2660</td>\n",
       "      <td>1601</td>\n",
       "      <td>1014.0</td>\n",
       "      <td>0.384920</td>\n",
       "      <td>0.384920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13192</th>\n",
       "      <td>251</td>\n",
       "      <td>390</td>\n",
       "      <td>331</td>\n",
       "      <td>528</td>\n",
       "      <td>297.0</td>\n",
       "      <td>0.007118</td>\n",
       "      <td>0.007118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13193</th>\n",
       "      <td>2905</td>\n",
       "      <td>2632</td>\n",
       "      <td>2415</td>\n",
       "      <td>2139</td>\n",
       "      <td>619.0</td>\n",
       "      <td>0.499721</td>\n",
       "      <td>0.499721</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11366 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Throughput.1  Throughput.2  Throughput.3  Throughput.4  Throughput.5  \\\n",
       "5               390          2331           193          2139         162.0   \n",
       "6               234          2134          2331          1022        1411.0   \n",
       "7               521          2139          2660          1411         892.0   \n",
       "8              2632          2415          1482           892        3747.0   \n",
       "9              2905            95           528           892         300.0   \n",
       "...             ...           ...           ...           ...           ...   \n",
       "13189          1168          2632          2415            19        2139.0   \n",
       "13190          1252           501            13           390         408.0   \n",
       "13191           575          1252          2660          1601        1014.0   \n",
       "13192           251           390           331           528         297.0   \n",
       "13193          2905          2632          2415          2139         619.0   \n",
       "\n",
       "       var_throughput  var_throughput_u_shaped  \n",
       "5            0.743479                 0.743479  \n",
       "6            0.451285                 0.451285  \n",
       "7            0.479614                 0.479614  \n",
       "8            0.753045                 0.753045  \n",
       "9            0.801213                 0.801213  \n",
       "...               ...                      ...  \n",
       "13189        0.726839                 0.726839  \n",
       "13190        0.127779                 0.127779  \n",
       "13191        0.384920                 0.384920  \n",
       "13192        0.007118                 0.007118  \n",
       "13193        0.499721                 0.499721  \n",
       "\n",
       "[11366 rows x 7 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_throughput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = range(df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Individual Classifiers are LSTMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test, indices_train, indices_test = train_test_split(df, indices, test_size=0.2)\n",
    "\n",
    "new_deception_train = train[\"Input.deception_quadrant\"].copy()\n",
    "new_deception_train['Input.deception_quadrant'] = train[\"Input.deception_quadrant\"].apply(lambda x : 1 if x == \"Straightforward\" else 0)\n",
    "y_train_deception = new_deception_train['Input.deception_quadrant'].tolist()\n",
    "y_train_rapport = train['Answer.3rapport.yes_label'].tolist()\n",
    "y_train_share_information = train['Answer.4shareinformation.yes_label'].tolist()\n",
    "y_train_reasoning = train['Answer.2reasoning.yes_label'].tolist()\n",
    "y_train_gamemove = train['Answer.1gamemove.yes_label'].tolist()\n",
    "\n",
    "X_train_col = train['Input.full_text']\n",
    "\n",
    "new_deception_test = test[\"Input.deception_quadrant\"].copy()\n",
    "new_deception_test['Input.deception_quadrant'] = test[\"Input.deception_quadrant\"].apply(lambda x : 1 if x == \"Straightforward\" else 0)\n",
    "y_test_deception = new_deception_test['Input.deception_quadrant'].tolist()\n",
    "y_test_rapport = test['Answer.3rapport.yes_label'].tolist()\n",
    "y_test_share_information = test['Answer.4shareinformation.yes_label'].tolist()\n",
    "y_test_reasoning = test['Answer.2reasoning.yes_label'].tolist()\n",
    "y_test_gamemove = test['Answer.1gamemove.yes_label'].tolist()\n",
    "\n",
    "X_test_col = test['Input.full_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', min_delta=0, patience=0, verbose=0, mode='auto',\n",
    "    baseline=None, restore_best_weights=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaiyuan/anaconda3/envs/TF2/lib/python3.6/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "\n",
    "y_train_deception = le.fit_transform(y_train_deception)\n",
    "y_train_deception = y_train_deception.reshape(-1,1)\n",
    "\n",
    "y_train_rapport = le.fit_transform(y_train_rapport)\n",
    "y_train_rapport = y_train_rapport.reshape(-1,1)\n",
    "\n",
    "y_train_share_information = le.fit_transform(y_train_share_information)\n",
    "y_train_share_information = y_train_share_information.reshape(-1,1)\n",
    "\n",
    "y_train_reasoning = le.fit_transform(y_train_reasoning)\n",
    "y_train_reasoning = y_train_reasoning.reshape(-1,1)\n",
    "\n",
    "y_train_gamemove = le.fit_transform(y_train_gamemove)\n",
    "y_train_gamemove = y_train_gamemove.reshape(-1,1)\n",
    "\n",
    "y_train_deception = le.fit_transform(y_train_deception)\n",
    "y_train_deception = y_train_deception.reshape(-1,1)\n",
    "\n",
    "y_test_rapport = le.fit_transform(y_test_rapport)\n",
    "y_test_rapport = y_test_rapport.reshape(-1,1)\n",
    "\n",
    "y_test_share_information = le.fit_transform(y_test_share_information)\n",
    "y_test_share_information = y_test_share_information.reshape(-1,1)\n",
    "\n",
    "y_test_reasoning = le.fit_transform(y_test_reasoning)\n",
    "y_test_reasoning = y_test_reasoning.reshape(-1,1)\n",
    "\n",
    "y_test_gamemove = le.fit_transform(y_test_gamemove)\n",
    "y_test_gamemove = y_test_gamemove.reshape(-1,1)\n",
    "\n",
    "y_test_deception = le.fit_transform(y_test_deception)\n",
    "y_test_deception = y_test_deception.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 1000\n",
    "max_len = 220\n",
    "\n",
    "tok = Tokenizer(num_words=max_words)\n",
    "\n",
    "tok.fit_on_texts(X_train_col)\n",
    "X_train_sequences = tok.texts_to_sequences(X_train_col)\n",
    "X_train = pad_sequences(X_train_sequences, maxlen=max_len)\n",
    "\n",
    "# tok.fit_on_texts(X_test_col)\n",
    "X_test_sequences = tok.texts_to_sequences(X_test_col)\n",
    "X_test = pad_sequences(X_test_sequences, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss',min_delta=0.00001)\n",
    "def create_lstm():\n",
    "    Inp = Input(name='inputs', shape=[max_len])\n",
    "    x = Embedding(max_words, 50, input_length=max_len)(Inp)\n",
    "    x = LSTM(64, name='LSTM_01')(x)\n",
    "    x = Dropout(0.5, name='Dropout')(x)\n",
    "    x = Dense(128, activation='relu',name='Dense_01')(x)\n",
    "    # x = Dropout(0.5,name='Dropout')(x)\n",
    "    out = Dense(1,activation='sigmoid', name='output')(x)\n",
    "    model = Model(inputs=Inp, outputs=out)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct individual LSTM models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "72/72 [==============================] - 2s 27ms/step - loss: 0.4287 - accuracy: 0.8557 - f1_m: 0.9226 - recall_m: 0.9954 - precision_m: 0.8609 - val_loss: 0.3904 - val_accuracy: 0.8769 - val_f1_m: 0.9340 - val_recall_m: 1.0000 - val_precision_m: 0.8767\n",
      "Epoch 2/15\n",
      "72/72 [==============================] - 1s 21ms/step - loss: 0.4127 - accuracy: 0.8590 - f1_m: 0.9249 - recall_m: 1.0000 - precision_m: 0.8609 - val_loss: 0.3853 - val_accuracy: 0.8769 - val_f1_m: 0.9340 - val_recall_m: 1.0000 - val_precision_m: 0.8767\n",
      "Epoch 3/15\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.4094 - accuracy: 0.8590 - f1_m: 0.9249 - recall_m: 1.0000 - precision_m: 0.8609 - val_loss: 0.3882 - val_accuracy: 0.8769 - val_f1_m: 0.9340 - val_recall_m: 1.0000 - val_precision_m: 0.8767\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fbec576e208>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rapport model\n",
    "rapport_model = create_lstm()\n",
    "rapport_model.compile(loss='binary_crossentropy',optimizer=RMSprop(),metrics=['accuracy', f1_m, recall_m, precision_m])\n",
    "rapport_model.fit(X_train,y_train_rapport,\n",
    "          batch_size=128,\n",
    "          epochs=15,\n",
    "          validation_data=(X_test, y_test_rapport), callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rapport_pred = rapport_model.predict(X_train)\n",
    "rapport_pred_test = rapport_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaiyuan/anaconda3/envs/TF2/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4384344766930519, 0.5, 0.46719775070290537, None)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rapport_pred_test_round = rapport_pred_test.round()\n",
    "precision_recall_fscore_support(y_test_rapport, rapport_pred_test_round, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "72/72 [==============================] - 2s 25ms/step - loss: 0.2858 - accuracy: 0.9232 - f1_m: 0.9595 - recall_m: 0.9933 - precision_m: 0.9300 - val_loss: 0.2405 - val_accuracy: 0.9362 - val_f1_m: 0.9669 - val_recall_m: 1.0000 - val_precision_m: 0.9363\n",
      "Epoch 2/15\n",
      "72/72 [==============================] - 2s 22ms/step - loss: 0.2593 - accuracy: 0.9294 - f1_m: 0.9638 - recall_m: 1.0000 - precision_m: 0.9303 - val_loss: 0.2370 - val_accuracy: 0.9362 - val_f1_m: 0.9669 - val_recall_m: 1.0000 - val_precision_m: 0.9363\n",
      "Epoch 3/15\n",
      "72/72 [==============================] - 2s 24ms/step - loss: 0.2570 - accuracy: 0.9294 - f1_m: 0.9618 - recall_m: 1.0000 - precision_m: 0.9270 - val_loss: 0.2527 - val_accuracy: 0.9362 - val_f1_m: 0.9669 - val_recall_m: 1.0000 - val_precision_m: 0.9363\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fbeac627fd0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Game move model\n",
    "gamemove_model = create_lstm()\n",
    "gamemove_model.compile(loss='binary_crossentropy',optimizer=RMSprop(),metrics=['accuracy', f1_m, recall_m, precision_m])\n",
    "gamemove_model.fit(X_train,y_train_gamemove,\n",
    "          batch_size=128,\n",
    "          epochs=15,\n",
    "          validation_data=(X_test, y_test_gamemove), callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamemove_pred = gamemove_model.predict(X_train)\n",
    "gamemove_pred_test = gamemove_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.46811785400175904, 0.5, 0.48353395412218947, None)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gamemove_pred_test_round = gamemove_pred_test.round()\n",
    "precision_recall_fscore_support(y_test_gamemove, gamemove_pred_test_round, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "72/72 [==============================] - 2s 26ms/step - loss: 0.4774 - accuracy: 0.8259 - f1_m: 0.9052 - recall_m: 0.9964 - precision_m: 0.8308 - val_loss: 0.4544 - val_accuracy: 0.8347 - val_f1_m: 0.9097 - val_recall_m: 1.0000 - val_precision_m: 0.8347\n",
      "Epoch 2/15\n",
      "72/72 [==============================] - 2s 25ms/step - loss: 0.4647 - accuracy: 0.8279 - f1_m: 0.9048 - recall_m: 1.0000 - precision_m: 0.8268 - val_loss: 0.4482 - val_accuracy: 0.8347 - val_f1_m: 0.9097 - val_recall_m: 1.0000 - val_precision_m: 0.8347\n",
      "Epoch 3/15\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.4589 - accuracy: 0.8279 - f1_m: 0.9066 - recall_m: 1.0000 - precision_m: 0.8302 - val_loss: 0.4639 - val_accuracy: 0.8347 - val_f1_m: 0.9097 - val_recall_m: 1.0000 - val_precision_m: 0.8347\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fbea00b9f60>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reasoning model\n",
    "reasoning_model = create_lstm()\n",
    "reasoning_model.compile(loss='binary_crossentropy',optimizer=RMSprop(),metrics=['accuracy', f1_m, recall_m, precision_m])\n",
    "reasoning_model.fit(X_train,y_train_reasoning,\n",
    "          batch_size=128,\n",
    "          epochs=15,\n",
    "          validation_data=(X_test, y_test_reasoning), callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "reasoning_pred = reasoning_model.predict(X_train)\n",
    "reasoning_pred_test = reasoning_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4173262972735268, 0.5, 0.4549376797698946, None)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reasoning_pred_test_round = reasoning_pred_test.round()\n",
    "precision_recall_fscore_support(y_test_reasoning, reasoning_pred_test_round, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "72/72 [==============================] - 2s 26ms/step - loss: 0.4662 - accuracy: 0.8316 - f1_m: 0.9049 - recall_m: 0.9886 - precision_m: 0.8413 - val_loss: 0.4382 - val_accuracy: 0.8461 - val_f1_m: 0.9162 - val_recall_m: 1.0000 - val_precision_m: 0.8460\n",
      "Epoch 2/15\n",
      "72/72 [==============================] - 2s 21ms/step - loss: 0.4477 - accuracy: 0.8392 - f1_m: 0.9115 - recall_m: 1.0000 - precision_m: 0.8380 - val_loss: 0.4382 - val_accuracy: 0.8461 - val_f1_m: 0.9162 - val_recall_m: 1.0000 - val_precision_m: 0.8460\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fbe4c494cc0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Share Information model\n",
    "shareinfo_model = create_lstm()\n",
    "shareinfo_model.compile(loss='binary_crossentropy',optimizer=RMSprop(),metrics=['accuracy', f1_m, recall_m, precision_m])\n",
    "shareinfo_model.fit(X_train,y_train_share_information,\n",
    "          batch_size=128,\n",
    "          epochs=15,\n",
    "          validation_data=(X_test, y_test_share_information), callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "shareinfo_pred = shareinfo_model.predict(X_train)\n",
    "shareinfo_pred_test = shareinfo_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4230430958663149, 0.5, 0.45831348261076704, None)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shareinfo_pred_test_round = shareinfo_pred_test.round()\n",
    "precision_recall_fscore_support(y_test_share_information, shareinfo_pred_test_round, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "72/72 [==============================] - 2s 26ms/step - loss: 0.2292 - accuracy: 0.9449 - f1_m: 0.9710 - recall_m: 0.9935 - precision_m: 0.9515 - val_loss: 0.1981 - val_accuracy: 0.9512 - val_f1_m: 0.9750 - val_recall_m: 1.0000 - val_precision_m: 0.9514\n",
      "Epoch 2/15\n",
      "72/72 [==============================] - 2s 21ms/step - loss: 0.2006 - accuracy: 0.9508 - f1_m: 0.9750 - recall_m: 1.0000 - precision_m: 0.9515 - val_loss: 0.1988 - val_accuracy: 0.9512 - val_f1_m: 0.9750 - val_recall_m: 1.0000 - val_precision_m: 0.9514\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fbe1c250fd0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Deception model\n",
    "deception_model = create_lstm()\n",
    "deception_model.compile(loss='binary_crossentropy',optimizer=RMSprop(),metrics=['accuracy', f1_m, recall_m, precision_m])\n",
    "deception_model.fit(X_train,y_train_deception,\n",
    "          batch_size=128,\n",
    "          epochs=15,\n",
    "          validation_data=(X_test, y_test_deception), callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.47559366754617416, 0.5, 0.48749154834347536, None)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deception_pred = deception_model.predict(X_train)\n",
    "deception_pred_test = deception_model.predict(X_test)\n",
    "deception_pred_test_round = deception_pred_test.round()\n",
    "precision_recall_fscore_support(y_test_deception, deception_pred_test_round, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One hot encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train encodings\n",
    "pred_df_arr_full = []\n",
    "pred_df_arr = []\n",
    "for i in range(0, len(gamemove_pred)):\n",
    "    pred_obj_1 = {}\n",
    "    pred_obj_1['gamemove'] = gamemove_pred[i][0]\n",
    "    pred_obj_1['reasoning'] = reasoning_pred[i][0]\n",
    "    pred_obj_1['shareinfo'] = shareinfo_pred[i][0]\n",
    "    pred_df_arr.append(pred_obj_1)\n",
    "    \n",
    "    pred_obj_2 = pred_obj_1.copy()\n",
    "    pred_obj_2['rapport'] = rapport_pred[i][0]\n",
    "    pred_df_arr_full.append(pred_obj_2)\n",
    "    \n",
    "pred_df_full = pd.DataFrame(pred_df_arr_full)\n",
    "pred_df = pd.DataFrame(pred_df_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test encodings\n",
    "pred_test_df_arr_full = []\n",
    "pred_test_df_arr = []\n",
    "\n",
    "for i in range(0, len(gamemove_pred_test)):\n",
    "    pred_obj_1 = {}\n",
    "    pred_obj_1['gamemove'] = gamemove_pred_test[i][0]\n",
    "    pred_obj_1['reasoning'] = reasoning_pred_test[i][0]\n",
    "    pred_obj_1['shareinfo'] = shareinfo_pred_test[i][0]\n",
    "    pred_test_df_arr.append(pred_obj_1)\n",
    "    \n",
    "    pred_obj_2 = pred_obj_1.copy()\n",
    "    pred_obj_2['rapport'] = rapport_pred_test[i][0]\n",
    "    pred_test_df_arr_full.append(pred_obj_2)\n",
    "    \n",
    "pred_test_df_full = pd.DataFrame(pred_test_df_arr_full)\n",
    "pred_test_df = pd.DataFrame(pred_test_df_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joint Model with one hot encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_joint_model(df):\n",
    "    inputB = Input(shape=(df.shape[1],))\n",
    "    c = Dense(2, activation='relu')(inputB)\n",
    "    c = Dense(4, activation='relu')(c)\n",
    "    c = Dense(1, activation='softmax')(c)\n",
    "    full_model = Model(inputs=inputB, outputs=c)\n",
    "\n",
    "    full_model.compile(loss='binary_crossentropy', optimizer='adam', \n",
    "                          metrics=['acc',f1_m,precision_m, recall_m])\n",
    "    \n",
    "    return full_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joint full model with one hot encoding, predicting deception\n",
      "Model: \"functional_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 4)]               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 12        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 27\n",
      "Trainable params: 27\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/32\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.7497 - acc: 0.9508 - f1_m: 0.9738 - precision_m: 0.9495 - recall_m: 1.0000 - val_loss: 0.7444 - val_acc: 0.9512 - val_f1_m: 0.9750 - val_precision_m: 0.9514 - val_recall_m: 1.0000\n",
      "Epoch 2/32\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.7497 - acc: 0.9508 - f1_m: 0.9748 - precision_m: 0.9512 - recall_m: 1.0000 - val_loss: 0.7444 - val_acc: 0.9512 - val_f1_m: 0.9750 - val_precision_m: 0.9514 - val_recall_m: 1.0000\n"
     ]
    }
   ],
   "source": [
    "print('Joint full model with one hot encoding, predicting deception')\n",
    "joint_full_model = create_joint_model(pred_df_full)\n",
    "joint_full_model.summary()\n",
    "history = joint_full_model.fit(x=pred_df_full, y=y_train_deception, epochs=32, \n",
    "                    batch_size=64, \n",
    "                    validation_data=(pred_test_df_full,y_test_deception), callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaiyuan/anaconda3/envs/TF2/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.024406332453825858, 0.5, 0.04654088050314466, None)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joint_predict = joint_full_model.predict(pred_test_df_full)\n",
    "joint_predict_round = []\n",
    "for a in joint_predict:\n",
    "    joint_predict_round.append([np.argmax(a)])\n",
    "precision_recall_fscore_support(y_test_deception, np.array(joint_predict_round), average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joint full model with one hot encoding, predicting rapport\n",
      "Model: \"functional_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 3)]               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 8         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 4)                 12        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 25\n",
      "Trainable params: 25\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/32\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 2.1502 - acc: 0.8590 - f1_m: 0.9241 - precision_m: 0.8599 - recall_m: 1.0000 - val_loss: 1.8777 - val_acc: 0.8769 - val_f1_m: 0.9338 - val_precision_m: 0.8766 - val_recall_m: 1.0000\n",
      "Epoch 2/32\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 2.1502 - acc: 0.8590 - f1_m: 0.9241 - precision_m: 0.8599 - recall_m: 1.0000 - val_loss: 1.8777 - val_acc: 0.8769 - val_f1_m: 0.9338 - val_precision_m: 0.8766 - val_recall_m: 1.0000\n"
     ]
    }
   ],
   "source": [
    "print('Joint full model with one hot encoding, predicting rapport')\n",
    "joint_full_model = create_joint_model(pred_df)\n",
    "joint_full_model.summary()\n",
    "history = joint_full_model.fit(x=pred_df, y=y_train_rapport, epochs=32, \n",
    "                    batch_size=64, \n",
    "                    validation_data=(pred_test_df,y_test_rapport), callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaiyuan/anaconda3/envs/TF2/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.06156552330694811, 0.5, 0.1096319498825372, None)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joint_predict = joint_full_model.predict(pred_test_df)\n",
    "joint_predict_round = []\n",
    "for a in joint_predict:\n",
    "    joint_predict_round.append([np.argmax(a)])\n",
    "precision_recall_fscore_support(y_test_rapport, np.array(joint_predict_round), average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joint Model by Keras Concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_concatenate_keras_model(models_arr):\n",
    "    commonInput = Input(shape=[max_len])\n",
    "\n",
    "    input_model_arr = []\n",
    "    for model in models_arr: \n",
    "        outmodel = model(commonInput)\n",
    "        input_model_arr.append(outmodel)\n",
    "    \n",
    "    mergedOut = Concatenate()(input_model_arr)\n",
    "\n",
    "    mergedOut = Flatten()(mergedOut)    \n",
    "    mergedOut = Dense(256, activation='relu')(mergedOut)\n",
    "    mergedOut = Dropout(.5)(mergedOut)\n",
    "    mergedOut = Dense(128, activation='relu')(mergedOut)\n",
    "    mergedOut = Dropout(.35)(mergedOut)\n",
    "    mergedOut = Dense(1, activation='softmax')(mergedOut)  #Cuz binary\n",
    "\n",
    "    mergedModel = Model(commonInput, mergedOut)\n",
    "    mergedModel.compile(loss='binary_crossentropy', optimizer=RMSprop(), metrics=['accuracy', f1_m, recall_m, precision_m])\n",
    "    \n",
    "    return mergedModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joint model by concatenate, predicting deception\n",
      "Model: \"functional_15\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 220)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "functional_3 (Functional)       (None, 1)            87889       input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "functional_5 (Functional)       (None, 1)            87889       input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "functional_7 (Functional)       (None, 1)            87889       input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "functional_1 (Functional)       (None, 1)            87889       input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 4)            0           functional_3[0][0]               \n",
      "                                                                 functional_5[0][0]               \n",
      "                                                                 functional_7[0][0]               \n",
      "                                                                 functional_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 4)            0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 256)          1280        flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 256)          0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 128)          32896       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 128)          0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 1)            129         dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 385,861\n",
      "Trainable params: 385,861\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/15\n",
      "72/72 [==============================] - 6s 77ms/step - loss: 0.7497 - accuracy: 0.9508 - f1_m: 0.9751 - recall_m: 1.0000 - precision_m: 0.9515 - val_loss: 0.7444 - val_accuracy: 0.9512 - val_f1_m: 0.9750 - val_recall_m: 1.0000 - val_precision_m: 0.9514\n",
      "Epoch 2/15\n",
      "72/72 [==============================] - 5s 66ms/step - loss: 0.7497 - accuracy: 0.9508 - f1_m: 0.9750 - recall_m: 1.0000 - precision_m: 0.9515 - val_loss: 0.7444 - val_accuracy: 0.9512 - val_f1_m: 0.9750 - val_recall_m: 1.0000 - val_precision_m: 0.9514\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fbdf45b1cc0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Joint model by concatenate, predicting deception')\n",
    "merged_model = create_concatenate_keras_model([gamemove_model, reasoning_model, shareinfo_model, rapport_model])\n",
    "merged_model.summary()\n",
    "merged_model.fit(X_train,y_train_deception,\n",
    "          batch_size=128,\n",
    "          epochs=15,\n",
    "          validation_data=(X_test,y_test_deception), callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joint model by concatenate, predicting rapport\n",
      "Model: \"functional_17\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 220)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "functional_3 (Functional)       (None, 1)            87889       input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "functional_5 (Functional)       (None, 1)            87889       input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "functional_7 (Functional)       (None, 1)            87889       input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 3)            0           functional_3[1][0]               \n",
      "                                                                 functional_5[1][0]               \n",
      "                                                                 functional_7[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 3)            0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 256)          1024        flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 256)          0           dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 128)          32896       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 128)          0           dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 1)            129         dropout_3[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 297,716\n",
      "Trainable params: 297,716\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/15\n",
      "72/72 [==============================] - 4s 58ms/step - loss: 2.1502 - accuracy: 0.8590 - f1_m: 0.9248 - recall_m: 1.0000 - precision_m: 0.8609 - val_loss: 1.8777 - val_accuracy: 0.8769 - val_f1_m: 0.9340 - val_recall_m: 1.0000 - val_precision_m: 0.8767\n",
      "Epoch 2/15\n",
      "72/72 [==============================] - 4s 49ms/step - loss: 2.1502 - accuracy: 0.8590 - f1_m: 0.9249 - recall_m: 1.0000 - precision_m: 0.8609 - val_loss: 1.8777 - val_accuracy: 0.8769 - val_f1_m: 0.9340 - val_recall_m: 1.0000 - val_precision_m: 0.8767\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fbdc0101630>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Joint model by concatenate, predicting rapport')\n",
    "merged_model = create_concatenate_keras_model([gamemove_model, reasoning_model, shareinfo_model])\n",
    "merged_model.summary()\n",
    "merged_model.fit(X_train,y_train_rapport,\n",
    "          batch_size=128,\n",
    "          epochs=15,\n",
    "          validation_data=(X_test,y_test_rapport), callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weighted against Throughput & WorkTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train weighted encodings\n",
    "pred_df_full_throughput = pred_df_full.copy()\n",
    "pred_df_full_worktime = pred_df_full.copy()\n",
    "pred_df_throughput = pred_df.copy()\n",
    "pred_df_worktime = pred_df.copy()\n",
    "\n",
    "throughput_values = df_throughput['var_throughput'].take(indices_train).values\n",
    "pred_df_full_throughput = pred_df_full_throughput.mul(throughput_values, axis=0)\n",
    "pred_df_throughput = pred_df_throughput.mul(throughput_values, axis=0)\n",
    "\n",
    "worktime_values = df_worktime['var_worktime'].take(indices_train).values\n",
    "pred_df_full_worktime = pred_df_full_worktime.mul(worktime_values, axis=0)\n",
    "pred_df_worktime = pred_df_worktime.mul(worktime_values, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gamemove</th>\n",
       "      <th>reasoning</th>\n",
       "      <th>shareinfo</th>\n",
       "      <th>rapport</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.904174</td>\n",
       "      <td>0.916218</td>\n",
       "      <td>0.811955</td>\n",
       "      <td>0.933604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.897872</td>\n",
       "      <td>0.918377</td>\n",
       "      <td>0.803144</td>\n",
       "      <td>0.944711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.895877</td>\n",
       "      <td>0.904362</td>\n",
       "      <td>0.790460</td>\n",
       "      <td>0.939799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.901822</td>\n",
       "      <td>0.880043</td>\n",
       "      <td>0.797400</td>\n",
       "      <td>0.923424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.884904</td>\n",
       "      <td>0.909780</td>\n",
       "      <td>0.809640</td>\n",
       "      <td>0.924574</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gamemove  reasoning  shareinfo   rapport\n",
       "0  0.904174   0.916218   0.811955  0.933604\n",
       "1  0.897872   0.918377   0.803144  0.944711\n",
       "2  0.895877   0.904362   0.790460  0.939799\n",
       "3  0.901822   0.880043   0.797400  0.923424\n",
       "4  0.884904   0.909780   0.809640  0.924574"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gamemove</th>\n",
       "      <th>reasoning</th>\n",
       "      <th>shareinfo</th>\n",
       "      <th>rapport</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.004403</td>\n",
       "      <td>0.004461</td>\n",
       "      <td>0.003954</td>\n",
       "      <td>0.004546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.754537</td>\n",
       "      <td>0.771769</td>\n",
       "      <td>0.674931</td>\n",
       "      <td>0.793899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.417646</td>\n",
       "      <td>0.421602</td>\n",
       "      <td>0.368502</td>\n",
       "      <td>0.438122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.791001</td>\n",
       "      <td>0.771898</td>\n",
       "      <td>0.699411</td>\n",
       "      <td>0.809948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.432799</td>\n",
       "      <td>0.444966</td>\n",
       "      <td>0.395988</td>\n",
       "      <td>0.452201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gamemove  reasoning  shareinfo   rapport\n",
       "0  0.004403   0.004461   0.003954  0.004546\n",
       "1  0.754537   0.771769   0.674931  0.793899\n",
       "2  0.417646   0.421602   0.368502  0.438122\n",
       "3  0.791001   0.771898   0.699411  0.809948\n",
       "4  0.432799   0.444966   0.395988  0.452201"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df_full_throughput.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test weighted encodings\n",
    "pred_df_full_throughput_test = pred_test_df_full.copy()\n",
    "pred_df_full_worktime_test = pred_test_df_full.copy()\n",
    "pred_df_throughput_test = pred_test_df.copy()\n",
    "pred_df_worktime_test = pred_test_df.copy()\n",
    "\n",
    "throughput_values_test = df_throughput['var_throughput'].take(indices_test).values\n",
    "pred_df_full_throughput_test = pred_df_full_throughput_test.mul(throughput_values_test, axis=0)\n",
    "pred_df_throughput_test = pred_df_throughput_test.mul(throughput_values_test, axis=0)\n",
    "\n",
    "worktime_values_test = df_worktime['var_worktime'].take(indices_test).values\n",
    "pred_df_full_worktime_test = pred_df_full_worktime_test.mul(worktime_values_test, axis=0)\n",
    "pred_df_worktime_test = pred_df_worktime_test.mul(worktime_values_test, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gamemove</th>\n",
       "      <th>reasoning</th>\n",
       "      <th>shareinfo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.111068</td>\n",
       "      <td>0.107816</td>\n",
       "      <td>0.101914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.842065</td>\n",
       "      <td>0.825836</td>\n",
       "      <td>0.746711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.526439</td>\n",
       "      <td>0.529091</td>\n",
       "      <td>0.463505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.011915</td>\n",
       "      <td>0.011823</td>\n",
       "      <td>0.010660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.605660</td>\n",
       "      <td>0.624752</td>\n",
       "      <td>0.543460</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gamemove  reasoning  shareinfo\n",
       "0  0.111068   0.107816   0.101914\n",
       "1  0.842065   0.825836   0.746711\n",
       "2  0.526439   0.529091   0.463505\n",
       "3  0.011915   0.011823   0.010660\n",
       "4  0.605660   0.624752   0.543460"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df_throughput_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gamemove</th>\n",
       "      <th>reasoning</th>\n",
       "      <th>shareinfo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.857640</td>\n",
       "      <td>0.832532</td>\n",
       "      <td>0.786955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.890549</td>\n",
       "      <td>0.873386</td>\n",
       "      <td>0.789704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.890432</td>\n",
       "      <td>0.894917</td>\n",
       "      <td>0.783984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.893293</td>\n",
       "      <td>0.886343</td>\n",
       "      <td>0.799185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.885502</td>\n",
       "      <td>0.913415</td>\n",
       "      <td>0.794562</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gamemove  reasoning  shareinfo\n",
       "0  0.857640   0.832532   0.786955\n",
       "1  0.890549   0.873386   0.789704\n",
       "2  0.890432   0.894917   0.783984\n",
       "3  0.893293   0.886343   0.799185\n",
       "4  0.885502   0.913415   0.794562"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Throughput only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joint Model with one hot encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_joint_model(df):\n",
    "    inputB = Input(shape=(df.shape[1],))\n",
    "    c = Dense(2, activation='relu')(inputB)\n",
    "    c = Dense(4, activation='relu')(c)\n",
    "    c = Dense(1, activation='softmax')(c)\n",
    "    full_model = Model(inputs=inputB, outputs=c)\n",
    "\n",
    "    full_model.compile(loss='binary_crossentropy', optimizer='adam', \n",
    "                          metrics=['acc',f1_m,precision_m, recall_m])\n",
    "    \n",
    "    return full_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joint full model with one hot encoding, predicting deception, weighted by throughput\n",
      "Model: \"functional_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         [(None, 4)]               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 4)                 12        \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 27\n",
      "Trainable params: 27\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/32\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.7497 - acc: 0.9508 - f1_m: 0.9748 - precision_m: 0.9512 - recall_m: 1.0000 - val_loss: 0.7444 - val_acc: 0.9512 - val_f1_m: 0.9750 - val_precision_m: 0.9514 - val_recall_m: 1.0000\n",
      "Epoch 2/32\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.7497 - acc: 0.9508 - f1_m: 0.9748 - precision_m: 0.9512 - recall_m: 1.0000 - val_loss: 0.7444 - val_acc: 0.9512 - val_f1_m: 0.9750 - val_precision_m: 0.9514 - val_recall_m: 1.0000\n"
     ]
    }
   ],
   "source": [
    "print('Joint full model with one hot encoding, predicting deception, weighted by throughput')\n",
    "joint_full_model = create_joint_model(pred_df_full_throughput)\n",
    "joint_full_model.summary()\n",
    "history = joint_full_model.fit(x=pred_df_full_throughput, y=y_train_deception, epochs=32, \n",
    "                    batch_size=64, \n",
    "                    validation_data=(pred_df_full_throughput_test,y_test_deception), callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaiyuan/anaconda3/envs/TF2/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.024406332453825858, 0.5, 0.04654088050314466, None)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joint_predict = joint_full_model.predict(pred_df_full_throughput_test)\n",
    "joint_predict_round = []\n",
    "for a in joint_predict:\n",
    "    joint_predict_round.append([np.argmax(a)])\n",
    "precision_recall_fscore_support(y_test_deception, np.array(joint_predict_round), average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_rapport = np.asarray(y_test_rapport)\n",
    "y_train_rapport = np.asarray(y_train_rapport)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joint full model with one hot encoding, predicting rapport, weighted by throughput\n",
      "Model: \"functional_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         [(None, 3)]               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 2)                 8         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 4)                 12        \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 25\n",
      "Trainable params: 25\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/32\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 2.1502 - acc: 0.8590 - f1_m: 0.9240 - precision_m: 0.8599 - recall_m: 1.0000 - val_loss: 1.8777 - val_acc: 0.8769 - val_f1_m: 0.9338 - val_precision_m: 0.8766 - val_recall_m: 1.0000\n",
      "Epoch 2/32\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 2.1502 - acc: 0.8590 - f1_m: 0.9240 - precision_m: 0.8599 - recall_m: 1.0000 - val_loss: 1.8777 - val_acc: 0.8769 - val_f1_m: 0.9338 - val_precision_m: 0.8766 - val_recall_m: 1.0000\n"
     ]
    }
   ],
   "source": [
    "print('Joint full model with one hot encoding, predicting rapport, weighted by throughput')\n",
    "joint_full_model = create_joint_model(pred_df_throughput)\n",
    "joint_full_model.summary()\n",
    "history = joint_full_model.fit(x=pred_df_throughput, y=y_train_rapport, epochs=32, \n",
    "                    batch_size=64, \n",
    "                    validation_data=(pred_df_throughput_test,y_test_rapport), callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaiyuan/anaconda3/envs/TF2/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.06156552330694811, 0.5, 0.1096319498825372, None)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joint_predict = joint_full_model.predict(pred_df_throughput_test)\n",
    "joint_predict_round = []\n",
    "for a in joint_predict:\n",
    "    joint_predict_round.append([np.argmax(a)])\n",
    "precision_recall_fscore_support(y_test_rapport, np.array(joint_predict_round), average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WorkTime only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joint Model with one hot encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_joint_model(df):\n",
    "    inputB = Input(shape=(df.shape[1],))\n",
    "    c = Dense(2, activation='relu')(inputB)\n",
    "    c = Dense(4, activation='relu')(c)\n",
    "    c = Dense(1, activation='softmax')(c)\n",
    "    full_model = Model(inputs=inputB, outputs=c)\n",
    "\n",
    "    full_model.compile(loss='binary_crossentropy', optimizer='adam', \n",
    "                          metrics=['acc',f1_m,precision_m, recall_m])\n",
    "    \n",
    "    return full_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joint full model with one hot encoding, predicting deception, weighted by throughput\n",
      "Model: \"functional_23\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         [(None, 4)]               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 4)                 12        \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 27\n",
      "Trainable params: 27\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/32\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.7497 - acc: 0.9508 - f1_m: 0.9748 - precision_m: 0.9512 - recall_m: 1.0000 - val_loss: 0.7444 - val_acc: 0.9512 - val_f1_m: 0.9750 - val_precision_m: 0.9514 - val_recall_m: 1.0000\n",
      "Epoch 2/32\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.7497 - acc: 0.9508 - f1_m: 0.9747 - precision_m: 0.9512 - recall_m: 1.0000 - val_loss: 0.7444 - val_acc: 0.9512 - val_f1_m: 0.9750 - val_precision_m: 0.9514 - val_recall_m: 1.0000\n"
     ]
    }
   ],
   "source": [
    "print('Joint full model with one hot encoding, predicting deception, weighted by throughput')\n",
    "joint_full_model = create_joint_model(pred_df_full_worktime)\n",
    "joint_full_model.summary()\n",
    "history = joint_full_model.fit(x=pred_df_full_worktime, y=y_train_deception, epochs=32, \n",
    "                    batch_size=64, \n",
    "                    validation_data=(pred_df_full_worktime_test,y_test_deception), callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_rapport = np.asarray(y_test_rapport)\n",
    "y_train_rapport = np.asarray(y_train_rapport)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joint full model with one hot encoding, predicting rapport, weighted by throughput\n",
      "Model: \"functional_25\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_8 (InputLayer)         [(None, 3)]               0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 2)                 8         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 4)                 12        \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 25\n",
      "Trainable params: 25\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/32\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 2.1502 - acc: 0.8590 - f1_m: 0.9240 - precision_m: 0.8599 - recall_m: 1.0000 - val_loss: 1.8777 - val_acc: 0.8769 - val_f1_m: 0.9338 - val_precision_m: 0.8766 - val_recall_m: 1.0000\n",
      "Epoch 2/32\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 2.1502 - acc: 0.8590 - f1_m: 0.9240 - precision_m: 0.8599 - recall_m: 1.0000 - val_loss: 1.8777 - val_acc: 0.8769 - val_f1_m: 0.9338 - val_precision_m: 0.8766 - val_recall_m: 1.0000\n"
     ]
    }
   ],
   "source": [
    "print('Joint full model with one hot encoding, predicting rapport, weighted by throughput')\n",
    "joint_full_model = create_joint_model(pred_df_worktime)\n",
    "joint_full_model.summary()\n",
    "history = joint_full_model.fit(x=pred_df_worktime, y=y_train_rapport, epochs=32, \n",
    "                    batch_size=64, \n",
    "                    validation_data=(pred_df_worktime_test,y_test_rapport), callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfgpu",
   "language": "python",
   "name": "tfgpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
