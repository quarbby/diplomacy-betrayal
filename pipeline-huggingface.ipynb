{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from metadata_options.ipynb\n",
      "TP4 + k: weighted by 1 upright k-power U-shaped variance per set of OHE, i.e. (a, b, c, d) -> (w*a, w*b, w*c, w*d)\n",
      "Plot below: old throughput (x-axis) vs new throughput (y-axis)\n",
      "WT2: weighted by 1 linear variance per set of OHE, i.e. (a, b, c, d) -> (w*a, w*b, w*c, w*d)\n",
      "PC3: weighted by 1 PC agreement weight per annotation in each OHE, i.e. (a, b, c, d) -> (w1*a, w2*b, w3*c, w4*d)\n",
      "TL2: weighted by 1 normalised number of words per set of OHE, i.e. (a, b, c, d) -> (w*a, w*b, w*c, w*d)\n",
      "SP1: weighted by average of TP1 and TP2 per set of OHE, i.e. (a, b, c, d) -> (w*a, w*b, w*c, w*d)\n",
      "importing Jupyter notebook from models_nn.ipynb\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "from transformers import AutoModel, AutoTokenizer, AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "## Own code \n",
    "import import_ipynb\n",
    "import metadata_options\n",
    "import models_nn\n",
    "import Text_Huggingface_Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.read_csv('data/kokil dec 6 reprepare/conf_pc_worker_sem.csv')\n",
    "full_df = full_df.dropna() # dataset contains NaN values, dropping NaNs here\n",
    "\n",
    "y_variables = ['Answer.1gamemove.yes_label', 'Answer.2reasoning.yes_label', \n",
    "               'Answer.3rapport.yes_label', 'Answer.4shareinformation.yes_label',\n",
    "               'Input.deception_quadrant']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################\n",
    "## Metadata Options ##\n",
    "######################################\n",
    "\n",
    "throughput_option = 'TP4'\n",
    "worktime_option = 'WT2'\n",
    "pc_agreement_option = 'PC3'\n",
    "textlength_option = 'TL2'\n",
    "special_option = 'RAND_NORM'\n",
    "k_option_for_tp = 1\n",
    "\n",
    "df_throughput, df_worktime, df_agreement, df_textlength, df_special = metadata_options.set_OHE_pipeline_options(df, throughput_option, worktime_option, pc_agreement_option, textlength_option, special_option, k_option_for_tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################\n",
    "## Model Options ##\n",
    "# From 0 to 3\n",
    "######################################\n",
    "model_option = 0\n",
    "\n",
    "pre_trained_model_selection = ['bert-base-uncased', 'distilbert-base-uncased', \n",
    "                               'albert-base-v2', 'roberta-base']\n",
    "\n",
    "PRE_TRAINED_MODEL_NAME = pre_trained_model_selection[model_option]\n",
    "print(PRE_TRAINED_MODEL_NAME)\n",
    "\n",
    "epochs = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "full_df['Answer.1gamemove.yes_label'] = le.fit_transform(full_df['Answer.1gamemove.yes_label'])\n",
    "full_df['Answer.2reasoning.yes_label'] = le.fit_transform(full_df['Answer.2reasoning.yes_label'])\n",
    "full_df['Answer.3rapport.yes_label'] = le.fit_transform(full_df['Answer.3rapport.yes_label'])\n",
    "full_df['Answer.4shareinformation.yes_label'] = le.fit_transform(full_df['Answer.4shareinformation.yes_label'])\n",
    "full_df['Input.deception_quadrant'] = le.fit_transform(full_df['Input.deception_quadrant'])\n",
    "\n",
    "df_train, df_test = train_test_split(full_df, test_size=0.2)\n",
    "df_val, df_test = train_test_split(df_test, test_size=0.2)\n",
    "\n",
    "y_train_deception = df_train['Input.deception_quadrant'].tolist()\n",
    "y_test_deception = df_test['Input.deception_quadrant'].tolist()\n",
    "\n",
    "y_train_rapport = df_train['Answer.3rapport.yes_label'].tolist()\n",
    "y_test_rapport = df_test['Answer.3rapport.yes_label'].tolist()\n",
    "\n",
    "y_test_deception = np.asarray(y_test_deception)\n",
    "y_train_deception = np.asarray(y_train_deception)\n",
    "\n",
    "y_test_rapport = np.asarray(y_test_rapport)\n",
    "y_train_rapport = np.asarray(y_train_rapport)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('device: ', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct individual models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dict = {}\n",
    "models_train_pred_dict = {}\n",
    "models_test_pred_dict = {}\n",
    "\n",
    "for y_var in y_variables:\n",
    "    print()\n",
    "    print(y_var)\n",
    "    \n",
    "    # Create data splits\n",
    "    train_data_loader = Text_Huggingface_Transformers.create_data_loader(df_train, tokenizer, y_var, MAX_LEN, BATCH_SIZE)\n",
    "    test_data_loader = Text_Huggingface_Transformers.create_data_loader(df_test, tokenizer, y_var, MAX_LEN, BATCH_SIZE)\n",
    "    val_data_loader = Text_Huggingface_Transformers.create_data_loader(df_val, tokenizer, y_var, MAX_LEN, BATCH_SIZE)\n",
    "    \n",
    "    # Sainty checks\n",
    "    print('sanity checks')\n",
    "    data = next(iter(train_data_loader))\n",
    "    print(data.keys())\n",
    "    \n",
    "    class_names = df_train[y_var].unique()\n",
    "    \n",
    "    # Create classifier model\n",
    "    new_model = Text_Huggingface_Transformers.QuadrantClassifier(len(class_names))\n",
    "    new_model = new_model.to(device)\n",
    "    \n",
    "    input_ids = data['input_ids'].to(device)\n",
    "    attention_mask = data['attention_mask'].to(device)\n",
    "\n",
    "    nn.functional.softmax(new_model(input_ids, attention_mask), dim=1)\n",
    "\n",
    "    # Compile model for number of epochs\n",
    "    total_steps = len(train_data_loader) * EPOCHS\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "      optimizer,\n",
    "      num_warmup_steps=0,\n",
    "      num_training_steps=total_steps\n",
    "    )\n",
    "    loss_fn = nn.CrossEntropyLoss().to(device)\n",
    "    \n",
    "    history = defaultdict(list)\n",
    "    best_accuracy = 0\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
    "        print('-' * 10)\n",
    "        train_acc, train_loss = train_epoch(\n",
    "            new_model,\n",
    "            train_data_loader,\n",
    "            loss_fn,\n",
    "            optimizer,\n",
    "            device,\n",
    "            scheduler,\n",
    "            len(df_train)\n",
    "        )\n",
    "\n",
    "        print(f'Train loss {train_loss} accuracy {train_acc}')\n",
    "\n",
    "        val_acc, val_loss = eval_model(\n",
    "            new_model,\n",
    "            val_data_loader,\n",
    "            loss_fn,\n",
    "            device,\n",
    "            len(df_val)\n",
    "          )\n",
    "\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        history['val_loss'].append(val_loss)\n",
    "\n",
    "        if val_acc > best_accuracy:\n",
    "            torch.save(model.state_dict(), y_var + '.bin')\n",
    "            best_accuracy = val_acc\n",
    "    \n",
    "    # Get predictions\n",
    "    test_acc, _ = eval_model(\n",
    "      new_model,\n",
    "      test_data_loader,\n",
    "      loss_fn,\n",
    "      device,\n",
    "      len(df_test)\n",
    "    )\n",
    "        \n",
    "    y_full_texts, y_pred_train, y_pred_probs, y_test = Text_Huggingface_Transformers.get_predictions(\n",
    "      new_model,\n",
    "      train_data_loader\n",
    "    )\n",
    "    y_pred_train = y_pred_train.numpy()\n",
    "    y_test = y_test.numpy()\n",
    "\n",
    "    # Classification report and confusion matrix\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    print(pd.DataFrame(report).transpose())\n",
    "    \n",
    "    y_full_texts, y_pred_test, y_pred_probs, y_test = Text_Huggingface_Transformers.get_predictions(\n",
    "      new_model,\n",
    "      test_data_loader\n",
    "    )\n",
    "    y_pred_test = y_pred_test.numpy()\n",
    "    y_test = y_test.numpy()\n",
    "        \n",
    "    # Add to model\n",
    "    model_dict[y_var] = new_model\n",
    "    models_train_pred_dict[y_var] = y_pred_train\n",
    "    models_test_pred_dict[y_var] = y_pred_test\n",
    "\n",
    "    # Clear GPU memory\n",
    "    del input_ids\n",
    "    del attention_mask\n",
    "    del new_model\n",
    "    del loss_fn\n",
    "    \n",
    "    print(torch.cuda.empty_cache())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train encodings\n",
    "pred_df_arr_full = []\n",
    "pred_df_arr = []\n",
    "\n",
    "num_preds = len(models_train_pred_dict[y_variables[0]])\n",
    "\n",
    "for i in range(0, len(num_preds)):\n",
    "    pred_obj_1 = {}\n",
    "    pred_obj_1['gamemove'] = models_train_pred_dict['Answer.1gamemove.yes_label'][i]\n",
    "    pred_obj_1['reasoning'] = models_train_pred_dict['Answer.2reasoning.yes_label'][i]\n",
    "    pred_obj_1['shareinfo'] = models_train_pred_dict['Answer.4shareinformation.yes_label'][i]\n",
    "    pred_df_arr.append(pred_obj_1)\n",
    "    \n",
    "    pred_obj_2 = pred_obj_1.copy()\n",
    "    pred_obj_2['rapport'] = models_train_pred_dict['Answer.3rapport.yes_label'][i]\n",
    "    pred_df_arr_full.append(pred_obj_2)\n",
    "    \n",
    "pred_df_full = pd.DataFrame(pred_df_arr_full)\n",
    "pred_df = pd.DataFrame(pred_df_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train encodings\n",
    "pred_test_df_arr_full = []\n",
    "pred_test_df_arr = []\n",
    "\n",
    "num_preds = len(models_test_pred_dict[y_variables[0]])\n",
    "\n",
    "for i in range(0, len(num_preds)):\n",
    "    pred_obj_1 = {}\n",
    "    pred_obj_1['gamemove'] = models_test_pred_dict['Answer.1gamemove.yes_label'][i]\n",
    "    pred_obj_1['reasoning'] = models_test_pred_dict['Answer.2reasoning.yes_label'][i]\n",
    "    pred_obj_1['shareinfo'] = models_test_pred_dict['Answer.4shareinformation.yes_label'][i]\n",
    "    pred_test_df_arr.append(pred_obj_1)\n",
    "    \n",
    "    pred_obj_2 = pred_obj_1.copy()\n",
    "    pred_obj_2['rapport'] = models_test_pred_dict['Answer.3rapport.yes_label'][i]\n",
    "    pred_test_df_arr_full.append(pred_obj_2)\n",
    "    \n",
    "pred_test_df_full = pd.DataFrame(pred_test_df_arr_full)\n",
    "pred_test_df = pd.DataFrame(pred_test_df_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct metadata frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train weighted encodings\n",
    "pred_df_full_throughput, pred_df_throughput, pred_df_full_worktime, pred_df_worktime, pred_df_full_agreement, pred_df_agreement, pred_df_full_textlength, pred_df_textlength, pred_df_full_special, pred_df_special = metadata_options.construct_train_weighted_dataframe(indices_train, df_throughput, df_worktime, df_agreement, df_textlength, df_special, pred_df, pred_df_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test weighted encodings\n",
    "pred_df_full_throughput_test, pred_df_throughput_test, pred_df_full_worktime_test, pred_df_worktime_test, pred_df_full_agreement_test, pred_df_agreement_test, pred_df_full_textlength_test, pred_df_textlength_test, pred_df_full_special_test, pred_df_special_test = metadata_options.construct_train_weighted_dataframe(indices_test, df_throughput, df_worktime, df_agreement, df_textlength, df_special, pred_test_df, pred_test_df_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join the models with One Hot Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Joint full model with one hot encoding, predicting deception')\n",
    "joint_full_model = models_nn.create_joint_model(pred_df_full)\n",
    "joint_full_model.summary()\n",
    "history = joint_full_model.fit(x=pred_df_full, \n",
    "                               y=y_train_deception, \n",
    "                               epochs=32, \n",
    "                               batch_size=64, \n",
    "                               validation_data=(pred_test_df_full,y_test_deception), \n",
    "                               callbacks=[models_nn.callback], \n",
    "                               class_weight=deception_class_weight_dict)\n",
    "\n",
    "joint_predict = joint_full_model.predict(pred_test_df_full)\n",
    "joint_predict_round = []\n",
    "for a in joint_predict:\n",
    "    joint_predict_round.append(np.argmax(a))\n",
    "precision_recall_fscore_support(y_test_deception, np.array(joint_predict_round), average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Joint full model with one hot encoding, predicting rapport')\n",
    "joint_full_model = models_nn.create_joint_model(pred_df)\n",
    "joint_full_model.summary()\n",
    "history = joint_full_model.fit(x=pred_df, \n",
    "                               y=y_train_rapport, \n",
    "                               epochs=32, \n",
    "                               batch_size=64, \n",
    "                               validation_data=(pred_test_df,y_test_rapport), \n",
    "                               callbacks=[models_nn.callback], \n",
    "                               class_weight=rapport_class_weight_dict)\n",
    "\n",
    "joint_predict = joint_full_model.predict(pred_test_df)\n",
    "joint_predict_round = []\n",
    "for a in joint_predict:\n",
    "    joint_predict_round.append(np.argmax(a))\n",
    "precision_recall_fscore_support(y_test_rapport, np.array(joint_predict_round), average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Throughput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Joint full model with one hot encoding, predicting deception, weighted by throughput')\n",
    "joint_full_model = models_nn.create_joint_model(pred_df_full_throughput)\n",
    "joint_full_model.summary()\n",
    "history = joint_full_model.fit(x=pred_df_full_throughput, \n",
    "                               y=y_train_deception, \n",
    "                               epochs=32, \n",
    "                               batch_size=64, \n",
    "                               validation_data=(pred_df_full_throughput_test,y_test_deception), \n",
    "                               callbacks=[models_nn.callback], \n",
    "                               class_weight=deception_class_weight_dict)\n",
    "\n",
    "joint_predict = joint_full_model.predict(pred_df_full_throughput_test)\n",
    "joint_predict_round = []\n",
    "for a in joint_predict:\n",
    "    joint_predict_round.append(np.argmax(a))\n",
    "precision_recall_fscore_support(y_test_deception, np.array(joint_predict_round), average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Joint full model with one hot encoding, predicting rapport, weighted by throughput')\n",
    "joint_full_model = models_nn.create_joint_model(pred_df_throughput)\n",
    "joint_full_model.summary()\n",
    "history = joint_full_model.fit(x=pred_df_throughput, \n",
    "                               y=y_train_rapport, \n",
    "                               epochs=32, \n",
    "                               batch_size=64,\n",
    "                               validation_data=(pred_df_throughput_test,y_test_rapport), \n",
    "                               callbacks=[models_nn.callback], \n",
    "                               class_weight=rapport_class_weight_dict)\n",
    "\n",
    "joint_predict = joint_full_model.predict(pred_df_throughput_test)\n",
    "joint_predict_round = []\n",
    "for a in joint_predict:\n",
    "    joint_predict_round.append(np.argmax(a))\n",
    "precision_recall_fscore_support(y_test_rapport, np.array(joint_predict_round), average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PC Agreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Joint full model with one hot encoding, predicting deception, weighted by PC Agreement')\n",
    "joint_full_model = models_nn.create_joint_model(pred_df_full_agreement)\n",
    "joint_full_model.summary()\n",
    "history = joint_full_model.fit(x=pred_df_full_agreement, \n",
    "                               y=y_train_deception, \n",
    "                               epochs=32, \n",
    "                               batch_size=64, \n",
    "                               validation_data=(pred_df_full_agreement_test,y_test_deception), \n",
    "                               callbacks=[models_nn.callback],\n",
    "                               class_weight=deception_class_weight_dict)\n",
    "\n",
    "joint_predict = joint_full_model.predict(pred_df_full_throughput_test)\n",
    "joint_predict_round = []\n",
    "for a in joint_predict:\n",
    "    joint_predict_round.append(np.argmax(a))\n",
    "precision_recall_fscore_support(y_test_rapport, np.array(joint_predict_round), average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Joint full model with one hot encoding, predicting rapport, weighted by PC Agreement')\n",
    "joint_full_model = models_nn.create_joint_model(pred_df_agreement)\n",
    "joint_full_model.summary()\n",
    "history = joint_full_model.fit(x=pred_df_agreement, \n",
    "                               y=y_train_rapport, \n",
    "                               epochs=32, \n",
    "                               batch_size=64, \n",
    "                               validation_data=(pred_df_agreement_test,y_test_rapport), \n",
    "                               callbacks=[models_nn.callback], \n",
    "                               class_weight=rapport_class_weight_dict)\n",
    "\n",
    "joint_predict = joint_full_model.predict(pred_df_throughput_test)\n",
    "joint_predict_round = []\n",
    "for a in joint_predict:\n",
    "    joint_predict_round.append(np.argmax(a))\n",
    "precision_recall_fscore_support(y_test_rapport, np.array(joint_predict_round), average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### WorkTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Joint full model with one hot encoding, predicting deception, weighted by worktime')\n",
    "joint_full_model = models_nn.create_joint_model(pred_df_full_worktime)\n",
    "joint_full_model.summary()\n",
    "history = joint_full_model.fit(x=pred_df_full_worktime, \n",
    "                               y=y_train_deception, \n",
    "                               epochs=32, \n",
    "                               batch_size=64, \n",
    "                               validation_data=(pred_df_full_worktime_test,y_test_deception), \n",
    "                               callbacks=[models_nn.callback],\n",
    "                               class_weight=deception_class_weight_dict)\n",
    "\n",
    "joint_predict = joint_full_model.predict(pred_df_full_worktime_test)\n",
    "joint_predict_round = []\n",
    "for a in joint_predict:\n",
    "    joint_predict_round.append(np.argmax(a))\n",
    "precision_recall_fscore_support(y_test_deception, np.array(joint_predict_round), average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Joint full model with one hot encoding, predicting rapport, weighted by worktime')\n",
    "joint_full_model = models_nn.create_joint_model(pred_df_worktime)\n",
    "joint_full_model.summary()\n",
    "history = joint_full_model.fit(x=pred_df_worktime, \n",
    "                               y=y_train_rapport, \n",
    "                               epochs=32, \n",
    "                               batch_size=64,\n",
    "                               validation_data=(pred_df_worktime_test,y_test_rapport), \n",
    "                               callbacks=[models_nn.callback], \n",
    "                               class_weight=rapport_class_weight_dict)\n",
    "\n",
    "joint_predict = joint_full_model.predict(pred_df_worktime_test)\n",
    "joint_predict_round = []\n",
    "for a in joint_predict:\n",
    "    joint_predict_round.append(np.argmax(a))\n",
    "precision_recall_fscore_support(y_test_rapport, np.array(joint_predict_round), average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Joint full model with one hot encoding, predicting deception, weighted by text length')\n",
    "joint_full_model = models_nn.create_joint_model(pred_df_full_textlength)\n",
    "joint_full_model.summary()\n",
    "history = joint_full_model.fit(x=pred_df_full_textlength, \n",
    "                               y=y_train_deception, \n",
    "                               epochs=32, \n",
    "                               batch_size=64, \n",
    "                               validation_data=(pred_df_full_textlength_test,y_test_deception), \n",
    "                               callbacks=[models_nn.callback],\n",
    "                               class_weight=deception_class_weight_dict)\n",
    "\n",
    "joint_predict = joint_full_model.predict(pred_df_full_textlength_test)\n",
    "joint_predict_round = []\n",
    "for a in joint_predict:\n",
    "    joint_predict_round.append(np.argmax(a))\n",
    "precision_recall_fscore_support(y_test_deception, np.array(joint_predict_round), average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Joint full model with one hot encoding, predicting rapport, weighted by text length')\n",
    "joint_full_model = models_nn.create_joint_model(pred_df_textlength)\n",
    "joint_full_model.summary()\n",
    "history = joint_full_model.fit(x=pred_df_textlength, \n",
    "                               y=y_train_rapport, \n",
    "                               epochs=32, \n",
    "                               batch_size=64, \n",
    "                               validation_data=(pred_df_textlength_test,y_test_rapport), \n",
    "                               callbacks=[models_nn.callback], \n",
    "                               class_weight=rapport_class_weight_dict)\n",
    "\n",
    "joint_predict = joint_full_model.predict(pred_df_textlength_test)\n",
    "joint_predict_round = []\n",
    "for a in joint_predict:\n",
    "    joint_predict_round.append(np.argmax(a))\n",
    "precision_recall_fscore_support(y_test_rapport, np.array(joint_predict_round), average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Special Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Joint full model with one hot encoding, predicting deception, weighted by special option')\n",
    "joint_full_model = models_nn.create_joint_model(pred_df_full_special)\n",
    "joint_full_model.summary()\n",
    "history = joint_full_model.fit(x=pred_df_full_special, \n",
    "                               y=y_train_deception, \n",
    "                               epochs=32, \n",
    "                               batch_size=64, \n",
    "                               validation_data=(pred_df_full_special_test,y_test_deception), \n",
    "                               callbacks=[models_nn.callback],\n",
    "                               class_weight=deception_class_weight_dict)\n",
    "\n",
    "joint_predict = joint_full_model.predict(pred_df_full_special_test)\n",
    "joint_predict_round = []\n",
    "for a in joint_predict:\n",
    "    joint_predict_round.append(np.argmax(a))\n",
    "precision_recall_fscore_support(y_test_deception, np.array(joint_predict_round), average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Joint full model with one hot encoding, predicting rapport, weighted by special option')\n",
    "joint_full_model = models_nn.create_joint_model(pred_df_special)\n",
    "joint_full_model.summary()\n",
    "history = joint_full_model.fit(x=pred_df_special, \n",
    "                               y=y_train_rapport, \n",
    "                               epochs=32, \n",
    "                               batch_size=64,\n",
    "                               validation_data=(pred_df_special_test,y_test_rapport), \n",
    "                               callbacks=[models_nn.callback], \n",
    "                               class_weight=rapport_class_weight_dict)\n",
    "\n",
    "joint_predict = joint_full_model.predict(pred_df_special_test)\n",
    "joint_predict_round = []\n",
    "for a in joint_predict:\n",
    "    joint_predict_round.append(np.argmax(a))\n",
    "precision_recall_fscore_support(y_test_rapport, np.array(joint_predict_round), average='macro')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfgpu",
   "language": "python",
   "name": "tfgpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
