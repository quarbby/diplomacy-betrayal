{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from convokit import Corpus, Speaker, Utterance, download\n",
    "from collections import defaultdict\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HITId</th>\n",
       "      <th>Input.sentence_id</th>\n",
       "      <th>Input.convo_id</th>\n",
       "      <th>Input.train_test_val</th>\n",
       "      <th>Input.msg_id</th>\n",
       "      <th>Input.timestamp</th>\n",
       "      <th>Input.full_text</th>\n",
       "      <th>Input.speaker</th>\n",
       "      <th>Input.reply_to</th>\n",
       "      <th>Input.speaker_intention</th>\n",
       "      <th>...</th>\n",
       "      <th>Input.deception_quadrant</th>\n",
       "      <th>Input.num_words</th>\n",
       "      <th>Input.num_characters</th>\n",
       "      <th>Input.sno</th>\n",
       "      <th>Input.sno1</th>\n",
       "      <th>Input.similar_text_id</th>\n",
       "      <th>affcon_gamemove</th>\n",
       "      <th>affcon_reasoning</th>\n",
       "      <th>affcon_rapport</th>\n",
       "      <th>affcon_shareinformation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>301KG0KX9CLR06T6MC6UVPAHBC92HU</td>\n",
       "      <td>22056</td>\n",
       "      <td>Game7-turkey-austria</td>\n",
       "      <td>Train</td>\n",
       "      <td>Game7-turkey-austria-9</td>\n",
       "      <td>197</td>\n",
       "      <td>Im moving my fleet to Alb not for Greece but f...</td>\n",
       "      <td>austria-Game7</td>\n",
       "      <td>Game7-turkey-austria-8</td>\n",
       "      <td>Truth</td>\n",
       "      <td>...</td>\n",
       "      <td>Straightforward</td>\n",
       "      <td>12</td>\n",
       "      <td>56</td>\n",
       "      <td>32</td>\n",
       "      <td>16.0</td>\n",
       "      <td>104</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>301KG0KX9CLR06T6MC6UVPAHBCAH2A</td>\n",
       "      <td>6906</td>\n",
       "      <td>Game11-austria-italy</td>\n",
       "      <td>Validation</td>\n",
       "      <td>Game11-austria-italy-5</td>\n",
       "      <td>45</td>\n",
       "      <td>And yes I would like peace on our front, I cou...</td>\n",
       "      <td>austria-Game11</td>\n",
       "      <td>Game11-austria-italy-4</td>\n",
       "      <td>Truth</td>\n",
       "      <td>...</td>\n",
       "      <td>Straightforward</td>\n",
       "      <td>31</td>\n",
       "      <td>132</td>\n",
       "      <td>46</td>\n",
       "      <td>22.0</td>\n",
       "      <td>18629</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>301KG0KX9CLR06T6MC6UVPAHBCC2HX</td>\n",
       "      <td>3066</td>\n",
       "      <td>Game1-england-germany</td>\n",
       "      <td>Train</td>\n",
       "      <td>Game1-england-germany-271</td>\n",
       "      <td>1468</td>\n",
       "      <td>okay...well, as the person who has ever seen a...</td>\n",
       "      <td>germany-Game1</td>\n",
       "      <td>Game1-england-germany-270</td>\n",
       "      <td>Truth</td>\n",
       "      <td>...</td>\n",
       "      <td>Straightforward</td>\n",
       "      <td>15</td>\n",
       "      <td>86</td>\n",
       "      <td>79</td>\n",
       "      <td>33.0</td>\n",
       "      <td>8855</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>301KG0KX9CLR06T6MC6UVPAHBCCH2C</td>\n",
       "      <td>24093</td>\n",
       "      <td>Game9-italy-germany</td>\n",
       "      <td>Train</td>\n",
       "      <td>Game9-italy-germany-70</td>\n",
       "      <td>1460</td>\n",
       "      <td>I think the best thing we can do to keep the a...</td>\n",
       "      <td>germany-Game9</td>\n",
       "      <td>Game9-italy-germany-69</td>\n",
       "      <td>Truth</td>\n",
       "      <td>...</td>\n",
       "      <td>Straightforward</td>\n",
       "      <td>22</td>\n",
       "      <td>104</td>\n",
       "      <td>7</td>\n",
       "      <td>36.0</td>\n",
       "      <td>9729</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>301KG0KX9CLR06T6MC6UVPAHBCD2HY</td>\n",
       "      <td>1591</td>\n",
       "      <td>Game1-england-italy</td>\n",
       "      <td>Train</td>\n",
       "      <td>Game1-england-italy-273</td>\n",
       "      <td>1809</td>\n",
       "      <td>We'll see if I can keep it friendly.</td>\n",
       "      <td>england-Game1</td>\n",
       "      <td>Game1-england-italy-272</td>\n",
       "      <td>Truth</td>\n",
       "      <td>...</td>\n",
       "      <td>Straightforward</td>\n",
       "      <td>8</td>\n",
       "      <td>36</td>\n",
       "      <td>58</td>\n",
       "      <td>39.0</td>\n",
       "      <td>19784</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            HITId  Input.sentence_id         Input.convo_id  \\\n",
       "0  301KG0KX9CLR06T6MC6UVPAHBC92HU              22056   Game7-turkey-austria   \n",
       "1  301KG0KX9CLR06T6MC6UVPAHBCAH2A               6906   Game11-austria-italy   \n",
       "2  301KG0KX9CLR06T6MC6UVPAHBCC2HX               3066  Game1-england-germany   \n",
       "3  301KG0KX9CLR06T6MC6UVPAHBCCH2C              24093    Game9-italy-germany   \n",
       "4  301KG0KX9CLR06T6MC6UVPAHBCD2HY               1591    Game1-england-italy   \n",
       "\n",
       "  Input.train_test_val               Input.msg_id  Input.timestamp  \\\n",
       "0                Train     Game7-turkey-austria-9              197   \n",
       "1           Validation     Game11-austria-italy-5               45   \n",
       "2                Train  Game1-england-germany-271             1468   \n",
       "3                Train     Game9-italy-germany-70             1460   \n",
       "4                Train    Game1-england-italy-273             1809   \n",
       "\n",
       "                                     Input.full_text   Input.speaker  \\\n",
       "0  Im moving my fleet to Alb not for Greece but f...   austria-Game7   \n",
       "1  And yes I would like peace on our front, I cou...  austria-Game11   \n",
       "2  okay...well, as the person who has ever seen a...   germany-Game1   \n",
       "3  I think the best thing we can do to keep the a...   germany-Game9   \n",
       "4               We'll see if I can keep it friendly.   england-Game1   \n",
       "\n",
       "              Input.reply_to Input.speaker_intention  ...  \\\n",
       "0     Game7-turkey-austria-8                   Truth  ...   \n",
       "1     Game11-austria-italy-4                   Truth  ...   \n",
       "2  Game1-england-germany-270                   Truth  ...   \n",
       "3     Game9-italy-germany-69                   Truth  ...   \n",
       "4    Game1-england-italy-272                   Truth  ...   \n",
       "\n",
       "  Input.deception_quadrant Input.num_words  Input.num_characters  Input.sno  \\\n",
       "0          Straightforward              12                    56         32   \n",
       "1          Straightforward              31                   132         46   \n",
       "2          Straightforward              15                    86         79   \n",
       "3          Straightforward              22                   104          7   \n",
       "4          Straightforward               8                    36         58   \n",
       "\n",
       "   Input.sno1  Input.similar_text_id  affcon_gamemove  affcon_reasoning  \\\n",
       "0        16.0                    104              1.0               1.0   \n",
       "1        22.0                  18629              1.0               1.0   \n",
       "2        33.0                   8855              1.0               1.0   \n",
       "3        36.0                   9729              1.0               1.0   \n",
       "4        39.0                  19784              1.0               1.0   \n",
       "\n",
       "  affcon_rapport  affcon_shareinformation  \n",
       "0            1.0                      1.0  \n",
       "1            1.0                      1.0  \n",
       "2            1.0                      1.0  \n",
       "3            1.0                      1.0  \n",
       "4            1.0                      1.0  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/kokil dec 6 reprepare/conf_good_stripped.csv')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "speakers_list = df['Input.speaker'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_speakers = {k: Speaker(id=k) for k in speakers_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already exists at C:\\Users\\lynne\\.convokit\\downloads\\diplomacy-corpus\n"
     ]
    }
   ],
   "source": [
    "corpus = Corpus(filename=download(\"diplomacy-corpus\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Speakers: 83\n",
      "Number of Utterances: 17289\n",
      "Number of Conversations: 246\n"
     ]
    }
   ],
   "source": [
    "corpus.print_summary_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg_ids = df['Input.msg_id'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_filter = corpus.filter_utterances_by(lambda utt: utt.id in msg_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Speakers: 83\n",
      "Number of Utterances: 3474\n",
      "Number of Conversations: 217\n"
     ]
    }
   ],
   "source": [
    "corpus_filter.print_summary_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in df.iterrows():\n",
    "    utt = corpus_filter.get_utterance(row['Input.msg_id'])\n",
    "    utt.meta['affcon_gamemove'] = row['affcon_gamemove']\n",
    "    utt.meta['affcon_reasoning'] = row['affcon_reasoning']\n",
    "    utt.meta['affcon_rapport'] = row['affcon_rapport']\n",
    "    utt.meta['affcon_shareinformation'] = row['affcon_shareinformation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_filter.dump(r'C:\\Users\\lynne\\Documents\\diplomacy-betrayal\\data\\kokil dec 6 reprepare\\convokit_with_affcon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from convokit import PolitenessStrategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POLITENESS STRATEGIES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PolitenessStrategies(verbose=1000)\n",
    "corpus_filter = ps.transform(corpus_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "utterance_ids = corpus_filter.get_utterance_ids()\n",
    "rows = []\n",
    "for uid in utterance_ids:\n",
    "    rows.append(corpus_filter.get_utterance(uid).meta[\"politeness_strategies\"])\n",
    "politeness_strategies = pd.DataFrame(rows, index=utterance_ids)\n",
    "politeness_strategies['msg_id'] = politeness_strategies.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_politeness_==Please==</th>\n",
       "      <th>feature_politeness_==Please_start==</th>\n",
       "      <th>feature_politeness_==HASHEDGE==</th>\n",
       "      <th>feature_politeness_==Indirect_(btw)==</th>\n",
       "      <th>feature_politeness_==Hedges==</th>\n",
       "      <th>feature_politeness_==Factuality==</th>\n",
       "      <th>feature_politeness_==Deference==</th>\n",
       "      <th>feature_politeness_==Gratitude==</th>\n",
       "      <th>feature_politeness_==Apologizing==</th>\n",
       "      <th>feature_politeness_==1st_person_pl.==</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_politeness_==2nd_person==</th>\n",
       "      <th>feature_politeness_==2nd_person_start==</th>\n",
       "      <th>feature_politeness_==Indirect_(greeting)==</th>\n",
       "      <th>feature_politeness_==Direct_question==</th>\n",
       "      <th>feature_politeness_==Direct_start==</th>\n",
       "      <th>feature_politeness_==HASPOSITIVE==</th>\n",
       "      <th>feature_politeness_==HASNEGATIVE==</th>\n",
       "      <th>feature_politeness_==SUBJUNCTIVE==</th>\n",
       "      <th>feature_politeness_==INDICATIVE==</th>\n",
       "      <th>msg_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Game1-italy-germany-0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Game1-italy-germany-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Game1-italy-germany-9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Game1-italy-germany-9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Game1-italy-germany-10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Game1-italy-germany-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Game1-italy-germany-11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Game1-italy-germany-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Game1-italy-germany-13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Game1-italy-germany-13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        feature_politeness_==Please==  \\\n",
       "Game1-italy-germany-0                               0   \n",
       "Game1-italy-germany-9                               0   \n",
       "Game1-italy-germany-10                              0   \n",
       "Game1-italy-germany-11                              0   \n",
       "Game1-italy-germany-13                              0   \n",
       "\n",
       "                        feature_politeness_==Please_start==  \\\n",
       "Game1-italy-germany-0                                     0   \n",
       "Game1-italy-germany-9                                     0   \n",
       "Game1-italy-germany-10                                    0   \n",
       "Game1-italy-germany-11                                    0   \n",
       "Game1-italy-germany-13                                    0   \n",
       "\n",
       "                        feature_politeness_==HASHEDGE==  \\\n",
       "Game1-italy-germany-0                                 1   \n",
       "Game1-italy-germany-9                                 1   \n",
       "Game1-italy-germany-10                                1   \n",
       "Game1-italy-germany-11                                0   \n",
       "Game1-italy-germany-13                                1   \n",
       "\n",
       "                        feature_politeness_==Indirect_(btw)==  \\\n",
       "Game1-italy-germany-0                                       0   \n",
       "Game1-italy-germany-9                                       0   \n",
       "Game1-italy-germany-10                                      0   \n",
       "Game1-italy-germany-11                                      0   \n",
       "Game1-italy-germany-13                                      0   \n",
       "\n",
       "                        feature_politeness_==Hedges==  \\\n",
       "Game1-italy-germany-0                               1   \n",
       "Game1-italy-germany-9                               1   \n",
       "Game1-italy-germany-10                              1   \n",
       "Game1-italy-germany-11                              0   \n",
       "Game1-italy-germany-13                              1   \n",
       "\n",
       "                        feature_politeness_==Factuality==  \\\n",
       "Game1-italy-germany-0                                   1   \n",
       "Game1-italy-germany-9                                   1   \n",
       "Game1-italy-germany-10                                  0   \n",
       "Game1-italy-germany-11                                  0   \n",
       "Game1-italy-germany-13                                  0   \n",
       "\n",
       "                        feature_politeness_==Deference==  \\\n",
       "Game1-italy-germany-0                                  0   \n",
       "Game1-italy-germany-9                                  0   \n",
       "Game1-italy-germany-10                                 0   \n",
       "Game1-italy-germany-11                                 0   \n",
       "Game1-italy-germany-13                                 0   \n",
       "\n",
       "                        feature_politeness_==Gratitude==  \\\n",
       "Game1-italy-germany-0                                  0   \n",
       "Game1-italy-germany-9                                  0   \n",
       "Game1-italy-germany-10                                 0   \n",
       "Game1-italy-germany-11                                 0   \n",
       "Game1-italy-germany-13                                 0   \n",
       "\n",
       "                        feature_politeness_==Apologizing==  \\\n",
       "Game1-italy-germany-0                                    0   \n",
       "Game1-italy-germany-9                                    0   \n",
       "Game1-italy-germany-10                                   0   \n",
       "Game1-italy-germany-11                                   0   \n",
       "Game1-italy-germany-13                                   0   \n",
       "\n",
       "                        feature_politeness_==1st_person_pl.==  ...  \\\n",
       "Game1-italy-germany-0                                       0  ...   \n",
       "Game1-italy-germany-9                                       0  ...   \n",
       "Game1-italy-germany-10                                      1  ...   \n",
       "Game1-italy-germany-11                                      1  ...   \n",
       "Game1-italy-germany-13                                      0  ...   \n",
       "\n",
       "                        feature_politeness_==2nd_person==  \\\n",
       "Game1-italy-germany-0                                   1   \n",
       "Game1-italy-germany-9                                   1   \n",
       "Game1-italy-germany-10                                  1   \n",
       "Game1-italy-germany-11                                  1   \n",
       "Game1-italy-germany-13                                  1   \n",
       "\n",
       "                        feature_politeness_==2nd_person_start==  \\\n",
       "Game1-italy-germany-0                                         0   \n",
       "Game1-italy-germany-9                                         0   \n",
       "Game1-italy-germany-10                                        0   \n",
       "Game1-italy-germany-11                                        0   \n",
       "Game1-italy-germany-13                                        0   \n",
       "\n",
       "                        feature_politeness_==Indirect_(greeting)==  \\\n",
       "Game1-italy-germany-0                                            0   \n",
       "Game1-italy-germany-9                                            0   \n",
       "Game1-italy-germany-10                                           0   \n",
       "Game1-italy-germany-11                                           0   \n",
       "Game1-italy-germany-13                                           0   \n",
       "\n",
       "                        feature_politeness_==Direct_question==  \\\n",
       "Game1-italy-germany-0                                        1   \n",
       "Game1-italy-germany-9                                        0   \n",
       "Game1-italy-germany-10                                       0   \n",
       "Game1-italy-germany-11                                       0   \n",
       "Game1-italy-germany-13                                       0   \n",
       "\n",
       "                        feature_politeness_==Direct_start==  \\\n",
       "Game1-italy-germany-0                                     1   \n",
       "Game1-italy-germany-9                                     0   \n",
       "Game1-italy-germany-10                                    1   \n",
       "Game1-italy-germany-11                                    0   \n",
       "Game1-italy-germany-13                                    1   \n",
       "\n",
       "                        feature_politeness_==HASPOSITIVE==  \\\n",
       "Game1-italy-germany-0                                    1   \n",
       "Game1-italy-germany-9                                    1   \n",
       "Game1-italy-germany-10                                   1   \n",
       "Game1-italy-germany-11                                   1   \n",
       "Game1-italy-germany-13                                   1   \n",
       "\n",
       "                        feature_politeness_==HASNEGATIVE==  \\\n",
       "Game1-italy-germany-0                                    1   \n",
       "Game1-italy-germany-9                                    1   \n",
       "Game1-italy-germany-10                                   0   \n",
       "Game1-italy-germany-11                                   1   \n",
       "Game1-italy-germany-13                                   1   \n",
       "\n",
       "                        feature_politeness_==SUBJUNCTIVE==  \\\n",
       "Game1-italy-germany-0                                    0   \n",
       "Game1-italy-germany-9                                    0   \n",
       "Game1-italy-germany-10                                   0   \n",
       "Game1-italy-germany-11                                   0   \n",
       "Game1-italy-germany-13                                   0   \n",
       "\n",
       "                        feature_politeness_==INDICATIVE==  \\\n",
       "Game1-italy-germany-0                                   0   \n",
       "Game1-italy-germany-9                                   0   \n",
       "Game1-italy-germany-10                                  0   \n",
       "Game1-italy-germany-11                                  0   \n",
       "Game1-italy-germany-13                                  0   \n",
       "\n",
       "                                        msg_id  \n",
       "Game1-italy-germany-0    Game1-italy-germany-0  \n",
       "Game1-italy-germany-9    Game1-italy-germany-9  \n",
       "Game1-italy-germany-10  Game1-italy-germany-10  \n",
       "Game1-italy-germany-11  Game1-italy-germany-11  \n",
       "Game1-italy-germany-13  Game1-italy-germany-13  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "politeness_strategies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "politeness_strategies.to_csv('./data/kokil dec 6 reprepare/politeness_strategies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_politeness_merge = politeness_strategies.merge(df, left_on='msg_id', right_on='Input.msg_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_politeness_merge.to_csv('./data/kokil dec 6 reprepare/affcon_final_politeness_strategies_merge.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding ngrams "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from nltk.util import ngrams\n",
    "import nltk, collections\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.read_csv('./data/kokil dec 6 reprepare/affcon_final_politeness_strategies_merge.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = ['affcon_rapport', 'affcon_shareinformation', 'affcon_reasoning', 'affcon_gamemove']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_freq_df(item_df):\n",
    "    word_vectorizer = CountVectorizer(ngram_range=(1,4), analyzer='word')\n",
    "    sparse_matrix = word_vectorizer.fit_transform(item_df['Input.full_text'])\n",
    "    frequencies = sum(sparse_matrix).data\n",
    "    df_frequency = pd.DataFrame(frequencies, index=word_vectorizer.get_feature_names(), columns=['frequency'])\n",
    "    return df_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "affcon_rapport\n",
      "                         frequency\n",
      "more tempting if              2437\n",
      "more strength                 1760\n",
      "more interested               1401\n",
      "morning but might be          1212\n",
      "mos arm                        889\n",
      "mood for message               788\n",
      "more year it will              648\n",
      "more in the                    617\n",
      "more inclined to               599\n",
      "mos bud gal                    595\n",
      "moscow offers                  572\n",
      "morning so didnt think         555\n",
      "mood                           531\n",
      "more organized than the        484\n",
      "mos northward                  467\n",
      "more organized than            447\n",
      "more or                        427\n",
      "most two units                 420\n",
      "most natural                   381\n",
      "mos                            370\n",
      "                      frequency\n",
      "move straight               390\n",
      "move out of my              281\n",
      "multiple dots off of        225\n",
      "moves and talks             188\n",
      "multiple dots off           128\n",
      "moves over the next         125\n",
      "means yes                   115\n",
      "move sets                   101\n",
      "munich                       99\n",
      "move the fleet               92\n",
      "more in                      86\n",
      "mun bur                      85\n",
      "moves but                    84\n",
      "moves but that youve         80\n",
      "more imposing                79\n",
      "meant you want               79\n",
      "no hard feelings             73\n",
      "mun but                      63\n",
      "next from                    61\n",
      "me know if                   58\n",
      "affcon_shareinformation\n",
      "                               frequency\n",
      "more meant the greece               2393\n",
      "more maybe                          1708\n",
      "mos northward                       1372\n",
      "more organized than the             1187\n",
      "more of                              875\n",
      "most natural                         763\n",
      "more pro                             635\n",
      "mos stp in spring                    597\n",
      "mos stp because                      593\n",
      "more useful to                       575\n",
      "more communication all around        565\n",
      "more of an opportunity               546\n",
      "more time looking over               534\n",
      "mos northward this turn              495\n",
      "more valuable than your              463\n",
      "move set might make                  443\n",
      "mnage                                421\n",
      "move rum gal                         403\n",
      "monday night and ill                 359\n",
      "move into it                         357\n",
      "                            frequency\n",
      "more sense                        404\n",
      "more than                         298\n",
      "mind lmao                         239\n",
      "more comfortable but in           199\n",
      "more awake but                    149\n",
      "much fun on the                   145\n",
      "maybe see                         119\n",
      "more support from you             113\n",
      "move while they put               100\n",
      "mean what                          94\n",
      "move with norway                   91\n",
      "much less                          84\n",
      "more concerned                     84\n",
      "more                               80\n",
      "more concerned with losing         80\n",
      "more aware of it                   80\n",
      "my part of                         78\n",
      "more before commit                 71\n",
      "more options for                   68\n",
      "might be worth                     66\n",
      "affcon_reasoning\n",
      "                      frequency\n",
      "might not trust me         2406\n",
      "might mean that            1729\n",
      "misorder or                1363\n",
      "might take that            1163\n",
      "might request bounce        867\n",
      "messages                    769\n",
      "might use in                632\n",
      "miss by                     592\n",
      "minimum of five             582\n",
      "misplay this one            575\n",
      "messed that                 569\n",
      "might resent                530\n",
      "mine                        521\n",
      "might bounce                488\n",
      "mins to                     462\n",
      "mean to                     437\n",
      "mean tough sell             421\n",
      "mean to take st             404\n",
      "more centers                379\n",
      "more proactive              348\n",
      "                                        frequency\n",
      "minds if we went                              421\n",
      "minds if we                                   300\n",
      "mind giving it to                             259\n",
      "might say have to                             219\n",
      "mind that you are                             156\n",
      "mos                                           140\n",
      "most important                                126\n",
      "minds                                         115\n",
      "moving on the                                 109\n",
      "me staying with                                97\n",
      "moving out of                                  96\n",
      "mind that you                                  95\n",
      "might not recover                              92\n",
      "mentioned specifically because england         92\n",
      "mind giving it                                 88\n",
      "mind                                           86\n",
      "moscow as well                                 79\n",
      "more keen to                                   76\n",
      "might say have                                 75\n",
      "may have reached out                           69\n",
      "affcon_gamemove\n",
      "                           frequency\n",
      "mean there no solo              2532\n",
      "mean to be                      1817\n",
      "meanwhile germany built         1450\n",
      "mean that you basically         1241\n",
      "mean the fleet in                905\n",
      "message england sent to          813\n",
      "mean no truce with               665\n",
      "measures may need                626\n",
      "measures                         605\n",
      "me where cant move               603\n",
      "me to say                        584\n",
      "mean the english channel         562\n",
      "me wonder did                    553\n",
      "means don play                   498\n",
      "me what your plans               492\n",
      "momentum on you                  477\n",
      "moment no opportunity for        439\n",
      "me theyre                        420\n",
      "me to build                      388\n",
      "me sending                       375\n",
      "                            frequency\n",
      "necessary to                      304\n",
      "negotiated with russia not        223\n",
      "my advice about what              187\n",
      "need some                         163\n",
      "negotaitions with italy           120\n",
      "of 1910                           111\n",
      "my suggestions either              96\n",
      "northern fleet                     95\n",
      "no way                             87\n",
      "mun boh                            85\n",
      "necessary to force                 84\n",
      "near impossible                    83\n",
      "not under threat                   77\n",
      "negotiated                         75\n",
      "need some help                     68\n",
      "nth                                57\n",
      "need to be                         56\n",
      "moving into tyr can                56\n",
      "of want                            55\n",
      "negotiating                        54\n"
     ]
    }
   ],
   "source": [
    "for item in items: \n",
    "    print(item)\n",
    "    df_yes = full_df[full_df[item] == 1]\n",
    "    df_no = full_df[full_df[item] == 0]\n",
    "    \n",
    "    df_yes_freq = get_freq_df(df_yes)\n",
    "    df_no_freq = get_freq_df(df_no)\n",
    "    \n",
    "    df_yes_freq = df_yes_freq.sort_values(by=['frequency'], ascending=False)\n",
    "    print(df_yes_freq.head(20))\n",
    "    \n",
    "    df_no_freq = df_no_freq.sort_values(by=['frequency'], ascending=False)\n",
    "    print(df_no_freq.head(20))\n",
    "    \n",
    "    df_yes_freq.to_csv('./ngrams_results/kokil dec 6 reprepare/df_' + item +'_yes_ngrams.csv')\n",
    "    df_no_freq.to_csv('./ngrams_results/kokil dec 6 reprepare/df_' + item +'_no_ngrams.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rapport_frequency.to_csv('./ngrams_results/df_shareinfo_ngrams.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding Pronouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_person = [\"i\", \"me\", \"mine\", \"myself\", \"we\", \"us\", \"ours\", \"ourselves\", \"our\"]\n",
    "second_person = [\"you\",\"your\",\"yours\",\"yourself\",\"yourselves\"]\n",
    "third_person = [\"he\", \"she\", \"him\", \"her\", \"his\", \"hers\", \"himself\", \"herself\"\n",
    "                \"they\", \"them\", \"theirs\", \"themselves\", \"their\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = ['affcon_rapport', 'affcon_shareinformation', 'affcon_reasoning', 'affcon_gamemove']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "\n",
    "def get_pronouns_per_row(item_df):\n",
    "    first_list = []\n",
    "    second_list = []\n",
    "    third_list = []\n",
    "\n",
    "    total_words = 0\n",
    "    \n",
    "    for idx, row in item_df.iterrows():\n",
    "        text = row['Input.full_text'].strip()\n",
    "        text_split = text.split(' ')\n",
    "        for word in text_split:\n",
    "            word = re.sub(\"\\.|\\,|\\:|\\!|\\?|\\\"|\\'|\\;|\\)|\\(\", \"\", word)\n",
    "            total_words += 1\n",
    "            word = word.lower()\n",
    "\n",
    "            if word in first_person: \n",
    "                first_list.append(word)\n",
    "            elif word in second_person: \n",
    "                second_list.append(word)\n",
    "            elif word in third_person:\n",
    "                third_list.append(word)\n",
    "\n",
    "    length_first = len(first_list)\n",
    "    length_second = len(second_list)\n",
    "    length_third = len(third_list)\n",
    "\n",
    "    nominalize = 100\n",
    "\n",
    "    length_first = (length_first/total_words) * nominalize\n",
    "    length_second = (length_second/total_words) * nominalize\n",
    "    length_third = (length_third/total_words) * nominalize\n",
    "\n",
    "    #print('first: ', length_first, '\\n', 'second: ', length_second, '\\n', 'third: ', length_third)\n",
    "    \n",
    "    return length_first, length_second, length_third"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "affcon_rapport\n",
      "yes first:  5.426756283951754 \n",
      " second:  3.565049258815947 \n",
      " third:  1.2153577018690729\n",
      "no first:  5.193611398368379 \n",
      " second:  3.4700677927151555 \n",
      " third:  1.1720096518441918\n",
      "affcon_shareinformation\n",
      "yes first:  5.353789529031774 \n",
      " second:  3.4965822879891832 \n",
      " third:  1.3051153008337715\n",
      "no first:  5.4890767372927876 \n",
      " second:  3.7106158744099242 \n",
      " third:  0.8562959710176747\n",
      "affcon_reasoning\n",
      "yes first:  5.3607742712962265 \n",
      " second:  3.5493710928673643 \n",
      " third:  1.2239210665059876\n",
      "no first:  5.3957962982327725 \n",
      " second:  3.46125692774234 \n",
      " third:  1.2862072571368817\n",
      "affcon_gamemove\n",
      "yes first:  5.35598937773631 \n",
      " second:  3.541950764372354 \n",
      " third:  1.2273020885667123\n",
      "no first:  5.617977528089887 \n",
      " second:  3.4520102883443884 \n",
      " third:  1.2048192771084338\n"
     ]
    }
   ],
   "source": [
    "for item in items: \n",
    "    print(item)\n",
    "    df_yes = full_df[full_df[item] == 1]\n",
    "    df_no = full_df[full_df[item] == 0]\n",
    "    \n",
    "    yes_length_first, yes_length_second, yes_length_third = get_pronouns_per_row(df_yes)\n",
    "    no_length_first, no_length_second, no_length_third = get_pronouns_per_row(df_no)\n",
    "    \n",
    "    print('yes first: ', yes_length_first, '\\n', 'second: ', yes_length_second, '\\n', 'third: ', yes_length_third)\n",
    "    print('no first: ', no_length_first, '\\n', 'second: ', no_length_second, '\\n', 'third: ', no_length_third)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### For full df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "\n",
    "for idx, row in full_df.iterrows():\n",
    "    text = row['Input.full_text'].strip()\n",
    "    text_split = text.split(' ')\n",
    "    \n",
    "    first_person_count = 0\n",
    "    second_person_count = 0\n",
    "    third_person_count = 0\n",
    "    total_words = 0\n",
    "    \n",
    "    for word in text_split:\n",
    "        word = re.sub(\"\\.|\\,|\\:|\\!|\\?|\\\"|\\'|\\;|\\)|\\(\", \"\", word)\n",
    "        total_words += 1\n",
    "        word = word.lower()\n",
    "        \n",
    "        if word in first_person: \n",
    "            first_person_count += 1\n",
    "        elif word in second_person: \n",
    "            second_person_count += 1\n",
    "        elif word in third_person:\n",
    "            third_person_count += 1\n",
    "            \n",
    "        full_df.at[idx, 'first_person'] = float(first_person_count/ total_words)\n",
    "        full_df.at[idx, 'second_person'] = float(second_person_count/ total_words)\n",
    "        full_df.at[idx, 'third_person'] = float(third_person_count/ total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    4420.000000\n",
       "mean        0.053339\n",
       "std         0.060171\n",
       "min         0.000000\n",
       "25%         0.000000\n",
       "50%         0.043478\n",
       "75%         0.095238\n",
       "max         0.333333\n",
       "Name: first_person, dtype: float64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_no_rapport['first_person'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    4420.000000\n",
       "mean        0.037571\n",
       "std         0.056038\n",
       "min         0.000000\n",
       "25%         0.000000\n",
       "50%         0.000000\n",
       "75%         0.071429\n",
       "max         0.333333\n",
       "Name: second_person, dtype: float64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_no_rapport['second_person'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    4420.000000\n",
       "mean        0.010441\n",
       "std         0.031292\n",
       "min         0.000000\n",
       "25%         0.000000\n",
       "50%         0.000000\n",
       "75%         0.000000\n",
       "max         0.333333\n",
       "Name: third_person, dtype: float64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_no_rapport['third_person'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    11318.000000\n",
       "mean         0.053954\n",
       "std          0.057895\n",
       "min          0.000000\n",
       "25%          0.000000\n",
       "50%          0.047619\n",
       "75%          0.090909\n",
       "max          0.333333\n",
       "Name: first_person, dtype: float64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rapport['first_person'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    11318.000000\n",
       "mean         0.039349\n",
       "std          0.053361\n",
       "min          0.000000\n",
       "25%          0.000000\n",
       "50%          0.000000\n",
       "75%          0.074074\n",
       "max          0.400000\n",
       "Name: second_person, dtype: float64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rapport['second_person'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    11318.000000\n",
       "mean         0.010886\n",
       "std          0.030706\n",
       "min          0.000000\n",
       "25%          0.000000\n",
       "50%          0.000000\n",
       "75%          0.000000\n",
       "max          0.285714\n",
       "Name: third_person, dtype: float64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rapport['third_person'].describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfgpu",
   "language": "python",
   "name": "tfgpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
