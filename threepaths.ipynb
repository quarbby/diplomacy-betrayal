{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Input, InputLayer, Dropout, Dense, Flatten, Embedding\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.initializers import TruncatedNormal\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import CategoricalAccuracy\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/affcon_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Input.convo_id', 'Input.train_test_val', 'Input.msg_id',\n",
       "       'Input.timestamp', 'Input.full_text', 'affcon_gamemove',\n",
       "       'affcon_reasoning', 'affcon_rapport', 'affcon_shareinformation',\n",
       "       'Input.speaker', 'Input.reply_to', 'Input.speaker_intention',\n",
       "       'Input.reciever_perception', 'Input.reciever',\n",
       "       'Input.absolute_message_index', 'Input.relative_message_index',\n",
       "       'Input.year', 'Input.game_score_speaker', 'Input.game_score_receiver',\n",
       "       'Input.game_score_delta', 'Input.deception_quadrant', 'Input.num_words',\n",
       "       'Input.num_characters', 'Input.sno', 'Input.sno1'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Input.full_text'] = df['Input.full_text'].fillna(0)\n",
    "df['Input.full_text'] = df['Input.full_text'].replace('\\n','', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train['Input.full_text'].to_list()\n",
    "y_train_rapport = train['affcon_rapport'].tolist()\n",
    "y_train_share_information = train['affcon_shareinformation'].tolist()\n",
    "y_train_reasoning = train['affcon_reasoning'].tolist()\n",
    "y_train_gamemove = train['affcon_gamemove'].tolist()\n",
    "y_train_deception_quad = train['Input.deception_quadrant'].tolist()\n",
    "\n",
    "X_test = test['Input.full_text'].to_list()\n",
    "y_test_rapport = test['affcon_rapport'].tolist()\n",
    "y_test_share_information = test['affcon_shareinformation'].tolist()\n",
    "y_test_reasoning = test['affcon_reasoning'].tolist()\n",
    "y_test_gamemove = test['affcon_gamemove'].tolist()\n",
    "y_test_deception_quad = test['Input.deception_quadrant'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel, BertTokenizer, BertConfig\n",
    "\n",
    "max_length = 100\n",
    "configuration = BertConfig()\n",
    "model = BertModel(configuration)\n",
    "configuration = model.config\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_rapport_class = to_categorical(y_train_rapport)\n",
    "Y_train_share_information_class = to_categorical(y_train_share_information)\n",
    "Y_train_reasoning_class = to_categorical(y_train_reasoning)\n",
    "Y_train_gamemove_class = to_categorical(y_train_gamemove)\n",
    "Y_train_deception_class = to_categorical(y_train_deception_quad)\n",
    "\n",
    "Y_test_rapport_class = to_categorical(y_test_rapport)\n",
    "Y_test_share_information_class = to_categorical(y_test_share_information)\n",
    "Y_test_reasoning_class = to_categorical(y_test_reasoning)\n",
    "Y_test_gamemove_class = to_categorical(y_test_gamemove)\n",
    "Y_test_deception_class = to_categorical(y_test_deception)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_text = tokenizer(\n",
    "    text=X_train,\n",
    "    add_special_tokens=True,\n",
    "    max_length=max_length,\n",
    "    padding='max_length',\n",
    "    truncation=True,\n",
    "    return_tensors='tf',\n",
    "    return_token_type_ids = False,\n",
    "    return_attention_mask = False,\n",
    "    verbose = True)\n",
    "\n",
    "X_test_text = tokenizer(\n",
    "    text=X_test,\n",
    "    add_special_tokens=True,\n",
    "    max_length=max_length,\n",
    "    padding='max_length',\n",
    "    truncation=True,\n",
    "    return_tensors='tf',\n",
    "    return_token_type_ids = False,\n",
    "    return_attention_mask = False,\n",
    "    verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', min_delta=0, patience=0, verbose=0, mode='auto',\n",
    "    baseline=None, restore_best_weights=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_for_pre_training_1/bert/pooler/dense/kernel:0', 'tf_bert_for_pre_training_1/bert/pooler/dense/bias:0', 'tf_bert_for_pre_training_1/nsp___cls/seq_relationship/kernel:0', 'tf_bert_for_pre_training_1/nsp___cls/seq_relationship/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_for_pre_training_1/bert/pooler/dense/kernel:0', 'tf_bert_for_pre_training_1/bert/pooler/dense/bias:0', 'tf_bert_for_pre_training_1/nsp___cls/seq_relationship/kernel:0', 'tf_bert_for_pre_training_1/nsp___cls/seq_relationship/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_for_pre_training_1/bert/pooler/dense/kernel:0', 'tf_bert_for_pre_training_1/bert/pooler/dense/bias:0', 'tf_bert_for_pre_training_1/nsp___cls/seq_relationship/kernel:0', 'tf_bert_for_pre_training_1/nsp___cls/seq_relationship/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_for_pre_training_1/bert/pooler/dense/kernel:0', 'tf_bert_for_pre_training_1/bert/pooler/dense/bias:0', 'tf_bert_for_pre_training_1/nsp___cls/seq_relationship/kernel:0', 'tf_bert_for_pre_training_1/nsp___cls/seq_relationship/bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "2 root error(s) found.\n  (0) Resource exhausted:  OOM when allocating tensor with shape[8,12,100,100] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node functional_11/tf_bert_for_pre_training_1/bert/encoder/layer_._0/attention/self/Softmax (defined at C:\\Users\\lynne\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\transformers\\modeling_tf_bert.py:262) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[gradient_tape/functional_11/tf_bert_for_pre_training_1/bert/embeddings/add/Sum/_30]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n  (1) Resource exhausted:  OOM when allocating tensor with shape[8,12,100,100] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node functional_11/tf_bert_for_pre_training_1/bert/encoder/layer_._0/attention/self/Softmax (defined at C:\\Users\\lynne\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\transformers\\modeling_tf_bert.py:262) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_259954]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node functional_11/tf_bert_for_pre_training_1/bert/encoder/layer_._0/attention/self/Softmax:\n functional_11/tf_bert_for_pre_training_1/bert/encoder/layer_._0/attention/self/add (defined at C:\\Users\\lynne\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\transformers\\modeling_tf_bert.py:259)\n\nInput Source operations connected to node functional_11/tf_bert_for_pre_training_1/bert/encoder/layer_._0/attention/self/Softmax:\n functional_11/tf_bert_for_pre_training_1/bert/encoder/layer_._0/attention/self/add (defined at C:\\Users\\lynne\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\transformers\\modeling_tf_bert.py:259)\n\nFunction call stack:\ntrain_function -> train_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-1f80d915c045>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mgamemove_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'binary_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'acc'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mf1_m\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mprecision_m\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecall_m\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m history = gamemove_model.fit(X_train_text['input_ids'], Y_train_gamemove_class, epochs=8, batch_size=8, \n\u001b[1;32m---> 14\u001b[1;33m                     validation_split=0.2, callbacks=[callback])\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgamemove_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_text\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'input_ids'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_test_gamemove_class\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprecision\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecall\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    838\u001b[0m         \u001b[1;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    839\u001b[0m         \u001b[1;31m# stateless function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 840\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    841\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    842\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[0;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1848\u001b[1;33m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1850\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1924\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: 2 root error(s) found.\n  (0) Resource exhausted:  OOM when allocating tensor with shape[8,12,100,100] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node functional_11/tf_bert_for_pre_training_1/bert/encoder/layer_._0/attention/self/Softmax (defined at C:\\Users\\lynne\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\transformers\\modeling_tf_bert.py:262) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[gradient_tape/functional_11/tf_bert_for_pre_training_1/bert/embeddings/add/Sum/_30]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n  (1) Resource exhausted:  OOM when allocating tensor with shape[8,12,100,100] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node functional_11/tf_bert_for_pre_training_1/bert/encoder/layer_._0/attention/self/Softmax (defined at C:\\Users\\lynne\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\transformers\\modeling_tf_bert.py:262) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_259954]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node functional_11/tf_bert_for_pre_training_1/bert/encoder/layer_._0/attention/self/Softmax:\n functional_11/tf_bert_for_pre_training_1/bert/encoder/layer_._0/attention/self/add (defined at C:\\Users\\lynne\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\transformers\\modeling_tf_bert.py:259)\n\nInput Source operations connected to node functional_11/tf_bert_for_pre_training_1/bert/encoder/layer_._0/attention/self/Softmax:\n functional_11/tf_bert_for_pre_training_1/bert/encoder/layer_._0/attention/self/add (defined at C:\\Users\\lynne\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\transformers\\modeling_tf_bert.py:259)\n\nFunction call stack:\ntrain_function -> train_function\n"
     ]
    }
   ],
   "source": [
    "# Game move model\n",
    "input_ids_in = tf.keras.layers.Input(shape=(max_length,), name='input_token', dtype='int32')\n",
    "\n",
    "embedding_layer = auto_model(input_ids_in)[0]\n",
    "cls_token = embedding_layer[:,0,:]\n",
    "X = tf.keras.layers.BatchNormalization()(cls_token)\n",
    "X = tf.keras.layers.Dense(192, activation='relu')(X)\n",
    "X = tf.keras.layers.Dropout(0.2)(X)\n",
    "X = tf.keras.layers.Dense(2, activation='softmax')(X)\n",
    "gamemove_model = tf.keras.Model(inputs=input_ids_in, outputs = X)\n",
    "\n",
    "gamemove_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc',f1_m,precision_m, recall_m])\n",
    "history = gamemove_model.fit(X_train_text['input_ids'], Y_train_gamemove_class, epochs=8, batch_size=8, \n",
    "                    validation_split=0.2, callbacks=[callback])\n",
    "loss, accuracy, f1_score, precision, recall = gamemove_model.evaluate(X_test_text['input_ids'], Y_test_gamemove_class, verbose=0)\n",
    "print(precision, recall, f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_for_pre_training_1/bert/pooler/dense/kernel:0', 'tf_bert_for_pre_training_1/bert/pooler/dense/bias:0', 'tf_bert_for_pre_training_1/nsp___cls/seq_relationship/kernel:0', 'tf_bert_for_pre_training_1/nsp___cls/seq_relationship/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_for_pre_training_1/bert/pooler/dense/kernel:0', 'tf_bert_for_pre_training_1/bert/pooler/dense/bias:0', 'tf_bert_for_pre_training_1/nsp___cls/seq_relationship/kernel:0', 'tf_bert_for_pre_training_1/nsp___cls/seq_relationship/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_for_pre_training_1/bert/pooler/dense/kernel:0', 'tf_bert_for_pre_training_1/bert/pooler/dense/bias:0', 'tf_bert_for_pre_training_1/nsp___cls/seq_relationship/kernel:0', 'tf_bert_for_pre_training_1/nsp___cls/seq_relationship/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_for_pre_training_1/bert/pooler/dense/kernel:0', 'tf_bert_for_pre_training_1/bert/pooler/dense/bias:0', 'tf_bert_for_pre_training_1/nsp___cls/seq_relationship/kernel:0', 'tf_bert_for_pre_training_1/nsp___cls/seq_relationship/bias:0'] when minimizing the loss.\n",
      "2518/2518 [==============================] - 357s 142ms/step - loss: 4.7668 - acc: 0.6881 - f1_m: 0.6881 - precision_m: 0.6881 - recall_m: 0.6881 - val_loss: 3.6729 - val_acc: 0.7605 - val_f1_m: 0.7607 - val_precision_m: 0.7607 - val_recall_m: 0.7607\n",
      "0.7646253705024719 0.7646253705024719 0.7646253108978271\n"
     ]
    }
   ],
   "source": [
    "# Reasoning model \n",
    "input_ids_in = tf.keras.layers.Input(shape=(max_length,), dtype='int32')\n",
    "\n",
    "embedding_layer = auto_model(input_ids_in)[0]\n",
    "cls_token = embedding_layer[:,0,:]\n",
    "X = tf.keras.layers.BatchNormalization()(cls_token)\n",
    "X = tf.keras.layers.Dense(192, activation='relu')(X)\n",
    "X = tf.keras.layers.Dropout(0.2)(X)\n",
    "X = tf.keras.layers.Dense(2, activation='softmax')(X)\n",
    "reasoning_model = tf.keras.Model(inputs=input_ids_in, outputs = X)\n",
    "\n",
    "reasoning_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc',f1_m,precision_m, recall_m])\n",
    "history = reasoning_model.fit(X_train_text['input_ids'], Y_train_rapport_class, epochs=8, batch_size=8, \n",
    "                    validation_split=0.2, callbacks=[callback])\n",
    "loss, accuracy, f1_score, precision, recall = reasoning_model.evaluate(X_test_text['input_ids'], Y_test_rapport_class, verbose=0)\n",
    "print(precision, recall, f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_for_pre_training_1/bert/pooler/dense/kernel:0', 'tf_bert_for_pre_training_1/bert/pooler/dense/bias:0', 'tf_bert_for_pre_training_1/nsp___cls/seq_relationship/kernel:0', 'tf_bert_for_pre_training_1/nsp___cls/seq_relationship/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_for_pre_training_1/bert/pooler/dense/kernel:0', 'tf_bert_for_pre_training_1/bert/pooler/dense/bias:0', 'tf_bert_for_pre_training_1/nsp___cls/seq_relationship/kernel:0', 'tf_bert_for_pre_training_1/nsp___cls/seq_relationship/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_for_pre_training_1/bert/pooler/dense/kernel:0', 'tf_bert_for_pre_training_1/bert/pooler/dense/bias:0', 'tf_bert_for_pre_training_1/nsp___cls/seq_relationship/kernel:0', 'tf_bert_for_pre_training_1/nsp___cls/seq_relationship/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_for_pre_training_1/bert/pooler/dense/kernel:0', 'tf_bert_for_pre_training_1/bert/pooler/dense/bias:0', 'tf_bert_for_pre_training_1/nsp___cls/seq_relationship/kernel:0', 'tf_bert_for_pre_training_1/nsp___cls/seq_relationship/bias:0'] when minimizing the loss.\n",
      "2518/2518 [==============================] - 358s 142ms/step - loss: 7.4520 - acc: 0.5132 - f1_m: 0.5132 - precision_m: 0.5132 - recall_m: 0.5132 - val_loss: 7.0838 - val_acc: 0.5381 - val_f1_m: 0.5377 - val_precision_m: 0.5377 - val_recall_m: 0.5377\n",
      "0.5111532211303711 0.5111532211303711 0.5111531615257263\n"
     ]
    }
   ],
   "source": [
    "# Share information model \n",
    "input_ids_in = tf.keras.layers.Input(shape=(max_length,), dtype='int32')\n",
    "\n",
    "embedding_layer = auto_model(input_ids_in)[0]\n",
    "cls_token = embedding_layer[:,0,:]\n",
    "X = tf.keras.layers.BatchNormalization()(cls_token)\n",
    "X = tf.keras.layers.Dense(192, activation='relu')(X)\n",
    "X = tf.keras.layers.Dropout(0.2)(X)\n",
    "X = tf.keras.layers.Dense(2, activation='softmax')(X)\n",
    "shareinfo_model = tf.keras.Model(inputs=input_ids_in, outputs = X)\n",
    "\n",
    "shareinfo_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc',f1_m,precision_m, recall_m])\n",
    "history = shareinfo_model.fit(X_train_text['input_ids'], Y_train_share_information_class, epochs=8, batch_size=8, \n",
    "                    validation_split=0.2, callbacks=[callback])\n",
    "loss, accuracy, f1_score, precision, recall = reasoning_model.evaluate(X_test_text['input_ids'], Y_test_share_information_class, verbose=0)\n",
    "print(precision, recall, f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rapport model \n",
    "input_ids_in = tf.keras.layers.Input(shape=(max_length,), dtype='int32')\n",
    "\n",
    "embedding_layer = auto_model(input_ids_in)[0]\n",
    "cls_token = embedding_layer[:,0,:]\n",
    "X = tf.keras.layers.BatchNormalization()(cls_token)\n",
    "X = tf.keras.layers.Dense(192, activation='relu')(X)\n",
    "X = tf.keras.layers.Dropout(0.2)(X)\n",
    "X = tf.keras.layers.Dense(2, activation='softmax')(X)\n",
    "rapport_model = tf.keras.Model(inputs=input_ids_in, outputs = X)\n",
    "\n",
    "rapport_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc',f1_m,precision_m, recall_m])\n",
    "history = rapport_model.fit(X_train_text['input_ids'], Y_train_rapport_class, epochs=8, batch_size=8, \n",
    "                    validation_split=0.2, callbacks=[callback])\n",
    "loss, accuracy, f1_score, precision, recall = reasoning_model.evaluate(X_test_text['input_ids'], Y_test_rapport_class, verbose=0)\n",
    "print(precision, recall, f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# game move + reasoning - shareinfo\n",
    "\n",
    "from keras.layers import * \n",
    "\n",
    "commonInput = tf.keras.layers.Input(shape=(max_length,))\n",
    "\n",
    "out1 = gamemove_model(commonInput)    \n",
    "out2 = reasoning_model(commonInput)   \n",
    "out3 = shareinfo_model(commonInput)\n",
    "mergedTwo = tf.keras.layers.Add()([out1,out2])\n",
    "mergedOut = tf.keras.layers.Subtract()([mergedTwo, out3])\n",
    "\n",
    "mergedOut = tf.keras.layers.Flatten()(mergedOut)    \n",
    "mergedOut = tf.keras.layers.Dense(256, activation='relu')(mergedOut)\n",
    "mergedOut = tf.keras.layers.Dropout(.5)(mergedOut)\n",
    "mergedOut = tf.keras.layers.Dense(128, activation='relu')(mergedOut)\n",
    "mergedOut = tf.keras.layers.Dropout(.35)(mergedOut)\n",
    "mergedOut = tf.keras.layers.Dense(2, activation='softmax')(mergedOut)  #Cuz binary\n",
    "\n",
    "mergedModel = tf.keras.Model(commonInput, mergedOut)\n",
    "mergedModel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc',f1_m,precision_m, recall_m])\n",
    "mergedModel.fit(X_train_text['input_ids'], Y_train_rapport_class, epochs=8, batch_size=8, \n",
    "                    validation_split=0.2, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# game move + reasoning + shareinfo\n",
    "\n",
    "from keras.layers import * \n",
    "\n",
    "commonInput = tf.keras.layers.Input(shape=(max_length,))\n",
    "\n",
    "out1 = gamemove_model(commonInput)    \n",
    "out2 = reasoning_model(commonInput)   \n",
    "out3 = shareinfo_model(commonInput)\n",
    "mergedOut = tf.keras.layers.Add()([out1,out2,out3])\n",
    "\n",
    "mergedOut = tf.keras.layers.Flatten()(mergedOut)    \n",
    "mergedOut = tf.keras.layers.Dense(256, activation='relu')(mergedOut)\n",
    "mergedOut = tf.keras.layers.Dropout(.5)(mergedOut)\n",
    "mergedOut = tf.keras.layers.Dense(128, activation='relu')(mergedOut)\n",
    "mergedOut = tf.keras.layers.Dropout(.35)(mergedOut)\n",
    "mergedOut = tf.keras.layers.Dense(2, activation='softmax')(mergedOut)  #Cuz binary\n",
    "\n",
    "#mergedModel = Model([model1.input,model2.input], mergedOut)\n",
    "mergedModel = tf.keras.Model(commonInput, mergedOut)\n",
    "mergedModel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc',f1_m,precision_m, recall_m])\n",
    "mergedModel.fit(X_train_text['input_ids'], Y_train_rapport_class, epochs=8, batch_size=8, \n",
    "                    validation_split=0.2, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# game move + reasoning + shareinfo + rapport\n",
    "\n",
    "from keras.layers import * \n",
    "\n",
    "commonInput = tf.keras.layers.Input(shape=(max_length,))\n",
    "\n",
    "out1 = gamemove_model(commonInput)    \n",
    "out2 = reasoning_model(commonInput)   \n",
    "out3 = shareinfo_model(commonInput)\n",
    "out4 = rapport_model(commonInput)\n",
    "mergedOut = tf.keras.layers.Add()([out1,out2,out3,out4])\n",
    "\n",
    "mergedOut = tf.keras.layers.Flatten()(mergedOut)    \n",
    "mergedOut = tf.keras.layers.Dense(256, activation='relu')(mergedOut)\n",
    "mergedOut = tf.keras.layers.Dropout(.5)(mergedOut)\n",
    "mergedOut = tf.keras.layers.Dense(128, activation='relu')(mergedOut)\n",
    "mergedOut = tf.keras.layers.Dropout(.35)(mergedOut)\n",
    "mergedOut = tf.keras.layers.Dense(2, activation='softmax')(mergedOut)  #Cuz binary\n",
    "\n",
    "#mergedModel = Model([model1.input,model2.input], mergedOut)\n",
    "mergedModel = tf.keras.Model(commonInput, mergedOut)\n",
    "mergedModel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc',f1_m,precision_m, recall_m])\n",
    "mergedModel.fit(X_train_text['input_ids'], Y_test_deception_class, epochs=8, batch_size=8, \n",
    "                    validation_split=0.2, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.41065216, 0.5893479 ]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_text_to_predict = tokenizer(\n",
    "    text=\"hello how are you? I love you\",\n",
    "    add_special_tokens=True,\n",
    "    max_length=max_length,\n",
    "    padding='max_length',\n",
    "    truncation=True,\n",
    "    return_tensors='tf',\n",
    "    return_token_type_ids = False,\n",
    "    return_attention_mask = False,\n",
    "    verbose = True)\n",
    "\n",
    "mergedModel.predict(X_text_to_predict['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other merge strategies https://github.com/A2Zadeh/TensorFusionNetwork/blob/master/tf_mosi.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfgpu",
   "language": "python",
   "name": "tfgpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
