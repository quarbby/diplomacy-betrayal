{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import LSTM, Input, InputLayer, Dropout, Dense, Flatten, Embedding, Add, Concatenate\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import import_ipynb\n",
    "import metadata_options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/kokil dec 6 reprepare/conf_pc_worker_sem.csv')\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP1: weighted by 1 average per set of OHE, i.e. (a, b, c, d) -> (w*a, w*b, w*c, w*d)\n",
      "WT2: weighted by 1 linear variance per set of OHE, i.e. (a, b, c, d) -> (w*a, w*b, w*c, w*d)\n",
      "PC3: weighted by 1 PC agreement weight per annotation in each OHE, i.e. (a, b, c, d) -> (w1*a, w2*b, w3*c, w4*d)\n",
      "TL2: weighted by 1 normalised number of words per set of OHE, i.e. (a, b, c, d) -> (w*a, w*b, w*c, w*d)\n"
     ]
    }
   ],
   "source": [
    "df_throughput, df_worktime, df_agreement, df_textlenght = metadata_options.set_OHE_pipeline_options(df, 'TP1', 'WT2', 'PC3', 'TL2', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################\n",
    "## Weighted Onehot Encoding options ##\n",
    "######################################\n",
    "\n",
    "# Select 1 option from each of the 3 variants above, e.g. TP2, WT1, PC3, and input into function\n",
    "# set_OHE_pipeline_options. If not selecting TP3 or TP4, input k (option_k) will be ignored. After\n",
    "# editing the options, run the entire notebook for results accordingly.\n",
    "\n",
    "df_throughput, df_worktime, df_agreement, df_textlenght = set_OHE_pipeline_options(df, 'TP1', 'WT2', 'PC3', 'TL2', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################\n",
    "## Model Options ##\n",
    "######################################\n",
    "# options: randomforest, logreg\n",
    "\n",
    "model_name = 'randomforest'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['Input.msg_id', 'HITId', 'Input.sentence_id', 'Input.convo_id', 'Input.train_test_val',\n",
    "                     'Input.similar_text_id', 'Input.msg_id', 'Input.timestamp', 'Input.full_text',\n",
    "                      'Input.speaker', 'Input.reply_to', \n",
    "                      'Input.game_score_delta', 'Input.game_score_receiver',\n",
    "                      'Input.speaker_intention', 'Input.reciever_perception', 'Input.reciever',\n",
    "                      'Input.absolute_message_index', 'Input.relative_message_index', 'Input.year',\n",
    "                      'Input.game_score_speaker', 'Input.num_words', 'Input.num_characters', \n",
    "                      'Input.sno', 'Input.sno1',\n",
    "                      'WorkTime.1', 'WorkTime.2', 'WorkTime.3', 'WorkTime.4', 'WorkTime.5',\n",
    "                      'Throughput.1', 'Throughput.2', 'Throughput.3', 'Throughput.4', 'Throughput.5',\n",
    "                      'Answer.1gamemove.yes', 'Answer.2reasoning.yes',\n",
    "                      'Answer.3a_apologies.yes', 'Answer.3a_compliment.yes', 'Answer.3a_personalthoughts.yes',\n",
    "                      'Answer.3a_reassurance.yes', 'Answer.3rapport.yes', 'Answer.4shareinformation.yes', 'count',\n",
    "                      'Answer.1gamemove.yes_pc_agree', 'Answer.2reasoning.yes_pc_agree', \n",
    "                      'Answer.3a_apologies.yes_pc_agree', 'Answer.3a_compliment.yes_pc_agree',\n",
    "                      'Answer.3a_personalthoughts.yes_pc_agree', 'Answer.3a_reassurance.yes_pc_agree',\n",
    "                      'Answer.3rapport.yes_pc_agree', 'Answer.4shareinformation.yes_pc_agree', \n",
    "                      'message_id.x', 'message_id.y',\n",
    "                      'Answer.3a_apologies.yes_label', 'Answer.3a_compliment.yes_label',\n",
    "                      'Answer.3a_personalthoughts.yes_label', 'Answer.3a_reassurance.yes_label'\n",
    "                     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = range(df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test, indices_train, indices_test = train_test_split(df, indices, test_size=0.2)\n",
    "\n",
    "new_deception_train = train[\"Input.deception_quadrant\"].copy()\n",
    "new_deception_train['Input.deception_quadrant'] = train[\"Input.deception_quadrant\"].apply(lambda x : 1 if x == \"Straightforward\" else 0)\n",
    "y_train_deception = new_deception_train['Input.deception_quadrant'].tolist()\n",
    "y_train_rapport = train['Answer.3rapport.yes_label'].tolist()\n",
    "y_train_share_information = train['Answer.4shareinformation.yes_label'].tolist()\n",
    "y_train_reasoning = train['Answer.2reasoning.yes_label'].tolist()\n",
    "y_train_gamemove = train['Answer.1gamemove.yes_label'].tolist()\n",
    "\n",
    "new_deception_test = test[\"Input.deception_quadrant\"].copy()\n",
    "new_deception_test['Input.deception_quadrant'] = test[\"Input.deception_quadrant\"].apply(lambda x : 1 if x == \"Straightforward\" else 0)\n",
    "y_test_deception = new_deception_test['Input.deception_quadrant'].tolist()\n",
    "y_test_rapport = test['Answer.3rapport.yes_label'].tolist()\n",
    "y_test_share_information = test['Answer.4shareinformation.yes_label'].tolist()\n",
    "y_test_reasoning = test['Answer.2reasoning.yes_label'].tolist()\n",
    "y_test_gamemove = test['Answer.1gamemove.yes_label'].tolist()\n",
    "\n",
    "X_train = train.drop(columns=['Answer.1gamemove.yes_label', 'Answer.2reasoning.yes_label',\n",
    "                              'Answer.3rapport.yes_label', 'Answer.4shareinformation.yes_label', 'Input.deception_quadrant'])\n",
    "\n",
    "X_test = test.drop(columns=['Answer.1gamemove.yes_label', 'Answer.2reasoning.yes_label',\n",
    "                              'Answer.3rapport.yes_label', 'Answer.4shareinformation.yes_label', 'Input.deception_quadrant'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Individual classifiers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       1.00      0.93      0.96      9092\n",
      "\n",
      "    accuracy                           0.93      9092\n",
      "   macro avg       0.50      0.47      0.48      9092\n",
      "weighted avg       1.00      0.93      0.96      9092\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lynne\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Game move classifier\n",
    "clf_gamemove = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "clf_gamemove.fit(X_train, y_train_gamemove)\n",
    "y_pred_gamemove = clf_gamemove.predict(X_train)\n",
    "y_pred_test_gamemove = clf_gamemove.predict(X_test)\n",
    "print(classification_report(y_pred_gamemove, y_train_gamemove))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       1.00      0.86      0.93      9092\n",
      "\n",
      "    accuracy                           0.86      9092\n",
      "   macro avg       0.50      0.43      0.46      9092\n",
      "weighted avg       1.00      0.86      0.93      9092\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lynne\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Rapport classifier\n",
    "clf_rapport = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "clf_rapport.fit(X_train, y_train_rapport)\n",
    "y_pred_rapport = clf_rapport.predict(X_train)\n",
    "y_pred_test_rapport = clf_rapport.predict(X_test)\n",
    "print(classification_report(y_pred_rapport, y_train_rapport))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       1.00      0.84      0.91      9092\n",
      "\n",
      "    accuracy                           0.84      9092\n",
      "   macro avg       0.50      0.42      0.46      9092\n",
      "weighted avg       1.00      0.84      0.91      9092\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lynne\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Share Information classifier\n",
    "clf_shareinfo = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "clf_shareinfo.fit(X_train, y_train_share_information)\n",
    "y_pred_shareinfo = clf_shareinfo.predict(X_train)\n",
    "y_pred_test_shareinfo = clf_shareinfo.predict(X_test)\n",
    "print(classification_report(y_pred_shareinfo, y_train_share_information))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       1.00      0.83      0.91      9092\n",
      "\n",
      "    accuracy                           0.83      9092\n",
      "   macro avg       0.50      0.41      0.45      9092\n",
      "weighted avg       1.00      0.83      0.91      9092\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lynne\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Reasoning classifier\n",
    "clf_reasoning = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "clf_reasoning.fit(X_train, y_train_reasoning)\n",
    "y_pred_reasoning = clf_reasoning.predict(X_train)\n",
    "y_pred_test_reasoning = clf_reasoning.predict(X_test)\n",
    "print(classification_report(y_pred_reasoning, y_train_reasoning))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One hot encodings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train encodings\n",
    "pred_df_arr_full = []\n",
    "pred_df_arr = []\n",
    "for i in range(0, len(y_pred_gamemove)):  \n",
    "    pred_obj_1 = {}\n",
    "    pred_obj_1['gamemove'] = y_pred_gamemove[i]\n",
    "    pred_obj_1['reasoning'] = y_pred_reasoning[i]\n",
    "    pred_obj_1['shareinfo'] = y_pred_shareinfo[i]\n",
    "    pred_df_arr.append(pred_obj_1)\n",
    "    \n",
    "    pred_obj_2 = pred_obj_1.copy()\n",
    "    pred_obj_2['rapport'] = y_pred_rapport[i]\n",
    "    pred_df_arr_full.append(pred_obj_2)\n",
    "    \n",
    "pred_df_full = pd.DataFrame(pred_df_arr_full)\n",
    "pred_df = pd.DataFrame(pred_df_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test encodings\n",
    "pred_test_df_arr_full = []\n",
    "pred_test_df_arr = []\n",
    "\n",
    "for i in range(0, len(y_pred_test_gamemove)):\n",
    "    pred_obj_1 = {}\n",
    "    pred_obj_1['gamemove'] = y_pred_test_gamemove[i]\n",
    "    pred_obj_1['reasoning'] = y_pred_test_reasoning[i]\n",
    "    pred_obj_1['shareinfo'] = y_pred_test_shareinfo[i]\n",
    "    pred_test_df_arr.append(pred_obj_1)\n",
    "    \n",
    "    pred_obj_2 = pred_obj_1.copy()\n",
    "    pred_obj_2['rapport'] = y_pred_test_rapport[i]\n",
    "    pred_test_df_arr_full.append(pred_obj_2)\n",
    "    \n",
    "pred_test_df_full = pd.DataFrame(pred_test_df_arr_full)\n",
    "pred_test_df = pd.DataFrame(pred_test_df_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train weighted encodings\n",
    "pred_df_full_throughput = pred_df_full.copy()\n",
    "pred_df_full_worktime = pred_df_full.copy()\n",
    "pred_df_full_agreement = pred_df_full.copy()\n",
    "\n",
    "pred_df_throughput = pred_df.copy()\n",
    "pred_df_worktime = pred_df.copy()\n",
    "pred_df_agreement = pred_df.copy()\n",
    "\n",
    "# Throughput values\n",
    "throughput_values = df_throughput['avg_throughput'].take(indices_train).values\n",
    "#throughput_values = df_throughput['var_throughput'].take(indices_train).values\n",
    "#throughput_values = df_throughput['var_throughput_u_shaped'].take(indices_train).values\n",
    "\n",
    "pred_df_full_throughput = pred_df_full_throughput.mul(throughput_values, axis=0)\n",
    "pred_df_throughput = pred_df_throughput.mul(throughput_values, axis=0)\n",
    "\n",
    "# Worktime values \n",
    "worktime_values = df_worktime['avg_worktime'].take(indices_train).values\n",
    "#worktime_values = df_worktime['var_worktime'].take(indices_train).values\n",
    "\n",
    "pred_df_full_worktime = pred_df_full_worktime.mul(worktime_values, axis=0)\n",
    "pred_df_worktime = pred_df_worktime.mul(worktime_values, axis=0)\n",
    "\n",
    "# PC Agreement values \n",
    "#agreement_values = df_agreement['avg_agreement'].take(indices_train).values\n",
    "agreement_values = df_agreement['var_agreement'].take(indices_train).values\n",
    "pred_df_full_agreement = pred_df_full_agreement.mul(agreement_values, axis=0)\n",
    "pred_df_agreement = pred_df_agreement.mul(agreement_values, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test weighted encodings\n",
    "pred_df_full_throughput_test = pred_test_df_full.copy()\n",
    "pred_df_full_worktime_test = pred_test_df_full.copy()\n",
    "pred_df_full_agreement_test = pred_test_df_full.copy()\n",
    "\n",
    "pred_df_throughput_test = pred_test_df.copy()\n",
    "pred_df_worktime_test = pred_test_df.copy()\n",
    "pred_df_agreement_test = pred_test_df.copy()\n",
    "\n",
    "# Throughput\n",
    "throughput_values_test = df_throughput['avg_throughput'].take(indices_test).values\n",
    "#throughput_values_test = df_throughput['var_throughput'].take(indices_test).values\n",
    "#throughput_values_test = df_throughput['var_throughput_u_shaped'].take(indices_test).values\n",
    "\n",
    "pred_df_full_throughput_test = pred_df_full_throughput_test.mul(throughput_values_test, axis=0)\n",
    "pred_df_throughput_test = pred_df_throughput_test.mul(throughput_values_test, axis=0)\n",
    "\n",
    "# Worktime\n",
    "worktime_values_test = df_worktime['avg_worktime'].take(indices_test).values\n",
    "#worktime_values_test = df_worktime['var_worktime'].take(indices_test).values\n",
    "\n",
    "pred_df_full_worktime_test = pred_df_full_worktime_test.mul(worktime_values_test, axis=0)\n",
    "pred_df_worktime_test = pred_df_worktime_test.mul(worktime_values_test, axis=0)\n",
    "\n",
    "# Agreement\n",
    "#agreement_values_test = df_agreement['avg_agreement'].take(indices_test).values\n",
    "agreement_values_test = df_agreement['var_agreement'].take(indices_test).values\n",
    "pred_df_full_agreement_test = pred_df_full_agreement_test.mul(agreement_values_test, axis=0)\n",
    "pred_df_agreement_test = pred_df_agreement_test.mul(agreement_values_test, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joint model is dense layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', min_delta=0, patience=0, verbose=0, mode='auto',\n",
    "    baseline=None, restore_best_weights=False\n",
    ")\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    classes_number=2\n",
    "    result = 0.0\n",
    "    for class_id in range(1, classes_number + 1):\n",
    "        y_true_single_class = y_true[:,:,class_id]\n",
    "        y_pred_single_class = y_pred[:,:,class_id]\n",
    "        f1_single = f1_binary(y_true_single_class, y_pred_single_class)\n",
    "        result += f1_single / float(classes_number)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_joint_model(df):\n",
    "    inputB = Input(shape=(df.shape[1],))\n",
    "    c = Dense(2, activation='relu')(inputB)\n",
    "    c = Dense(4, activation='relu')(c)\n",
    "    c = Dense(2, activation='softmax')(c)\n",
    "    full_model = Model(inputs=inputB, outputs=c)\n",
    "\n",
    "    full_model.compile(loss='binary_crossentropy', optimizer='adam', \n",
    "                          metrics=['acc',f1_m,precision_m, recall_m])\n",
    "    \n",
    "    return full_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_deception = np.array(y_train_deception)\n",
    "y_test_deception = np.array(y_test_deception)\n",
    "\n",
    "y_train_rapport = np.array(y_train_rapport)\n",
    "y_test_rapport = np.array(y_test_rapport)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joint full model with one hot encoding, predicting deception\n",
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 4)]               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 12        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 10        \n",
      "=================================================================\n",
      "Total params: 32\n",
      "Trainable params: 32\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/32\n",
      "143/143 [==============================] - 1s 5ms/step - loss: 0.6953 - acc: 0.9509 - f1_m: 0.9739 - precision_m: 0.9496 - recall_m: 1.0000 - val_loss: 0.6931 - val_acc: 0.9507 - val_f1_m: 0.9747 - val_precision_m: 0.9510 - val_recall_m: 1.0000\n",
      "Epoch 2/32\n",
      "143/143 [==============================] - 1s 4ms/step - loss: 0.6931 - acc: 0.4626 - f1_m: 0.9680 - precision_m: 0.9445 - recall_m: 0.9930 - val_loss: 0.6931 - val_acc: 0.9507 - val_f1_m: 0.9747 - val_precision_m: 0.9510 - val_recall_m: 1.0000\n"
     ]
    }
   ],
   "source": [
    "print('Joint full model with one hot encoding, predicting deception')\n",
    "joint_full_model = create_joint_model(pred_df_full)\n",
    "joint_full_model.summary()\n",
    "history = joint_full_model.fit(x=pred_df_full, y=y_train_deception, epochs=32, \n",
    "                    batch_size=64, \n",
    "                    validation_data=(pred_test_df_full,y_test_deception), callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pred = joint_full_model.predict(pred_df_full)\n",
    "full_pred = np.argmax(full_pred, axis=1)\n",
    "\n",
    "full_pred_test = joint_full_model.predict(pred_test_df_full)\n",
    "full_pred_test = np.argmax(full_pred_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lynne\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.47537379067722074, 0.5, 0.4873760144274121, None)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_recall_fscore_support(y_test_deception, full_pred_test, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joint full model with one hot encoding, predicting rapport\n",
      "Model: \"functional_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 3)]               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 2)                 8         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 4)                 12        \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 2)                 10        \n",
      "=================================================================\n",
      "Total params: 30\n",
      "Trainable params: 30\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/32\n",
      "143/143 [==============================] - 1s 5ms/step - loss: 0.7148 - acc: 0.8634 - f1_m: 0.9256 - precision_m: 0.8627 - recall_m: 1.0000 - val_loss: 0.6935 - val_acc: 0.8593 - val_f1_m: 0.9240 - val_precision_m: 0.8600 - val_recall_m: 1.0000\n",
      "Epoch 2/32\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6932 - acc: 0.8634 - f1_m: 0.9265 - precision_m: 0.8643 - recall_m: 1.0000 - val_loss: 0.6931 - val_acc: 0.8593 - val_f1_m: 0.9240 - val_precision_m: 0.8600 - val_recall_m: 1.0000\n",
      "Epoch 3/32\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6931 - acc: 0.6683 - f1_m: 0.8995 - precision_m: 0.8380 - recall_m: 0.9720 - val_loss: 0.6931 - val_acc: 0.1407 - val_f1_m: 0.9240 - val_precision_m: 0.8600 - val_recall_m: 1.0000\n"
     ]
    }
   ],
   "source": [
    "y_train_rapport = np.array(y_train_rapport)\n",
    "y_test_rapport = np.array(y_test_rapport)\n",
    "\n",
    "print('Joint full model with one hot encoding, predicting rapport')\n",
    "joint_full_model_rapport = create_joint_model(pred_df)\n",
    "joint_full_model_rapport.summary()\n",
    "history = joint_full_model_rapport.fit(x=pred_df, y=y_train_rapport, epochs=32, \n",
    "                    batch_size=64, \n",
    "                    validation_data=(pred_test_df,y_test_rapport), callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lynne\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.07036059806508356, 0.5, 0.12336160370084813, None)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_pred = joint_full_model_rapport.predict(pred_df)\n",
    "full_pred = np.argmax(full_pred, axis=1)\n",
    "\n",
    "full_pred_test = joint_full_model_rapport.predict(pred_test_df)\n",
    "full_pred_test = np.argmax(full_pred_test, axis=1)\n",
    "\n",
    "precision_recall_fscore_support(y_test_rapport, full_pred_test, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joint full model with one hot encoding, predicting deception, weighted by throughput\n",
      "Model: \"functional_43\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_22 (InputLayer)        [(None, 4)]               0         \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "dense_64 (Dense)             (None, 4)                 12        \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 2)                 10        \n",
      "=================================================================\n",
      "Total params: 32\n",
      "Trainable params: 32\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/32\n",
      "143/143 [==============================] - 1s 7ms/step - loss: 0.6984 - acc: 0.8351 - f1_m: 0.9756 - precision_m: 0.9527 - recall_m: 1.0000 - val_loss: 0.6936 - val_acc: 0.6746 - val_f1_m: 0.9713 - val_precision_m: 0.9446 - val_recall_m: 1.0000\n",
      "Epoch 2/32\n",
      "143/143 [==============================] - 1s 4ms/step - loss: 0.6935 - acc: 0.6154 - f1_m: 0.9756 - precision_m: 0.9527 - recall_m: 1.0000 - val_loss: 0.6935 - val_acc: 0.5770 - val_f1_m: 0.9713 - val_precision_m: 0.9446 - val_recall_m: 1.0000\n",
      "Epoch 3/32\n",
      "143/143 [==============================] - 1s 4ms/step - loss: 0.6934 - acc: 0.5859 - f1_m: 0.9756 - precision_m: 0.9527 - recall_m: 1.0000 - val_loss: 0.6934 - val_acc: 0.5774 - val_f1_m: 0.9713 - val_precision_m: 0.9446 - val_recall_m: 1.0000\n",
      "Epoch 4/32\n",
      "143/143 [==============================] - 1s 4ms/step - loss: 0.6934 - acc: 0.5868 - f1_m: 0.9746 - precision_m: 0.9510 - recall_m: 1.0000 - val_loss: 0.6934 - val_acc: 0.5814 - val_f1_m: 0.9713 - val_precision_m: 0.9446 - val_recall_m: 1.0000\n",
      "Epoch 5/32\n",
      "143/143 [==============================] - 1s 4ms/step - loss: 0.6934 - acc: 0.5893 - f1_m: 0.9756 - precision_m: 0.9527 - recall_m: 1.0000 - val_loss: 0.6933 - val_acc: 0.5945 - val_f1_m: 0.9713 - val_precision_m: 0.9446 - val_recall_m: 1.0000\n",
      "Epoch 6/32\n",
      "143/143 [==============================] - 1s 4ms/step - loss: 0.6933 - acc: 0.5936 - f1_m: 0.9755 - precision_m: 0.9527 - recall_m: 1.0000 - val_loss: 0.6933 - val_acc: 0.5910 - val_f1_m: 0.9713 - val_precision_m: 0.9446 - val_recall_m: 1.0000\n",
      "Epoch 7/32\n",
      "143/143 [==============================] - 1s 4ms/step - loss: 0.6933 - acc: 0.5968 - f1_m: 0.9756 - precision_m: 0.9527 - recall_m: 1.0000 - val_loss: 0.6933 - val_acc: 0.5976 - val_f1_m: 0.9713 - val_precision_m: 0.9446 - val_recall_m: 1.0000\n",
      "Epoch 8/32\n",
      "143/143 [==============================] - 1s 4ms/step - loss: 0.6933 - acc: 0.5972 - f1_m: 0.9746 - precision_m: 0.9510 - recall_m: 1.0000 - val_loss: 0.6932 - val_acc: 0.5915 - val_f1_m: 0.9713 - val_precision_m: 0.9446 - val_recall_m: 1.0000\n",
      "Epoch 9/32\n",
      "143/143 [==============================] - 1s 4ms/step - loss: 0.6932 - acc: 0.5983 - f1_m: 0.9756 - precision_m: 0.9527 - recall_m: 1.0000 - val_loss: 0.6932 - val_acc: 0.5989 - val_f1_m: 0.9713 - val_precision_m: 0.9446 - val_recall_m: 1.0000\n",
      "Epoch 10/32\n",
      "143/143 [==============================] - 1s 4ms/step - loss: 0.6932 - acc: 0.6034 - f1_m: 0.9756 - precision_m: 0.9527 - recall_m: 1.0000 - val_loss: 0.6932 - val_acc: 0.5967 - val_f1_m: 0.9713 - val_precision_m: 0.9446 - val_recall_m: 1.0000\n",
      "Epoch 11/32\n",
      "143/143 [==============================] - 1s 4ms/step - loss: 0.6932 - acc: 0.6031 - f1_m: 0.9756 - precision_m: 0.9527 - recall_m: 1.0000 - val_loss: 0.6932 - val_acc: 0.5985 - val_f1_m: 0.9713 - val_precision_m: 0.9446 - val_recall_m: 1.0000\n",
      "Epoch 12/32\n",
      "143/143 [==============================] - 1s 4ms/step - loss: 0.6932 - acc: 0.6033 - f1_m: 0.9746 - precision_m: 0.9510 - recall_m: 1.0000 - val_loss: 0.6932 - val_acc: 0.6020 - val_f1_m: 0.9713 - val_precision_m: 0.9446 - val_recall_m: 1.0000\n",
      "Epoch 13/32\n",
      "143/143 [==============================] - 1s 4ms/step - loss: 0.6932 - acc: 0.6028 - f1_m: 0.9756 - precision_m: 0.9527 - recall_m: 1.0000 - val_loss: 0.6932 - val_acc: 0.6099 - val_f1_m: 0.9713 - val_precision_m: 0.9446 - val_recall_m: 1.0000\n",
      "Epoch 14/32\n",
      "143/143 [==============================] - 1s 4ms/step - loss: 0.6932 - acc: 0.6060 - f1_m: 0.9755 - precision_m: 0.9527 - recall_m: 1.0000 - val_loss: 0.6932 - val_acc: 0.6121 - val_f1_m: 0.9713 - val_precision_m: 0.9446 - val_recall_m: 1.0000\n",
      "Epoch 15/32\n",
      "143/143 [==============================] - 1s 4ms/step - loss: 0.6932 - acc: 0.6113 - f1_m: 0.9756 - precision_m: 0.9527 - recall_m: 1.0000 - val_loss: 0.6932 - val_acc: 0.5976 - val_f1_m: 0.9713 - val_precision_m: 0.9446 - val_recall_m: 1.0000\n",
      "Epoch 16/32\n",
      "143/143 [==============================] - 1s 4ms/step - loss: 0.6932 - acc: 0.6077 - f1_m: 0.9756 - precision_m: 0.9527 - recall_m: 1.0000 - val_loss: 0.6932 - val_acc: 0.5994 - val_f1_m: 0.9713 - val_precision_m: 0.9446 - val_recall_m: 1.0000\n",
      "Epoch 17/32\n",
      "143/143 [==============================] - 1s 4ms/step - loss: 0.6932 - acc: 0.6120 - f1_m: 0.9756 - precision_m: 0.9527 - recall_m: 1.0000 - val_loss: 0.6932 - val_acc: 0.6020 - val_f1_m: 0.9713 - val_precision_m: 0.9446 - val_recall_m: 1.0000\n",
      "Epoch 18/32\n",
      "143/143 [==============================] - 1s 4ms/step - loss: 0.6932 - acc: 0.6089 - f1_m: 0.9746 - precision_m: 0.9510 - recall_m: 1.0000 - val_loss: 0.6932 - val_acc: 0.6055 - val_f1_m: 0.9713 - val_precision_m: 0.9446 - val_recall_m: 1.0000\n",
      "Epoch 19/32\n",
      "143/143 [==============================] - 1s 4ms/step - loss: 0.6932 - acc: 0.6132 - f1_m: 0.9756 - precision_m: 0.9527 - recall_m: 1.0000 - val_loss: 0.6932 - val_acc: 0.6099 - val_f1_m: 0.9713 - val_precision_m: 0.9446 - val_recall_m: 1.0000\n",
      "Epoch 20/32\n",
      "143/143 [==============================] - 1s 4ms/step - loss: 0.6932 - acc: 0.6125 - f1_m: 0.9756 - precision_m: 0.9527 - recall_m: 1.0000 - val_loss: 0.6932 - val_acc: 0.6069 - val_f1_m: 0.9713 - val_precision_m: 0.9446 - val_recall_m: 1.0000\n",
      "Epoch 21/32\n",
      "143/143 [==============================] - 1s 4ms/step - loss: 0.6932 - acc: 0.6137 - f1_m: 0.9756 - precision_m: 0.9527 - recall_m: 1.0000 - val_loss: 0.6932 - val_acc: 0.6069 - val_f1_m: 0.9713 - val_precision_m: 0.9446 - val_recall_m: 1.0000\n",
      "Epoch 22/32\n",
      "143/143 [==============================] - 1s 4ms/step - loss: 0.6932 - acc: 0.6150 - f1_m: 0.9755 - precision_m: 0.9527 - recall_m: 1.0000 - val_loss: 0.6932 - val_acc: 0.6179 - val_f1_m: 0.9713 - val_precision_m: 0.9446 - val_recall_m: 1.0000\n",
      "Epoch 23/32\n",
      "143/143 [==============================] - 1s 4ms/step - loss: 0.6932 - acc: 0.6152 - f1_m: 0.9755 - precision_m: 0.9527 - recall_m: 1.0000 - val_loss: 0.6932 - val_acc: 0.6104 - val_f1_m: 0.9713 - val_precision_m: 0.9446 - val_recall_m: 1.0000\n",
      "Epoch 24/32\n",
      "143/143 [==============================] - 1s 4ms/step - loss: 0.6932 - acc: 0.6134 - f1_m: 0.9756 - precision_m: 0.9527 - recall_m: 1.0000 - val_loss: 0.6932 - val_acc: 0.6086 - val_f1_m: 0.9713 - val_precision_m: 0.9446 - val_recall_m: 1.0000\n",
      "Epoch 25/32\n",
      "143/143 [==============================] - 1s 4ms/step - loss: 0.6932 - acc: 0.6128 - f1_m: 0.9755 - precision_m: 0.9527 - recall_m: 0.9999 - val_loss: 0.6932 - val_acc: 0.6038 - val_f1_m: 0.9713 - val_precision_m: 0.9446 - val_recall_m: 1.0000\n",
      "Epoch 26/32\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6932 - acc: 0.6147 - f1_m: 0.9756 - precision_m: 0.9527 - recall_m: 1.0000 - val_loss: 0.6931 - val_acc: 0.6064 - val_f1_m: 0.9713 - val_precision_m: 0.9446 - val_recall_m: 1.0000\n",
      "Epoch 27/32\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6931 - acc: 0.6138 - f1_m: 0.9756 - precision_m: 0.9527 - recall_m: 1.0000 - val_loss: 0.6931 - val_acc: 0.6249 - val_f1_m: 0.9713 - val_precision_m: 0.9446 - val_recall_m: 1.0000\n",
      "Epoch 28/32\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6931 - acc: 0.6174 - f1_m: 0.9747 - precision_m: 0.9510 - recall_m: 1.0000 - val_loss: 0.6931 - val_acc: 0.6179 - val_f1_m: 0.9713 - val_precision_m: 0.9446 - val_recall_m: 1.0000\n",
      "Epoch 29/32\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6931 - acc: 0.6122 - f1_m: 0.9756 - precision_m: 0.9527 - recall_m: 1.0000 - val_loss: 0.6931 - val_acc: 0.6223 - val_f1_m: 0.9713 - val_precision_m: 0.9446 - val_recall_m: 1.0000\n",
      "Epoch 30/32\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6931 - acc: 0.6169 - f1_m: 0.9756 - precision_m: 0.9527 - recall_m: 1.0000 - val_loss: 0.6931 - val_acc: 0.6214 - val_f1_m: 0.9713 - val_precision_m: 0.9446 - val_recall_m: 1.0000\n",
      "Epoch 31/32\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6931 - acc: 0.6154 - f1_m: 0.9756 - precision_m: 0.9527 - recall_m: 1.0000 - val_loss: 0.6931 - val_acc: 0.6161 - val_f1_m: 0.9713 - val_precision_m: 0.9446 - val_recall_m: 1.0000\n",
      "Epoch 32/32\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6931 - acc: 0.6134 - f1_m: 0.9756 - precision_m: 0.9527 - recall_m: 1.0000 - val_loss: 0.6931 - val_acc: 0.6121 - val_f1_m: 0.9713 - val_precision_m: 0.9446 - val_recall_m: 1.0000\n"
     ]
    }
   ],
   "source": [
    "print('Joint full model with one hot encoding, predicting deception, weighted by throughput')\n",
    "joint_full_model = create_joint_model(pred_df_full_throughput)\n",
    "joint_full_model.summary()\n",
    "history = joint_full_model.fit(x=pred_df_full_throughput, y=y_train_deception, epochs=32, \n",
    "                    batch_size=64, \n",
    "                    validation_data=(pred_df_full_throughput_test,y_test_deception), callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lynne\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4725153913808267, 0.5, 0.48586931946642553, None)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_pred = joint_full_model.predict(pred_df_full)\n",
    "full_pred = np.argmax(full_pred, axis=1)\n",
    "\n",
    "full_pred_test = joint_full_model.predict(pred_test_df_full)\n",
    "full_pred_test = np.argmax(full_pred_test, axis=1)\n",
    "\n",
    "precision_recall_fscore_support(y_test_deception, full_pred_test, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_rapport = np.array(y_train_rapport).astype(int)\n",
    "y_test_rapport = np.array(y_test_rapport).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joint full model with one hot encoding, predicting rapport, weighted by throughput\n",
      "Model: \"functional_51\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_26 (InputLayer)        [(None, 3)]               0         \n",
      "_________________________________________________________________\n",
      "dense_75 (Dense)             (None, 2)                 8         \n",
      "_________________________________________________________________\n",
      "dense_76 (Dense)             (None, 4)                 12        \n",
      "_________________________________________________________________\n",
      "dense_77 (Dense)             (None, 2)                 10        \n",
      "=================================================================\n",
      "Total params: 30\n",
      "Trainable params: 30\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/32\n",
      "143/143 [==============================] - 1s 5ms/step - loss: 0.7327 - acc: 0.1975 - f1_m: 0.9264 - precision_m: 0.8639 - recall_m: 1.0000 - val_loss: 0.6965 - val_acc: 0.3298 - val_f1_m: 0.9249 - val_precision_m: 0.8609 - val_recall_m: 1.0000\n",
      "Epoch 2/32\n",
      "143/143 [==============================] - 1s 4ms/step - loss: 0.6949 - acc: 0.4194 - f1_m: 0.9255 - precision_m: 0.8622 - recall_m: 1.0000 - val_loss: 0.6945 - val_acc: 0.4978 - val_f1_m: 0.9249 - val_precision_m: 0.8609 - val_recall_m: 1.0000\n",
      "Epoch 3/32\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6944 - acc: 0.4954 - f1_m: 0.9255 - precision_m: 0.8622 - recall_m: 1.0000 - val_loss: 0.6943 - val_acc: 0.5075 - val_f1_m: 0.9249 - val_precision_m: 0.8609 - val_recall_m: 1.0000\n",
      "Epoch 4/32\n",
      "143/143 [==============================] - 1s 4ms/step - loss: 0.6942 - acc: 0.4978 - f1_m: 0.9263 - precision_m: 0.8639 - recall_m: 1.0000 - val_loss: 0.6941 - val_acc: 0.5088 - val_f1_m: 0.9249 - val_precision_m: 0.8609 - val_recall_m: 1.0000\n",
      "Epoch 5/32\n",
      "143/143 [==============================] - 1s 4ms/step - loss: 0.6940 - acc: 0.5000 - f1_m: 0.9263 - precision_m: 0.8639 - recall_m: 1.0000 - val_loss: 0.6939 - val_acc: 0.5101 - val_f1_m: 0.9249 - val_precision_m: 0.8609 - val_recall_m: 1.0000\n",
      "Epoch 6/32\n",
      "143/143 [==============================] - 1s 4ms/step - loss: 0.6938 - acc: 0.4984 - f1_m: 0.9254 - precision_m: 0.8622 - recall_m: 1.0000 - val_loss: 0.6938 - val_acc: 0.5101 - val_f1_m: 0.9249 - val_precision_m: 0.8609 - val_recall_m: 1.0000\n",
      "Epoch 7/32\n",
      "143/143 [==============================] - 1s 4ms/step - loss: 0.6937 - acc: 0.4977 - f1_m: 0.9254 - precision_m: 0.8622 - recall_m: 1.0000 - val_loss: 0.6936 - val_acc: 0.5136 - val_f1_m: 0.9249 - val_precision_m: 0.8609 - val_recall_m: 1.0000\n",
      "Epoch 8/32\n",
      "143/143 [==============================] - 1s 4ms/step - loss: 0.6935 - acc: 0.4996 - f1_m: 0.9264 - precision_m: 0.8639 - recall_m: 1.0000 - val_loss: 0.6935 - val_acc: 0.5084 - val_f1_m: 0.9249 - val_precision_m: 0.8609 - val_recall_m: 1.0000\n",
      "Epoch 9/32\n",
      "143/143 [==============================] - 1s 4ms/step - loss: 0.6934 - acc: 0.4995 - f1_m: 0.9263 - precision_m: 0.8639 - recall_m: 1.0000 - val_loss: 0.6934 - val_acc: 0.4996 - val_f1_m: 0.9249 - val_precision_m: 0.8609 - val_recall_m: 1.0000\n",
      "Epoch 10/32\n",
      "143/143 [==============================] - 1s 4ms/step - loss: 0.6933 - acc: 0.4927 - f1_m: 0.9265 - precision_m: 0.8639 - recall_m: 1.0000 - val_loss: 0.6933 - val_acc: 0.5053 - val_f1_m: 0.9249 - val_precision_m: 0.8609 - val_recall_m: 1.0000\n",
      "Epoch 11/32\n",
      "143/143 [==============================] - 1s 4ms/step - loss: 0.6933 - acc: 0.4975 - f1_m: 0.9253 - precision_m: 0.8622 - recall_m: 1.0000 - val_loss: 0.6932 - val_acc: 0.4930 - val_f1_m: 0.9249 - val_precision_m: 0.8609 - val_recall_m: 1.0000\n",
      "Epoch 12/32\n",
      "143/143 [==============================] - 1s 4ms/step - loss: 0.6932 - acc: 0.4947 - f1_m: 0.9254 - precision_m: 0.8622 - recall_m: 1.0000 - val_loss: 0.6932 - val_acc: 0.5057 - val_f1_m: 0.9249 - val_precision_m: 0.8609 - val_recall_m: 1.0000\n",
      "Epoch 13/32\n",
      "143/143 [==============================] - 1s 4ms/step - loss: 0.6932 - acc: 0.4962 - f1_m: 0.9263 - precision_m: 0.8639 - recall_m: 1.0000 - val_loss: 0.6932 - val_acc: 0.5084 - val_f1_m: 0.9249 - val_precision_m: 0.8609 - val_recall_m: 1.0000\n",
      "Epoch 14/32\n",
      "143/143 [==============================] - 1s 4ms/step - loss: 0.6932 - acc: 0.4966 - f1_m: 0.9264 - precision_m: 0.8639 - recall_m: 1.0000 - val_loss: 0.6932 - val_acc: 0.5229 - val_f1_m: 0.9249 - val_precision_m: 0.8609 - val_recall_m: 1.0000\n",
      "Epoch 15/32\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6932 - acc: 0.4978 - f1_m: 0.9263 - precision_m: 0.8639 - recall_m: 1.0000 - val_loss: 0.6932 - val_acc: 0.5154 - val_f1_m: 0.9249 - val_precision_m: 0.8609 - val_recall_m: 1.0000\n",
      "Epoch 16/32\n",
      "143/143 [==============================] - 1s 4ms/step - loss: 0.6932 - acc: 0.4973 - f1_m: 0.9264 - precision_m: 0.8639 - recall_m: 1.0000 - val_loss: 0.6932 - val_acc: 0.5084 - val_f1_m: 0.9249 - val_precision_m: 0.8609 - val_recall_m: 1.0000\n",
      "Epoch 17/32\n",
      "143/143 [==============================] - 1s 4ms/step - loss: 0.6931 - acc: 0.4984 - f1_m: 0.9265 - precision_m: 0.8639 - recall_m: 1.0000 - val_loss: 0.6931 - val_acc: 0.5128 - val_f1_m: 0.9249 - val_precision_m: 0.8609 - val_recall_m: 1.0000\n",
      "Epoch 18/32\n",
      "143/143 [==============================] - 1s 4ms/step - loss: 0.6931 - acc: 0.4976 - f1_m: 0.9255 - precision_m: 0.8622 - recall_m: 1.0000 - val_loss: 0.6931 - val_acc: 0.5114 - val_f1_m: 0.9249 - val_precision_m: 0.8609 - val_recall_m: 1.0000\n",
      "Epoch 19/32\n",
      "143/143 [==============================] - 1s 4ms/step - loss: 0.6931 - acc: 0.4949 - f1_m: 0.9264 - precision_m: 0.8639 - recall_m: 1.0000 - val_loss: 0.6931 - val_acc: 0.5141 - val_f1_m: 0.9249 - val_precision_m: 0.8609 - val_recall_m: 1.0000\n",
      "Epoch 20/32\n",
      "143/143 [==============================] - 1s 4ms/step - loss: 0.6931 - acc: 0.4971 - f1_m: 0.9264 - precision_m: 0.8639 - recall_m: 1.0000 - val_loss: 0.6931 - val_acc: 0.5128 - val_f1_m: 0.9249 - val_precision_m: 0.8609 - val_recall_m: 1.0000\n",
      "Epoch 21/32\n",
      "143/143 [==============================] - 1s 4ms/step - loss: 0.6931 - acc: 0.4971 - f1_m: 0.9240 - precision_m: 0.8606 - recall_m: 0.9999 - val_loss: 0.6931 - val_acc: 0.5075 - val_f1_m: 0.9249 - val_precision_m: 0.8609 - val_recall_m: 1.0000\n",
      "Epoch 22/32\n",
      "143/143 [==============================] - 1s 4ms/step - loss: 0.6931 - acc: 0.4966 - f1_m: 0.9252 - precision_m: 0.8622 - recall_m: 0.9998 - val_loss: 0.6931 - val_acc: 0.5000 - val_f1_m: 0.9246 - val_precision_m: 0.8609 - val_recall_m: 0.9995\n"
     ]
    }
   ],
   "source": [
    "print('Joint full model with one hot encoding, predicting rapport, weighted by throughput')\n",
    "joint_full_model_rapport = create_joint_model(pred_df_throughput)\n",
    "joint_full_model_rapport.summary()\n",
    "history = joint_full_model_rapport.fit(x=pred_df_throughput, y=y_train_rapport, epochs=32, \n",
    "                    batch_size=64, \n",
    "                    validation_data=(pred_df_throughput_test,y_test_rapport), callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5586256881913154, 0.6194224279489533, 0.45684199911978396, None)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_pred_test = joint_full_model_rapport.predict(pred_df_throughput_test)\n",
    "full_pred_test = np.argmax(full_pred_test, axis=1)\n",
    "\n",
    "precision_recall_fscore_support(y_test_rapport, full_pred_test, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joint full model with one hot encoding, predicting deception, weighted by worktime\n",
      "Model: \"functional_23\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_12 (InputLayer)        [(None, 4)]               0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 4)                 12        \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 2)                 10        \n",
      "=================================================================\n",
      "Total params: 32\n",
      "Trainable params: 32\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/32\n",
      "143/143 [==============================] - 1s 5ms/step - loss: 0.6931 - acc: 0.6597 - f1_m: 0.9747 - precision_m: 0.9513 - recall_m: 0.9998 - val_loss: 0.6931 - val_acc: 0.0493 - val_f1_m: 0.9747 - val_precision_m: 0.9510 - val_recall_m: 1.0000\n",
      "Epoch 2/32\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6931 - acc: 0.5525 - f1_m: 0.9739 - precision_m: 0.9496 - recall_m: 1.0000 - val_loss: 0.6931 - val_acc: 0.9450 - val_f1_m: 0.9747 - val_precision_m: 0.9510 - val_recall_m: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.47523219814241485, 0.4969935245143386, 0.4858693194664255, None)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Joint full model with one hot encoding, predicting deception, weighted by worktime')\n",
    "joint_full_model = create_joint_model(pred_df_full_worktime)\n",
    "joint_full_model.summary()\n",
    "history = joint_full_model.fit(x=pred_df_full_worktime, y=y_train_deception, epochs=32, \n",
    "                    batch_size=64, \n",
    "                    validation_data=(pred_df_full_worktime_test,y_test_deception), callbacks=[callback])\n",
    "\n",
    "full_pred_test = joint_full_model.predict(pred_df_full_worktime_test)\n",
    "full_pred_test = np.argmax(full_pred_test, axis=1)\n",
    "\n",
    "precision_recall_fscore_support(y_test_deception, full_pred_test, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joint full model with one hot encoding, predicting rapport, weighted by worktime\n",
      "Model: \"functional_25\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_13 (InputLayer)        [(None, 3)]               0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 2)                 8         \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 4)                 12        \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 2)                 10        \n",
      "=================================================================\n",
      "Total params: 30\n",
      "Trainable params: 30\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/32\n",
      "143/143 [==============================] - 1s 5ms/step - loss: 0.6931 - acc: 0.4647 - f1_m: 0.9201 - precision_m: 0.8649 - recall_m: 0.9931 - val_loss: 0.6931 - val_acc: 0.1416 - val_f1_m: 0.9240 - val_precision_m: 0.8600 - val_recall_m: 1.0000\n",
      "Epoch 2/32\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6931 - acc: 0.4996 - f1_m: 0.9267 - precision_m: 0.8643 - recall_m: 1.0000 - val_loss: 0.6931 - val_acc: 0.1412 - val_f1_m: 0.0010 - val_precision_m: 0.0278 - val_recall_m: 5.2411e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5703915530136383, 0.5002558853633572, 0.12392068750906189, None)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Joint full model with one hot encoding, predicting rapport, weighted by worktime')\n",
    "joint_full_model = create_joint_model(pred_df_worktime)\n",
    "joint_full_model.summary()\n",
    "history = joint_full_model.fit(x=pred_df_worktime, y=y_train_rapport, epochs=32, \n",
    "                    batch_size=64, \n",
    "                    validation_data=(pred_df_worktime_test,y_test_rapport), callbacks=[callback])\n",
    "\n",
    "full_pred_test = joint_full_model.predict(pred_df_worktime_test)\n",
    "full_pred_test = np.argmax(full_pred_test, axis=1)\n",
    "\n",
    "precision_recall_fscore_support(y_test_rapport, full_pred_test, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joint full model with one hot encoding, predicting deception, weighted by agreement\n",
      "Model: \"functional_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         [(None, 4)]               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 4)                 12        \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 2)                 10        \n",
      "=================================================================\n",
      "Total params: 32\n",
      "Trainable params: 32\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/32\n",
      "143/143 [==============================] - 1s 5ms/step - loss: 0.6934 - acc: 0.2993 - f1_m: 0.9746 - precision_m: 0.9515 - recall_m: 0.9994 - val_loss: 0.6932 - val_acc: 0.1372 - val_f1_m: 0.9702 - val_precision_m: 0.9424 - val_recall_m: 1.0000\n",
      "Epoch 2/32\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6932 - acc: 0.1170 - f1_m: 0.9758 - precision_m: 0.9532 - recall_m: 1.0000 - val_loss: 0.6932 - val_acc: 0.0827 - val_f1_m: 0.9702 - val_precision_m: 0.9424 - val_recall_m: 1.0000\n",
      "Epoch 3/32\n",
      "143/143 [==============================] - 1s 4ms/step - loss: 0.6932 - acc: 0.0724 - f1_m: 0.9759 - precision_m: 0.9532 - recall_m: 1.0000 - val_loss: 0.6932 - val_acc: 0.0752 - val_f1_m: 0.9702 - val_precision_m: 0.9424 - val_recall_m: 1.0000\n",
      "Epoch 4/32\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6931 - acc: 0.0613 - f1_m: 0.9759 - precision_m: 0.9532 - recall_m: 1.0000 - val_loss: 0.6932 - val_acc: 0.0646 - val_f1_m: 0.9702 - val_precision_m: 0.9424 - val_recall_m: 1.0000\n",
      "Epoch 5/32\n",
      "143/143 [==============================] - 1s 4ms/step - loss: 0.6931 - acc: 0.0670 - f1_m: 0.9758 - precision_m: 0.9532 - recall_m: 1.0000 - val_loss: 0.6931 - val_acc: 0.0646 - val_f1_m: 0.9702 - val_precision_m: 0.9424 - val_recall_m: 1.0000\n",
      "Epoch 6/32\n",
      "143/143 [==============================] - 1s 4ms/step - loss: 0.6931 - acc: 0.1430 - f1_m: 0.9758 - precision_m: 0.9532 - recall_m: 1.0000 - val_loss: 0.6931 - val_acc: 0.0638 - val_f1_m: 0.9702 - val_precision_m: 0.9424 - val_recall_m: 1.0000\n",
      "Epoch 7/32\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6931 - acc: 0.0786 - f1_m: 0.9759 - precision_m: 0.9532 - recall_m: 1.0000 - val_loss: 0.6931 - val_acc: 0.9428 - val_f1_m: 0.9702 - val_precision_m: 0.9424 - val_recall_m: 1.0000\n",
      "Epoch 8/32\n",
      "143/143 [==============================] - 1s 4ms/step - loss: 0.6931 - acc: 0.3338 - f1_m: 0.9759 - precision_m: 0.9532 - recall_m: 1.0000 - val_loss: 0.6931 - val_acc: 0.0616 - val_f1_m: 0.9702 - val_precision_m: 0.9424 - val_recall_m: 1.0000\n",
      "Epoch 9/32\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6931 - acc: 0.2959 - f1_m: 0.9758 - precision_m: 0.9532 - recall_m: 1.0000 - val_loss: 0.6931 - val_acc: 0.0598 - val_f1_m: 0.9702 - val_precision_m: 0.9424 - val_recall_m: 1.0000\n",
      "Epoch 10/32\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6931 - acc: 0.2679 - f1_m: 0.9758 - precision_m: 0.9532 - recall_m: 1.0000 - val_loss: 0.6931 - val_acc: 0.0598 - val_f1_m: 0.9702 - val_precision_m: 0.9424 - val_recall_m: 1.0000\n",
      "Epoch 11/32\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6931 - acc: 0.3764 - f1_m: 0.9622 - precision_m: 0.9466 - recall_m: 0.9861 - val_loss: 0.6931 - val_acc: 0.9428 - val_f1_m: 0.9702 - val_precision_m: 0.9424 - val_recall_m: 1.0000\n",
      "Epoch 12/32\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6931 - acc: 0.2820 - f1_m: 0.9759 - precision_m: 0.9532 - recall_m: 1.0000 - val_loss: 0.6931 - val_acc: 0.0598 - val_f1_m: 0.9702 - val_precision_m: 0.9424 - val_recall_m: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.46596425419240955, 0.4977863088404133, 0.057092520992236134, None)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Joint full model with one hot encoding, predicting deception, weighted by agreement')\n",
    "joint_full_model = create_joint_model(pred_df_full_agreement)\n",
    "joint_full_model.summary()\n",
    "history = joint_full_model.fit(x=pred_df_full_agreement, y=y_train_deception, epochs=32, \n",
    "                    batch_size=64, \n",
    "                    validation_data=(pred_df_full_agreement_test,y_test_deception), callbacks=[callback])\n",
    "\n",
    "full_pred_test = joint_full_model.predict(pred_df_full_agreement_test)\n",
    "full_pred_test = np.argmax(full_pred_test, axis=1)\n",
    "\n",
    "precision_recall_fscore_support(y_test_deception, full_pred_test, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joint full model with one hot encoding, predicting rapport, weighted by agreement\n",
      "Model: \"functional_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         [(None, 3)]               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 2)                 8         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 4)                 12        \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 2)                 10        \n",
      "=================================================================\n",
      "Total params: 30\n",
      "Trainable params: 30\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/32\n",
      "143/143 [==============================] - 1s 5ms/step - loss: 0.6962 - acc: 0.6505 - f1_m: 0.9263 - precision_m: 0.8641 - recall_m: 0.9994 - val_loss: 0.6937 - val_acc: 0.7269 - val_f1_m: 0.9242 - val_precision_m: 0.8604 - val_recall_m: 1.0000\n",
      "Epoch 2/32\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6934 - acc: 0.6652 - f1_m: 0.9266 - precision_m: 0.8642 - recall_m: 1.0000 - val_loss: 0.6933 - val_acc: 0.6583 - val_f1_m: 0.9242 - val_precision_m: 0.8604 - val_recall_m: 1.0000\n",
      "Epoch 3/32\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6933 - acc: 0.6634 - f1_m: 0.9255 - precision_m: 0.8625 - recall_m: 1.0000 - val_loss: 0.6932 - val_acc: 0.6583 - val_f1_m: 0.9242 - val_precision_m: 0.8604 - val_recall_m: 1.0000\n",
      "Epoch 4/32\n",
      "143/143 [==============================] - 1s 4ms/step - loss: 0.6932 - acc: 0.6634 - f1_m: 0.9266 - precision_m: 0.8642 - recall_m: 1.0000 - val_loss: 0.6932 - val_acc: 0.6583 - val_f1_m: 0.9242 - val_precision_m: 0.8604 - val_recall_m: 1.0000\n",
      "Epoch 5/32\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6932 - acc: 0.6634 - f1_m: 0.9257 - precision_m: 0.8625 - recall_m: 1.0000 - val_loss: 0.6932 - val_acc: 0.6583 - val_f1_m: 0.9242 - val_precision_m: 0.8604 - val_recall_m: 1.0000\n",
      "Epoch 6/32\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6932 - acc: 0.6634 - f1_m: 0.9257 - precision_m: 0.8625 - recall_m: 1.0000 - val_loss: 0.6932 - val_acc: 0.6583 - val_f1_m: 0.9242 - val_precision_m: 0.8604 - val_recall_m: 1.0000\n",
      "Epoch 7/32\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6932 - acc: 0.6634 - f1_m: 0.9257 - precision_m: 0.8625 - recall_m: 1.0000 - val_loss: 0.6932 - val_acc: 0.6583 - val_f1_m: 0.9242 - val_precision_m: 0.8604 - val_recall_m: 1.0000\n",
      "Epoch 8/32\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6932 - acc: 0.6674 - f1_m: 0.9257 - precision_m: 0.8625 - recall_m: 1.0000 - val_loss: 0.6932 - val_acc: 0.6583 - val_f1_m: 0.9242 - val_precision_m: 0.8604 - val_recall_m: 1.0000\n",
      "Epoch 9/32\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6932 - acc: 0.6666 - f1_m: 0.9257 - precision_m: 0.8625 - recall_m: 1.0000 - val_loss: 0.6932 - val_acc: 0.6583 - val_f1_m: 0.9242 - val_precision_m: 0.8604 - val_recall_m: 1.0000\n",
      "Epoch 10/32\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6932 - acc: 0.6699 - f1_m: 0.9266 - precision_m: 0.8642 - recall_m: 1.0000 - val_loss: 0.6932 - val_acc: 0.6583 - val_f1_m: 0.9242 - val_precision_m: 0.8604 - val_recall_m: 1.0000\n",
      "Epoch 11/32\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6932 - acc: 0.6696 - f1_m: 0.9256 - precision_m: 0.8625 - recall_m: 1.0000 - val_loss: 0.6932 - val_acc: 0.6583 - val_f1_m: 0.9242 - val_precision_m: 0.8604 - val_recall_m: 1.0000\n",
      "Epoch 12/32\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6932 - acc: 0.6634 - f1_m: 0.9265 - precision_m: 0.8642 - recall_m: 1.0000 - val_loss: 0.6932 - val_acc: 0.6583 - val_f1_m: 0.9242 - val_precision_m: 0.8604 - val_recall_m: 1.0000\n",
      "Epoch 13/32\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6931 - acc: 0.6769 - f1_m: 0.9262 - precision_m: 0.8643 - recall_m: 0.9992 - val_loss: 0.6932 - val_acc: 0.6583 - val_f1_m: 0.9242 - val_precision_m: 0.8604 - val_recall_m: 1.0000\n",
      "Epoch 14/32\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6931 - acc: 0.6761 - f1_m: 0.9265 - precision_m: 0.8642 - recall_m: 1.0000 - val_loss: 0.6931 - val_acc: 0.6583 - val_f1_m: 0.9242 - val_precision_m: 0.8604 - val_recall_m: 1.0000\n",
      "Epoch 15/32\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6931 - acc: 0.6798 - f1_m: 0.9265 - precision_m: 0.8642 - recall_m: 1.0000 - val_loss: 0.6931 - val_acc: 0.6583 - val_f1_m: 0.9242 - val_precision_m: 0.8604 - val_recall_m: 1.0000\n",
      "Epoch 16/32\n",
      "143/143 [==============================] - 1s 4ms/step - loss: 0.6931 - acc: 0.6798 - f1_m: 0.9265 - precision_m: 0.8642 - recall_m: 1.0000 - val_loss: 0.6931 - val_acc: 0.6583 - val_f1_m: 0.9242 - val_precision_m: 0.8604 - val_recall_m: 1.0000\n",
      "Epoch 17/32\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6931 - acc: 0.6816 - f1_m: 0.9256 - precision_m: 0.8625 - recall_m: 1.0000 - val_loss: 0.6931 - val_acc: 0.6583 - val_f1_m: 0.9242 - val_precision_m: 0.8604 - val_recall_m: 1.0000\n",
      "Epoch 18/32\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6931 - acc: 0.6833 - f1_m: 0.9266 - precision_m: 0.8642 - recall_m: 1.0000 - val_loss: 0.6931 - val_acc: 0.7269 - val_f1_m: 0.9242 - val_precision_m: 0.8604 - val_recall_m: 1.0000\n",
      "Epoch 19/32\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6931 - acc: 0.6873 - f1_m: 0.9265 - precision_m: 0.8642 - recall_m: 1.0000 - val_loss: 0.6931 - val_acc: 0.6583 - val_f1_m: 0.9242 - val_precision_m: 0.8604 - val_recall_m: 1.0000\n",
      "Epoch 20/32\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6931 - acc: 0.6699 - f1_m: 0.9241 - precision_m: 0.8608 - recall_m: 0.9995 - val_loss: 0.6931 - val_acc: 0.6583 - val_f1_m: 0.9242 - val_precision_m: 0.8604 - val_recall_m: 1.0000\n",
      "Epoch 21/32\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6931 - acc: 0.6725 - f1_m: 0.9252 - precision_m: 0.8625 - recall_m: 0.9992 - val_loss: 0.6931 - val_acc: 0.6583 - val_f1_m: 0.9242 - val_precision_m: 0.8604 - val_recall_m: 1.0000\n",
      "Epoch 22/32\n",
      "143/143 [==============================] - 1s 4ms/step - loss: 0.6931 - acc: 0.6673 - f1_m: 0.9256 - precision_m: 0.8625 - recall_m: 1.0000 - val_loss: 0.6931 - val_acc: 0.7269 - val_f1_m: 0.9242 - val_precision_m: 0.8604 - val_recall_m: 1.0000\n",
      "Epoch 23/32\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6931 - acc: 0.6835 - f1_m: 0.9243 - precision_m: 0.8609 - recall_m: 1.0000 - val_loss: 0.6931 - val_acc: 0.8351 - val_f1_m: 0.9242 - val_precision_m: 0.8604 - val_recall_m: 1.0000\n",
      "Epoch 24/32\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6931 - acc: 0.7053 - f1_m: 0.9256 - precision_m: 0.8625 - recall_m: 1.0000 - val_loss: 0.6931 - val_acc: 0.8351 - val_f1_m: 0.9242 - val_precision_m: 0.8604 - val_recall_m: 1.0000\n",
      "Epoch 25/32\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.6931 - acc: 0.6554 - f1_m: 0.9257 - precision_m: 0.8641 - recall_m: 0.9987 - val_loss: 0.6931 - val_acc: 0.6583 - val_f1_m: 0.9242 - val_precision_m: 0.8604 - val_recall_m: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5745303425388171, 0.6451931788116637, 0.5546758334305778, None)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Joint full model with one hot encoding, predicting rapport, weighted by agreement')\n",
    "joint_full_model = create_joint_model(pred_df_agreement)\n",
    "joint_full_model.summary()\n",
    "history = joint_full_model.fit(x=pred_df_agreement, y=y_train_rapport, epochs=32, \n",
    "                    batch_size=64, \n",
    "                    validation_data=(pred_df_agreement_test,y_test_rapport), callbacks=[callback])\n",
    "\n",
    "full_pred_test = joint_full_model.predict(pred_df_agreement_test)\n",
    "full_pred_test = np.argmax(full_pred_test, axis=1)\n",
    "\n",
    "precision_recall_fscore_support(y_test_rapport, full_pred_test, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.94      0.97      2274\n",
      "\n",
      "    accuracy                           0.94      2274\n",
      "   macro avg       0.50      0.47      0.49      2274\n",
      "weighted avg       1.00      0.94      0.97      2274\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lynne\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\lynne\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4714160070360598, 0.5, 0.4852874603893164, None)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Joint full model with Random Forests, predicting deception\n",
    "clf_joint = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "clf_joint.fit(pred_df_full, y_train_deception)\n",
    "y_pred_deception = clf_joint.predict(pred_df_full)\n",
    "y_pred_test_deception = clf_joint.predict(pred_test_df_full)\n",
    "print(classification_report(y_pred_test_deception, y_test_deception))\n",
    "\n",
    "precision_recall_fscore_support(y_test_deception, y_pred_test_deception, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       1.00      0.86      0.93      2274\n",
      "\n",
      "    accuracy                           0.86      2274\n",
      "   macro avg       0.50      0.43      0.46      2274\n",
      "weighted avg       1.00      0.86      0.93      2274\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lynne\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\lynne\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4324978012313105, 0.5, 0.4638057062013676, None)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Joint full model with Random Forests, predicting rapport\n",
    "clf_joint = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "clf_joint.fit(pred_df, y_train_rapport)\n",
    "y_pred_repport = clf_joint.predict(pred_df)\n",
    "y_pred_test_rapport = clf_joint.predict(pred_test_df)\n",
    "print(classification_report(y_pred_test_rapport, y_test_rapport))\n",
    "\n",
    "precision_recall_fscore_support(y_test_rapport, y_pred_test_rapport, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.95      0.97      2274\n",
      "\n",
      "    accuracy                           0.95      2274\n",
      "   macro avg       0.50      0.47      0.49      2274\n",
      "weighted avg       1.00      0.95      0.97      2274\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lynne\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\lynne\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4725153913808267, 0.5, 0.48586931946642553, None)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Joint full model with Random Forests, predicting deception, weighted by throughput\n",
    "clf_joint = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "clf_joint.fit(pred_df_full_throughput, y_train_deception)\n",
    "y_pred_deception = clf_joint.predict(pred_df_full_throughput)\n",
    "y_pred_test_deception = clf_joint.predict(pred_df_full_throughput_test)\n",
    "print(classification_report(y_pred_test_deception, y_test_deception))\n",
    "\n",
    "precision_recall_fscore_support(y_test_deception, y_pred_test_deception, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.86      0.93      2274\n",
      "\n",
      "    accuracy                           0.86      2274\n",
      "   macro avg       0.50      0.43      0.46      2274\n",
      "weighted avg       1.00      0.86      0.93      2274\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lynne\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\lynne\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.43051890941073, 0.5, 0.4626654064272212, None)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Joint full model with Random Forests, predicting rapport, weighted by throughput\n",
    "clf_joint = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "clf_joint.fit(pred_df_throughput, y_train_rapport)\n",
    "y_pred_rapport = clf_joint.predict(pred_df_throughput)\n",
    "y_pred_test_rapport = clf_joint.predict(pred_df_throughput_test)\n",
    "print(classification_report(y_pred_test_rapport, y_test_rapport))\n",
    "\n",
    "precision_recall_fscore_support(y_test_rapport, y_pred_test_rapport, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.95      0.97      2274\n",
      "\n",
      "    accuracy                           0.95      2274\n",
      "   macro avg       0.50      0.48      0.49      2274\n",
      "weighted avg       1.00      0.95      0.97      2274\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lynne\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5, 0.47537379067722074, 0.4873760144274121, None)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Joint full model with Random Forests, predicting deception, weighted by worktime\n",
    "clf_joint = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "clf_joint.fit(pred_df_full_worktime, y_train_deception)\n",
    "y_pred_test = clf_joint.predict(pred_df_full_worktime_test)\n",
    "print(classification_report(y_pred_test, y_test_deception))\n",
    "\n",
    "precision_recall_fscore_support(y_pred_test, y_test_deception, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.01      0.33      0.01         6\n",
      "         1.0       1.00      0.86      0.92      2268\n",
      "\n",
      "    accuracy                           0.86      2274\n",
      "   macro avg       0.50      0.60      0.47      2274\n",
      "weighted avg       1.00      0.86      0.92      2274\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5021014585465712, 0.5965608465608465, 0.46800138334694397, None)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Joint full model with Random Forests, predicting rapport, weighted by worktime\n",
    "clf_joint = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "clf_joint.fit(pred_df_worktime, y_train_rapport)\n",
    "y_pred_test_rapport = clf_joint.predict(pred_df_worktime_test)\n",
    "print(classification_report(y_pred_test_rapport, y_test_rapport))\n",
    "\n",
    "precision_recall_fscore_support(y_pred_test_rapport, y_test_rapport, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.94      0.97      2274\n",
      "\n",
      "    accuracy                           0.94      2274\n",
      "   macro avg       0.50      0.47      0.49      2274\n",
      "weighted avg       1.00      0.94      0.97      2274\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lynne\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5, 0.4714160070360598, 0.4852874603893164, None)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Joint full model with Random Forests, predicting deception, weighted by agreement\n",
    "clf_joint = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "clf_joint.fit(pred_df_full_agreement, y_train_deception)\n",
    "y_pred_test = clf_joint.predict(pred_df_full_agreement_test)\n",
    "print(classification_report(y_pred_test, y_test_deception))\n",
    "\n",
    "precision_recall_fscore_support(y_pred_test, y_test_deception, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       1.00      0.86      0.92      2274\n",
      "\n",
      "    accuracy                           0.86      2274\n",
      "   macro avg       0.50      0.43      0.46      2274\n",
      "weighted avg       1.00      0.86      0.92      2274\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lynne\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5, 0.4298592788038698, 0.46228422794986995, None)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Joint full model with Random Forests, predicting rapport, weighted by agreement\n",
    "clf_joint = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "clf_joint.fit(pred_df_agreement, y_train_rapport)\n",
    "y_pred_test_rapport = clf_joint.predict(pred_df_agreement_test)\n",
    "print(classification_report(y_pred_test_rapport, y_test_rapport))\n",
    "\n",
    "precision_recall_fscore_support(y_pred_test_rapport, y_test_rapport, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfgpu",
   "language": "python",
   "name": "tfgpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
