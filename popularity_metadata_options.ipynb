{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def helloworld():\n",
    "    print('hello world')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################\n",
    "## Weighted Onehot Encoding options ##\n",
    "######################################\n",
    "\n",
    "##############\n",
    "# Throughput #\n",
    "##############\n",
    "# TP1: weighted by 1 average per set of OHE, i.e. (a, b, c, d) -> (w*a, w*b, w*c, w*d)\n",
    "# TP2: weighted by 1 linear variance per set of OHE, i.e. (a, b, c, d) -> (w*a, w*b, w*c, w*d)\n",
    "# TP3 + k: weighted by 1 inverted k-power U-shaped variance per set of OHE, i.e. (a, b, c, d) -> (w*a, w*b, w*c, w*d)\n",
    "# TP4 + k: weighted by 1 upright k-power U-shaped variance per set of OHE, i.e. (a, b, c, d) -> (w*a, w*b, w*c, w*d)\n",
    "# (For TP3 & TP4, k=1 results in V-shaped variance, and as k>1 increases, sides will curve into U-shaped variance)\n",
    "\n",
    "############\n",
    "# Worktime #\n",
    "############\n",
    "# WT1: weighted by 1 average per set of OHE, i.e. (a, b, c, d) -> (w*a, w*b, w*c, w*d)\n",
    "# WT2: weighted by 1 linear variance per set of OHE, i.e. (a, b, c, d) -> (w*a, w*b, w*c, w*d)\n",
    "\n",
    "################\n",
    "# PC agreement #\n",
    "################\n",
    "# PC1: weighted by 1 average per set of OHE, i.e. (a, b, c, d) -> (w*a, w*b, w*c, w*d)\n",
    "# PC2: weighted by 1 linear variance per set of OHE, i.e. (a, b, c, d) -> (w*a, w*b, w*c, w*d)\n",
    "# PC3: weighted by 1 PC agreement weight per annotation in each OHE, i.e. (a, b, c, d) -> (w1*a, w2*b, w3*c, w4*d)\n",
    "\n",
    "#####################\n",
    "# Input text length #\n",
    "#####################\n",
    "# TL1: weighted by 1 normalised number of characters per set of OHE, i.e. (a, b, c, d) -> (w*a, w*b, w*c, w*d)\n",
    "# TL2: weighted by 1 normalised number of words per set of OHE, i.e. (a, b, c, d) -> (w*a, w*b, w*c, w*d)\n",
    "\n",
    "###################\n",
    "# Special Options #\n",
    "###################\n",
    "# SP1: weighted by average of TP1 and TP2 per set of OHE, i.e. (a, b, c, d) -> (w*a, w*b, w*c, w*d)\n",
    "# SP2: weighted by average of WT1 and WT2 per set of OHE, i.e. (a, b, c, d) -> (w*a, w*b, w*c, w*d)\n",
    "# SP3: weighted by average of PC1 and PC2 per set of OHE, i.e. (a, b, c, d) -> (w*a, w*b, w*c, w*d)\n",
    "# RAND_UNI: weighted by 1 uniformly distributed random number between 0 to 1 per set of OHE, i.e. (a, b, c, d) -> (w*a, w*b, w*c, w*d)\n",
    "# RAND_NORM: weighted by 1 normally distributed random number between 0 to 1 per set of OHE, i.e. (a, b, c, d) -> (w*a, w*b, w*c, w*d)\n",
    "\n",
    "# Select 1 option from each of the few variants above, e.g. TP2, WT1, PC3, TL1, SP3, and input into function\n",
    "# set_OHE_pipeline_options. If not selecting TP3 or TP4, input k (option_k) will be ignored. After\n",
    "# editing the options, run the entire notebook for results accordingly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################\n",
    "## Weighted Onehot Encoding options ##\n",
    "######################################\n",
    "# During runtime: no need to edit anything in this cell\n",
    "\n",
    "def set_OHE_pipeline_options(dataframe, option_TP, option_WT, option_PC, option_TL, option_SP, option_k):\n",
    "    ##############\n",
    "    # Throughput #\n",
    "    ##############\n",
    "    df_throughput = dataframe[['Throughput.1_x', 'Throughput.2_x', 'Throughput.3_x', 'Throughput.4_x', 'Throughput.1_y', 'Throughput.2_y', 'Throughput.3_y', 'Throughput.4_y']].copy()\n",
    "    if option_TP == 'TP1':\n",
    "        print(\"TP1: weighted by 1 average per set of OHE, i.e. (a, b, c, d) -> (w*a, w*b, w*c, w*d)\")\n",
    "        df_throughput['avg_throughput'] = df_throughput.mean(axis=1)\n",
    "        df_throughput['avg_throughput'] = df_throughput['avg_throughput'] / df_throughput['avg_throughput'].max()\n",
    "    elif option_TP == 'TP2':\n",
    "        print(\"TP2: weighted by 1 linear variance per set of OHE, i.e. (a, b, c, d) -> (w*a, w*b, w*c, w*d)\")\n",
    "        df_throughput['var_throughput'] = df_throughput.var(axis=1)\n",
    "        print(\"Plot below: old throughput (x-axis) vs new throughput (y-axis)\")\n",
    "        plt.plot(df_throughput['var_throughput'], df_throughput['var_throughput'])\n",
    "        df_throughput['var_throughput'] = df_throughput['var_throughput'] / df_throughput['var_throughput'].max()\n",
    "    elif option_TP == 'TP3':\n",
    "        print(\"TP3 + k: weighted by 1 inverted k-power U-shaped variance per set of OHE, i.e. (a, b, c, d) -> (w*a, w*b, w*c, w*d)\")\n",
    "        df_throughput['var_throughput'] = df_throughput.var(axis=1)\n",
    "        max_val = df_throughput['var_throughput'].max()\n",
    "        min_val = df_throughput['var_throughput'].min()\n",
    "        tp_mid = ((max_val - min_val) // 2) + min_val\n",
    "        tp_to_list = df_throughput['var_throughput'].tolist()\n",
    "\n",
    "        amount_of_curve = option_k\n",
    "\n",
    "        u_shaped_variance = []\n",
    "        for each in tp_to_list:\n",
    "            if each > tp_mid:\n",
    "                u_shaped_variance.append((2*tp_mid - each)**(1/amount_of_curve))\n",
    "            else:\n",
    "                u_shaped_variance.append(each**(1/amount_of_curve))\n",
    "\n",
    "        df_throughput['var_throughput_u_shaped'] = u_shaped_variance\n",
    "        print(\"Plot below: old throughput (x-axis) vs new throughput (y-axis)\")\n",
    "        df_throughput.plot(x='var_throughput', y='var_throughput_u_shaped', style='o')\n",
    "        df_throughput['var_throughput_u_shaped'] = df_throughput['var_throughput_u_shaped'] / df_throughput['var_throughput_u_shaped'].max()\n",
    "        df_throughput = df_throughput.assign(var_throughput=df_throughput['var_throughput_u_shaped'])\n",
    "    elif option_TP == 'TP4':\n",
    "        print(\"TP4 + k: weighted by 1 upright k-power U-shaped variance per set of OHE, i.e. (a, b, c, d) -> (w*a, w*b, w*c, w*d)\")\n",
    "        df_throughput['var_throughput'] = df_throughput.var(axis=1)\n",
    "        max_val = df_throughput['var_throughput'].max()\n",
    "        min_val = df_throughput['var_throughput'].min()\n",
    "        tp_mid = ((max_val - min_val) // 2) + min_val\n",
    "        tp_to_list = df_throughput['var_throughput'].tolist()\n",
    "\n",
    "        amount_of_curve = option_k\n",
    "\n",
    "        u_shaped_variance = []\n",
    "        for each in tp_to_list:\n",
    "            if each > tp_mid:\n",
    "                u_shaped_variance.append((2*tp_mid - each)**(1/amount_of_curve))\n",
    "            else:\n",
    "                u_shaped_variance.append(each**(1/amount_of_curve))\n",
    "        list_min = min(u_shaped_variance)\n",
    "        list_max = max(u_shaped_variance)\n",
    "        u_shaped_variance = (np.asarray(u_shaped_variance) * -1) +  list_min + list_max\n",
    "\n",
    "        df_throughput['var_throughput_u_shaped'] = u_shaped_variance\n",
    "        print(\"Plot below: old throughput (x-axis) vs new throughput (y-axis)\")\n",
    "        df_throughput.plot(x='var_throughput', y='var_throughput_u_shaped', style='o')\n",
    "        df_throughput['var_throughput_u_shaped'] = df_throughput['var_throughput_u_shaped'] / df_throughput['var_throughput_u_shaped'].max()\n",
    "        df_throughput = df_throughput.assign(var_throughput=df_throughput['var_throughput_u_shaped'])\n",
    "    ############\n",
    "    # Worktime #\n",
    "    ############\n",
    "    df_worktime = dataframe[['WorkTime.1_x', 'WorkTime.2_x', 'WorkTime.3_x', 'WorkTime.4_x', 'WorkTime.1_y', 'WorkTime.2_y', 'WorkTime.3_y', 'WorkTime.4_y']].copy()\n",
    "    if option_WT == 'WT1':\n",
    "        print(\"WT1: weighted by 1 average per set of OHE, i.e. (a, b, c, d) -> (w*a, w*b, w*c, w*d)\")\n",
    "        df_worktime['avg_worktime'] = df_worktime.mean(axis=1)\n",
    "        df_worktime['avg_worktime'] = df_worktime['avg_worktime'] / df_worktime['avg_worktime'].max()\n",
    "    elif option_WT == 'WT2':\n",
    "        print(\"WT2: weighted by 1 linear variance per set of OHE, i.e. (a, b, c, d) -> (w*a, w*b, w*c, w*d)\")\n",
    "        df_worktime['var_worktime'] = df_worktime.var(axis=1)\n",
    "        df_worktime['var_worktime'] = df_worktime['var_worktime'] / df_worktime['var_worktime'].max()\n",
    "    ################\n",
    "    # PC agreement #\n",
    "    ################\n",
    "    df_agreement = dataframe[['emo_disc_pc_agree', 'info_disc_pc_agree', 'emo_supp_pc_agree', 'info_supp_pc_agree']].copy()\n",
    "    if option_PC == 'PC1':\n",
    "        print(\"PC1: weighted by 1 average per set of OHE, i.e. (a, b, c, d) -> (w*a, w*b, w*c, w*d)\")\n",
    "        df_agreement['avg_agreement'] = df_agreement.mean(axis=1)\n",
    "        df_agreement['avg_agreement'] = df_agreement['avg_agreement'] / df_agreement['avg_agreement'].max()\n",
    "    elif option_PC == 'PC2':\n",
    "        print(\"PC2: weighted by 1 linear variance per set of OHE, i.e. (a, b, c, d) -> (w*a, w*b, w*c, w*d)\")\n",
    "        df_agreement['var_agreement'] = df_agreement.var(axis=1)\n",
    "        df_agreement['var_agreement'] = df_agreement['var_agreement'] / df_agreement['var_agreement'].max()\n",
    "    elif option_PC == 'PC3':\n",
    "        print(\"PC3: weighted by 1 PC agreement weight per annotation in each OHE, i.e. (a, b, c, d) -> (w1*a, w2*b, w3*c, w4*d)\")\n",
    "        # Do nothing, df_agreement is ready as it is\n",
    "    #####################\n",
    "    # Input text length #\n",
    "    #####################\n",
    "    if option_TL == 'TL1':\n",
    "        print(\"TL1: weighted by 1 normalised number of characters per set of OHE, i.e. (a, b, c, d) -> (w*a, w*b, w*c, w*d)\")\n",
    "        df_textlength = dataframe[['num_chars']].copy()\n",
    "        df_textlength['num_chars'] = df_textlength['num_chars'] / df_textlength['num_chars'].max()\n",
    "    elif option_TL == 'TL2':\n",
    "        print(\"TL2: weighted by 1 normalised number of words per set of OHE, i.e. (a, b, c, d) -> (w*a, w*b, w*c, w*d)\")\n",
    "        df_textlength = dataframe[['num_words']].copy()\n",
    "        df_textlength['num_words'] = df_textlength['num_words'] / df_textlength['num_words'].max()\n",
    "    ###################\n",
    "    # Special Options #\n",
    "    ###################\n",
    "    if option_SP == 'SP1':\n",
    "        print(\"SP1: weighted by average of TP1 and TP2 per set of OHE, i.e. (a, b, c, d) -> (w*a, w*b, w*c, w*d)\")\n",
    "        df_special = dataframe[['Throughput.1_x', 'Throughput.2_x', 'Throughput.3_x', 'Throughput.4_x', 'Throughput.1_y', 'Throughput.2_y', 'Throughput.3_y', 'Throughput.4_y']].copy()\n",
    "        df_special['avg_throughput'] = df_special.mean(axis=1)\n",
    "        df_special['avg_throughput'] = df_special['avg_throughput'] / df_special['avg_throughput'].max()\n",
    "        df_special['var_throughput'] = df_special.var(axis=1)\n",
    "        df_special['var_throughput'] = df_special['var_throughput'] / df_special['var_throughput'].max()\n",
    "        df_special['average_avg_var'] = df_special[['avg_throughput', 'var_throughput']].mean(axis=1)\n",
    "    elif option_SP == 'SP2':\n",
    "        print(\"SP2: weighted by average of WT1 and WT2 per set of OHE, i.e. (a, b, c, d) -> (w*a, w*b, w*c, w*d)\")\n",
    "        df_special = dataframe[['WorkTime.1_x', 'WorkTime.2_x', 'WorkTime.3_x', 'WorkTime.4_x', 'WorkTime.1_y', 'WorkTime.2_y', 'WorkTime.3_y', 'WorkTime.4_y']].copy()\n",
    "        df_special['avg_worktime'] = df_special.mean(axis=1)\n",
    "        df_special['avg_worktime'] = df_special['avg_worktime'] / df_special['avg_worktime'].max()\n",
    "        df_special['var_worktime'] = df_special.var(axis=1)\n",
    "        df_special['var_worktime'] = df_special['var_worktime'] / df_special['var_worktime'].max()\n",
    "        df_special['average_avg_var'] = df_special[['avg_worktime', 'var_worktime']].mean(axis=1)\n",
    "    elif option_SP == 'SP3':\n",
    "        print(\"SP3: weighted by average of PC1 and PC2 per set of OHE, i.e. (a, b, c, d) -> (w*a, w*b, w*c, w*d)\")\n",
    "        df_special = dataframe[['emo_disc_pc_agree', 'info_disc_pc_agree', 'emo_supp_pc_agree', 'info_supp_pc_agree']].copy()\n",
    "        df_special['avg_agreement'] = df_special.mean(axis=1)\n",
    "        df_special['avg_agreement'] = df_special['avg_agreement'] / df_special['avg_agreement'].max()\n",
    "        df_special['var_agreement'] = df_special.var(axis=1)\n",
    "        df_special['var_agreement'] = df_special['var_agreement'] / df_special['var_agreement'].max()\n",
    "        df_special['average_avg_var'] = df_special[['avg_agreement', 'var_agreement']].mean(axis=1)\n",
    "    elif option_SP == 'RAND_UNI':\n",
    "        print(\"RAND_UNI: weighted by 1 uniformly distributed random number between 0 to 1 per set of OHE, i.e. (a, b, c, d) -> (w*a, w*b, w*c, w*d)\")\n",
    "        df_special = pd.DataFrame(np.random.uniform(low=0.0, high=1.0,size=(dataframe.shape[0], 1)), columns=['special_uni'])\n",
    "    elif option_SP == 'RAND_NORM':\n",
    "        print(\"# RAND_NORM: weighted by 1 normally distributed random number between 0 to 1 per set of OHE, i.e. (a, b, c, d) -> (w*a, w*b, w*c, w*d)\")\n",
    "        df_special = pd.DataFrame(np.random.normal(0.0, 1.0,size=(dataframe.shape[0], 1)), columns=['special_norm'])        \n",
    "    return df_throughput, df_worktime, df_agreement, df_textlength, df_special"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_weighted_dataframe(indices, df_throughput, df_worktime, \n",
    "                                 df_agreement, df_textlength, df_special,\n",
    "                                 pred_df):\n",
    "    \n",
    "    pred_df_throughput = pred_df.copy()\n",
    "    pred_df_worktime = pred_df.copy()\n",
    "\n",
    "    df_throughput_keys = df_throughput.keys().to_list()\n",
    "    throughput_values = df_throughput[df_throughput_keys[-1]].take(indices).values\n",
    "    pred_df_throughput = pred_df_throughput.mul(throughput_values, axis=0)\n",
    "\n",
    "    df_worktime_keys = df_worktime.keys().to_list()\n",
    "    worktime_values = df_worktime[df_worktime_keys[-1]].take(indices).values\n",
    "    pred_df_worktime = pred_df_worktime.mul(worktime_values, axis=0)\n",
    "    \n",
    "    df_agreement_keys = df_agreement.keys().to_list()\n",
    "    agreement_values = df_agreement[df_agreement_keys[-1]].take(indices).values\n",
    "#     agreement_values = df_agreement.take(indices)\n",
    "#     pred_df_agreement = np.multiply(pred_df_throughput, agreement_values)\n",
    "    pred_df_agreement = pred_df_throughput.mul(agreement_values, axis=0)\n",
    "\n",
    "    textlength_values = df_textlength.take(indices).values\n",
    "#     pred_df_full_textlength = pred_df_full_throughput.mul(textlength_values, axis=0)\n",
    "    pred_df_textlength = pred_df_throughput.mul(textlength_values, axis=0)\n",
    "\n",
    "    df_special_keys = df_special.keys().to_list()\n",
    "    special_values = df_special[df_special_keys[-1]].take(indices).values\n",
    "#     pred_df_full_special = pred_df_full_throughput.mul(special_values, axis=0)\n",
    "    pred_df_special = pred_df_throughput.mul(special_values, axis=0)\n",
    "    \n",
    "#     return pred_df_throughput, pred_df_worktime, pred_df_full_agreement, pred_df_agreement, pred_df_full_textlength, pred_df_textlength, pred_df_full_special, pred_df_special\n",
    "    return pred_df_throughput, pred_df_worktime, pred_df_agreement, pred_df_textlength, pred_df_special\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfgpu",
   "language": "python",
   "name": "tfgpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
