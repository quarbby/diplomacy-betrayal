{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from popularity_metadata_options.ipynb\n",
      "importing Jupyter notebook from models_nn.ipynb\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import LSTM, Input, InputLayer, Dropout, Dense, Flatten, Embedding, Add, Concatenate\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import tensorflow as tf\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "## Own code \n",
    "import import_ipynb\n",
    "import popularity_metadata_options\n",
    "import models_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data with Throughput & WorkTime\n",
    "df = pd.read_csv('./data/popularity/mean_merge.csv')\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>full_text_x</th>\n",
       "      <th>Emotional_disclosure</th>\n",
       "      <th>Information_disclosure</th>\n",
       "      <th>score_x</th>\n",
       "      <th>emo_disc.1</th>\n",
       "      <th>emo_disc.2</th>\n",
       "      <th>emo_disc.3</th>\n",
       "      <th>emo_disc.4</th>\n",
       "      <th>info_disc.1</th>\n",
       "      <th>...</th>\n",
       "      <th>WorkTime.2_y</th>\n",
       "      <th>WorkTime.3_y</th>\n",
       "      <th>WorkTime.4_y</th>\n",
       "      <th>popularity_y</th>\n",
       "      <th>num_words</th>\n",
       "      <th>num_chars</th>\n",
       "      <th>emo_disc_pc_agree</th>\n",
       "      <th>info_disc_pc_agree</th>\n",
       "      <th>emo_supp_pc_agree</th>\n",
       "      <th>info_supp_pc_agree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>''  Alot of people DONT think like that when t...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>57</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>'Official' would be one way to describe it.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>43</td>\n",
       "      <td>11</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>43</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>\"...you mix me a cocktail.\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>47</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"Be kind, for everyone you meet is fighting a ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>77</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>\"Consider yourself lucky because I chose you\"?</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>46</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                        full_text_x  \\\n",
       "0           0  ''  Alot of people DONT think like that when t...   \n",
       "1           1        'Official' would be one way to describe it.   \n",
       "2           2                        \"...you mix me a cocktail.\"   \n",
       "3           3  \"Be kind, for everyone you meet is fighting a ...   \n",
       "4           4     \"Consider yourself lucky because I chose you\"?   \n",
       "\n",
       "   Emotional_disclosure  Information_disclosure  score_x  emo_disc.1  \\\n",
       "0                     0                       0        2        True   \n",
       "1                     1                       0        2       False   \n",
       "2                     0                       0        2        True   \n",
       "3                     0                       0        3        True   \n",
       "4                     0                       0        1        True   \n",
       "\n",
       "   emo_disc.2  emo_disc.3  emo_disc.4  info_disc.1  ...  WorkTime.2_y  \\\n",
       "0        True        True       False        False  ...            11   \n",
       "1       False       False        True         True  ...            43   \n",
       "2        True        True       False        False  ...            47   \n",
       "3        True        True       False         True  ...            10   \n",
       "4        True        True        True         True  ...             9   \n",
       "\n",
       "   WorkTime.3_y  WorkTime.4_y  popularity_y  num_words  num_chars  \\\n",
       "0             7            19             0         12         57   \n",
       "1            11            41             0          8         43   \n",
       "2            10             4             0          5         27   \n",
       "3             7            13             0         14         77   \n",
       "4            66            23             0          7         46   \n",
       "\n",
       "   emo_disc_pc_agree  info_disc_pc_agree  emo_supp_pc_agree  \\\n",
       "0               0.75                0.50                1.0   \n",
       "1               0.75                0.75                1.0   \n",
       "2               0.75                0.50                1.0   \n",
       "3               0.75                1.00                1.0   \n",
       "4               1.00                1.00                1.0   \n",
       "\n",
       "   info_supp_pc_agree  \n",
       "0                0.75  \n",
       "1                1.00  \n",
       "2                0.75  \n",
       "3                1.00  \n",
       "4                1.00  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################\n",
    "# pipeline-onehot Function blocks #\n",
    "###################################\n",
    "\n",
    "def sss_train_test_split(dataframe, class_name, n_splits, test_size, random_state):\n",
    "    y = dataframe[class_name].copy()\n",
    "    X = dataframe.drop([class_name], axis=1)\n",
    "    sss = StratifiedShuffleSplit(n_splits=n_splits, test_size=test_size, random_state=random_state)\n",
    "    splits_generator = sss.split(X, y)\n",
    "\n",
    "    for train_idx, test_idx in splits_generator:\n",
    "        indices_train = train_idx\n",
    "        indices_test = test_idx\n",
    "\n",
    "    train = df.take(indices_train)\n",
    "    test = df.take(indices_test)\n",
    "    \n",
    "    return indices_train, indices_test, train, test\n",
    "\n",
    "def generate_class_weights(train_data, class_name, annotation_name):\n",
    "    y_train = train_data[annotation_name].to_numpy()\n",
    "    class_weights = class_weight.compute_class_weight('balanced', np.unique(y_train), y_train)\n",
    "    class_weight_dict = dict(enumerate(class_weights))\n",
    "    \n",
    "    return y_train, class_weight_dict\n",
    "\n",
    "def label_preprocessing(y_data, label_encoder):\n",
    "    out = label_encoder.fit_transform(y_data).reshape(-1,1)\n",
    "    return out\n",
    "\n",
    "def individual_model(annot_name, x_train_data, y_train_data, x_val_data, y_val_data, class_weight_dict, indiv_batch_size, indiv_epochs):\n",
    "    model = models_nn.create_nn_model()\n",
    "    model.compile(loss = 'binary_crossentropy',\n",
    "                  optimizer = RMSprop(),\n",
    "                  metrics = ['accuracy', models_nn.f1_m, models_nn.recall_m, models_nn.precision_m])\n",
    "    history = model.fit(x_train_data,y_train_data,\n",
    "                        batch_size=indiv_batch_size,\n",
    "                        epochs=indiv_epochs,\n",
    "                        validation_data=(x_val_data, y_val_data), \n",
    "#                         callbacks=[models_nn.early_stop],\n",
    "                        class_weight=class_weight_dict,\n",
    "                        verbose=0)\n",
    "    \n",
    "    pred = model.predict(x_train_data)\n",
    "    pred_test = model.predict(x_val_data)\n",
    "\n",
    "    pred_test_round = pred_test.round()\n",
    "    \n",
    "    validation_metrics_dict = history.history\n",
    "    val_f1_list = history.history['val_f1_m']\n",
    "    best_val_f1 = max(val_f1_list)\n",
    "    best_val_prec = history.history['val_precision_m'][val_f1_list.index(best_val_f1)]\n",
    "    best_val_recall = history.history['val_recall_m'][val_f1_list.index(best_val_f1)]\n",
    "    macro_scores = precision_recall_fscore_support(y_val_data, pred_test_round, average='macro')\n",
    "    print(\"#############################################################\")\n",
    "    print(\"Metrics for {} individual model:\".format(annot_name))\n",
    "    print(\"Best validation metrics: F1 = {}, Precision = {}, Recall = {}\".format(best_val_f1,\n",
    "                                                                                 best_val_prec,\n",
    "                                                                                 best_val_recall))\n",
    "    print(\"Macro validation metrics: F1 = {}, Precision = {}, Recall = {}\".format(macro_scores[2],\n",
    "                                                                                  macro_scores[0],\n",
    "                                                                                  macro_scores[1]))\n",
    "    return pred, pred_test\n",
    "\n",
    "# (HARD-CODED)\n",
    "def generate_encodings(info_support_pred, emo_support_pred, info_disclosure_pred, emo_disclosure_pred):\n",
    "    pred_df_arr_full = []\n",
    "\n",
    "    for i in range(0, len(info_support_pred)):\n",
    "        pred_obj_1 = {}\n",
    "        pred_obj_1['info_support'] = info_support_pred[i][0]\n",
    "        pred_obj_1['emo_support'] = emo_support_pred[i][0]\n",
    "        pred_obj_1['info_disclosure'] = info_disclosure_pred[i][0]\n",
    "        pred_obj_1['emo_disclosure'] = emo_disclosure_pred[i][0]\n",
    "        pred_df_arr_full.append(pred_obj_1)\n",
    "\n",
    "    pred_df_full = pd.DataFrame(pred_df_arr_full)\n",
    "    return pred_df_full\n",
    "\n",
    "def joint_model(weights_name, pred_df_full, y_train_1, pred_df_full_test, y_test_1,\n",
    "                class_weight_dict_1, joint_batch_size, joint_epochs):\n",
    "    \n",
    "    def helper(predict_name, pred_df, y_train, pred_df_test, y_test, class_weight_dict, joint_batch_size, \n",
    "               joint_epochs):\n",
    "        joint_full_model = models_nn.create_joint_model(pred_df)\n",
    "        history = joint_full_model.fit(x=pred_df, \n",
    "                                           y=y_train, \n",
    "                                           epochs=joint_epochs, \n",
    "                                           batch_size=joint_batch_size, \n",
    "                                           validation_data=(pred_df_test, y_test), \n",
    "#                                            callbacks=[models_nn.callback], \n",
    "                                           class_weight=class_weight_dict,\n",
    "                                           verbose=0)\n",
    "        joint_predict = joint_full_model.predict(pred_df_test)\n",
    "#         joint_predict_round = []\n",
    "#         for a in joint_predict:\n",
    "#             joint_predict_round.append(np.argmax(a))\n",
    "        joint_predict_round = joint_predict.round()\n",
    "        out1 = precision_recall_fscore_support(y_test, np.array(joint_predict_round), average='macro')\n",
    "\n",
    "        val_f1_list = history.history['val_f1_m']\n",
    "        best_val_f1 = val_f1_list[-1]\n",
    "        best_val_prec = history.history['val_precision_m'][val_f1_list.index(best_val_f1)]\n",
    "        best_val_recall = history.history['val_recall_m'][val_f1_list.index(best_val_f1)]\n",
    "        macro_scores = out1\n",
    "        if weights_name == None:\n",
    "            print(\"Metrics for {} joint model w/o weights:\".format(predict_name))\n",
    "        else:\n",
    "            print(\"Metrics for {} joint model weighted by {}\".format(predict_name, weights_name))\n",
    "        print(\"Best validation metrics: F1 = {}, Precision = {}, Recall = {}\".format(best_val_f1,\n",
    "                                                                                     best_val_prec,\n",
    "                                                                                     best_val_recall))\n",
    "        print(\"Macro validation metrics: F1 = {}, Precision = {}, Recall = {}\".format(macro_scores[2],\n",
    "                                                                                      macro_scores[0],\n",
    "                                                                                      macro_scores[1]))\n",
    "        return [best_val_f1, best_val_prec, best_val_recall], macro_scores\n",
    "    \n",
    "    print(\"#############################################################\")\n",
    "    decep_1, decep_2 = helper(\"Popularity\", pred_df_full, y_train_1, pred_df_full_test, y_test_1, class_weight_dict_1, joint_batch_size, joint_epochs)\n",
    "    \n",
    "    return decep_1, decep_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "# Main function for dataset sampling experiments #\n",
    "##################################################\n",
    "\n",
    "# Currently only supports annotations with 2 classes, i.e. binary\n",
    "\n",
    "def dataset_sampling(dataframe, class_name, sampling_size_list, metadata_options_list, model_name):\n",
    "    \n",
    "    # Misc variables\n",
    "    results = {}\n",
    "    \n",
    "    # Model settings (for individual annotation models)\n",
    "    models_nn.MODEL_NAME = model_name\n",
    "    \n",
    "    # Full dataframe proportions\n",
    "    full_size = dataframe.shape[0]\n",
    "    full_counts = dataframe[class_name].value_counts()\n",
    "    print(\"Full dataset proportions w.r.t. {}\".format(class_name))\n",
    "    print(full_counts)\n",
    "    full_counts_dict = full_counts.to_dict()\n",
    "    full_counts_list = list(full_counts_dict.values())\n",
    "    \n",
    "    ## class_proportions is a list of class proportions, first item corresponding to first class, etc\n",
    "    class_proportions = []\n",
    "    for each_class_counts in full_counts_list:\n",
    "        class_proportions.append(each_class_counts / full_size)\n",
    "\n",
    "    # Looping through sample_size_list\n",
    "    for each_sample_size in sampling_size_list:\n",
    "        \n",
    "        print(\"#################################\")\n",
    "        print(\"Sample size: {}\".format(each_sample_size))\n",
    "        print(\"#################################\")\n",
    "        \n",
    "        ## Counting number of datapoints per class proportionate to main dataset\n",
    "        class_sizes = [round(each_sample_size * class_proportions[0])]\n",
    "        class_sizes.append(each_sample_size - class_sizes[0])\n",
    "\n",
    "        ## Creating sub dataframe\n",
    "        s0 = dataframe.loc[dataframe[class_name] == list(full_counts_dict.keys())[0]].sample(class_sizes[0]).index\n",
    "        s1 = dataframe.loc[dataframe[class_name] == list(full_counts_dict.keys())[1]].sample(class_sizes[1]).index\n",
    "        sub_df = dataframe.loc[s0.union(s1)]\n",
    "\n",
    "        # Metadata settings\n",
    "        print(\"#############################################################\")\n",
    "        print(\"Metadata options for current sample\")\n",
    "        df_throughput, df_worktime, df_agreement, df_textlength, df_special = popularity_metadata_options.set_OHE_pipeline_options(sub_df, *metadata_options_list)\n",
    "  \n",
    "        ## Train_test_split using SSS\n",
    "        indices_train, indices_test, train, test = sss_train_test_split(sub_df, class_name, n_splits, test_size, random_state)\n",
    "        \n",
    "        ## Generate class weights dict and y_train data (HARD-CODED)\n",
    "        y_train_popularity, popularity_class_weight_dict = generate_class_weights(train, class_name, \"popularity_x\")\n",
    "        y_train_emo_disclosure, emo_disclosure_class_weight_dict = generate_class_weights(train, class_name, 'Emotional_disclosure')\n",
    "        y_train_info_disclosure, info_disclosure_class_weight_dict = generate_class_weights(train, class_name, 'Information_disclosure')\n",
    "        y_train_emo_support, emo_support_class_weight_dict = generate_class_weights(train, class_name, 'Emo_support')\n",
    "        y_train_info_support, info_support_class_weight_dict = generate_class_weights(train, class_name, 'Info_support')\n",
    "        print(\"#############################################################\")\n",
    "        print(\"Class weights generated\")\n",
    "        print(\"Popularity: {} \\nEmo Disclosure: {} \\nInfo Disclosure: {} \\nEmo Support: {} \\nInfo Support: {}\".format(popularity_class_weight_dict,\n",
    "                                                                                                          emo_disclosure_class_weight_dict,\n",
    "                                                                                                          info_disclosure_class_weight_dict,\n",
    "                                                                                                          emo_support_class_weight_dict,\n",
    "                                                                                                          info_support_class_weight_dict))\n",
    "        \n",
    "        ## Train and test data preparation (HARD-CODED)\n",
    "        X_train_col = train['full_text_x']\n",
    "        \n",
    "        y_test_popularity = test['popularity_x'].tolist()\n",
    "        y_test_emo_disclosure = test['Emotional_disclosure'].tolist()\n",
    "        y_test_info_disclosure = test['Information_disclosure'].tolist()\n",
    "        y_test_emo_support = test['Emo_support'].tolist()\n",
    "        y_test_info_support = test['Info_support'].tolist()\n",
    "\n",
    "        X_test_col = test['full_text_x']\n",
    "        \n",
    "        # Label encodings\n",
    "        le = LabelEncoder()\n",
    "\n",
    "        y_train_popularity = train['popularity_x'].tolist()\n",
    "        y_train_popularity = le.fit_transform(y_train_popularity)\n",
    "        y_train_popularity = y_train_popularity.reshape(-1,1)\n",
    "\n",
    "        y_train_emo_disclosure = train['Emotional_disclosure'].tolist()\n",
    "        y_train_emo_disclosure = le.fit_transform(y_train_emo_disclosure)\n",
    "        y_train_emo_disclosure = y_train_emo_disclosure.reshape(-1,1)\n",
    "\n",
    "        y_train_info_disclosure = train['Information_disclosure'].tolist()\n",
    "        y_train_info_disclosure = le.fit_transform(y_train_info_disclosure)\n",
    "        y_train_info_disclosure = y_train_info_disclosure.reshape(-1,1)\n",
    "\n",
    "        y_train_emo_support = train['Emo_support'].tolist()\n",
    "        y_train_emo_support = le.fit_transform(y_train_emo_support)\n",
    "        y_train_emo_support = y_train_emo_support.reshape(-1,1)\n",
    "\n",
    "        y_train_info_support = train['Info_support'].tolist()\n",
    "        y_train_info_support = le.fit_transform(y_train_info_support)\n",
    "        y_train_info_support = y_train_info_support.reshape(-1,1)\n",
    "        \n",
    "        ## Tokenizer settings\n",
    "        max_words = 1000\n",
    "        max_len = 220\n",
    "\n",
    "        tok = Tokenizer(num_words=max_words)\n",
    "\n",
    "        tok.fit_on_texts(X_train_col)\n",
    "        X_train_sequences = tok.texts_to_sequences(X_train_col)\n",
    "        X_train = pad_sequences(X_train_sequences, maxlen=max_len)\n",
    "\n",
    "        X_test_sequences = tok.texts_to_sequences(X_test_col)\n",
    "        X_test = pad_sequences(X_test_sequences, maxlen=max_len)\n",
    "        \n",
    "        ## Individual Models (HARD-CODED)\n",
    "        ### Deception pred and pred_test not needed\n",
    "        y_train_popularity = np.asarray(y_train_popularity)\n",
    "        y_test_popularity = np.asarray(y_test_popularity)\n",
    "        y_train_emo_disclosure = np.asarray(y_train_emo_disclosure)\n",
    "        y_test_emo_disclosure = np.asarray(y_test_emo_disclosure)\n",
    "        y_train_info_disclosure = np.asarray(y_train_info_disclosure)\n",
    "        y_test_info_disclosure = np.asarray(y_test_info_disclosure)\n",
    "        y_train_emo_support = np.asarray(y_train_emo_support)\n",
    "        y_test_emo_support = np.asarray(y_test_emo_support)\n",
    "        y_train_info_support = np.asarray(y_train_info_support)\n",
    "        y_test_info_support = np.asarray(y_test_info_support)\n",
    "        _, _ = individual_model('Popularity', X_train, y_train_popularity, X_test, y_test_popularity, popularity_class_weight_dict, indiv_batch_size, indiv_epochs)\n",
    "        emo_disclosure_pred, emo_disclosure_pred_test = individual_model('Emotional Disclosure', X_train, y_train_emo_disclosure, X_test, y_test_emo_disclosure, emo_disclosure_class_weight_dict, indiv_batch_size, indiv_epochs)\n",
    "        info_disclosure_pred, info_disclosure_pred_test = individual_model('Information Disclosure', X_train, y_train_info_disclosure, X_test, y_test_info_disclosure, info_disclosure_class_weight_dict, indiv_batch_size, indiv_epochs)\n",
    "        emo_support_pred, emo_support_pred_test = individual_model('Emotional Support', X_train, y_train_emo_support, X_test, y_test_emo_support, emo_support_class_weight_dict, indiv_batch_size, indiv_epochs)\n",
    "        info_support_pred, info_support_pred_test = individual_model('Information Support', X_train, y_train_info_support, X_test, y_test_info_support, info_support_class_weight_dict, indiv_batch_size, indiv_epochs)\n",
    "        \n",
    "        ## Generate one-hot encodings (HARD-CODED)\n",
    "        pred_df = generate_encodings(info_support_pred, emo_support_pred, info_disclosure_pred, emo_disclosure_pred)\n",
    "        pred_test_df = generate_encodings(info_support_pred_test, emo_support_pred_test, info_disclosure_pred_test, emo_disclosure_pred_test)\n",
    "        \n",
    "        # Generate weighted one-hot encodings (HARD-CODED)\n",
    "        pred_df_throughput, pred_df_worktime, pred_df_agreement, pred_df_textlength, pred_df_special = popularity_metadata_options.construct_weighted_dataframe(indices_train, df_throughput, df_worktime, df_agreement, df_textlength, df_special, pred_df)\n",
    "        pred_df_throughput_test, pred_df_worktime_test, pred_df_agreement_test, pred_df_textlength_test, pred_df_special_test = popularity_metadata_options.construct_weighted_dataframe(indices_test, df_throughput, df_worktime, df_agreement, df_textlength, df_special, pred_test_df)\n",
    "        print(\"#############################################################\")\n",
    "        print(\"Weighted one-hot encodings generated\")\n",
    "        \n",
    "        ## Joint model w/o weights\n",
    "        out1_wo_weights, _ = joint_model(None, pred_df, y_train_popularity, pred_test_df, y_test_popularity, \n",
    "                                                             popularity_class_weight_dict, joint_batch_size, joint_epochs)\n",
    "        # Joint model weighted by Throughput\n",
    "        out1_tp, _ = joint_model('Throughput', pred_df_throughput, y_train_popularity, pred_df_throughput_test, y_test_popularity,\n",
    "                                                       popularity_class_weight_dict, joint_batch_size, joint_epochs)\n",
    "        # Joint model weighted by Worktime\n",
    "        out1_wt, _ = joint_model('Worktime', pred_df_worktime, y_train_popularity, pred_df_worktime_test, y_test_popularity,\n",
    "                                                       popularity_class_weight_dict, joint_batch_size, joint_epochs)\n",
    "        # Joint model weighted by PC Agreement\n",
    "        out1_pc, _ = joint_model('PC Agreement', pred_df_agreement, y_train_popularity, pred_df_agreement_test, y_test_popularity,\n",
    "                                                       popularity_class_weight_dict, joint_batch_size, joint_epochs)\n",
    "        # Joint model weighted by Text Length\n",
    "        out1_tl, _ = joint_model('Text Length', pred_df_textlength, y_train_popularity, pred_df_textlength_test, y_test_popularity,\n",
    "                                                       popularity_class_weight_dict, joint_batch_size, joint_epochs)\n",
    "        \n",
    "        # Joint model weighted by Special options\n",
    "        out1_sp, _ = joint_model('Special', pred_df_special, y_train_popularity, pred_df_special_test, y_test_popularity,\n",
    "                                                       popularity_class_weight_dict, joint_batch_size, joint_epochs)\n",
    "        \n",
    "        results['run_' + str(each_sample_size)] = [out1_wo_weights, out1_tp, out1_wt, \n",
    "                                                   out1_pc, out1_tl, out1_sp]\n",
    "#         results['run_' + str(each_sample_size)] = [out1_wo_weights]\n",
    "    print(\"Done\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "# Arguments for current experiment #\n",
    "####################################\n",
    "\n",
    "# Metadata options\n",
    "throughput_option = 'TP2'\n",
    "worktime_option = 'WT1'\n",
    "pc_agreement_option = 'PC1'\n",
    "textlength_option = 'TL2'\n",
    "special_option = 'SP1'\n",
    "k_option_for_tp = 3\n",
    "metadata_options_choices = [throughput_option, worktime_option, pc_agreement_option, textlength_option, special_option, k_option_for_tp]\n",
    "\n",
    "# Train_test_split SSS options\n",
    "n_splits = 1\n",
    "test_size = 0.2\n",
    "random_state = 0\n",
    "\n",
    "# Individual model options\n",
    "model_name = 'cnn'\n",
    "models_nn.MODEL_NAME = model_name\n",
    "indiv_batch_size = 128\n",
    "indiv_epochs = 15\n",
    "\n",
    "# Joint model options\n",
    "joint_batch_size = 64\n",
    "joint_epochs = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full dataset proportions w.r.t. popularity_x\n",
      "0    14254\n",
      "1     3219\n",
      "Name: popularity_x, dtype: int64\n",
      "#################################\n",
      "Sample size: 17473\n",
      "#################################\n",
      "#############################################################\n",
      "Metadata options for current sample\n",
      "TP2: weighted by 1 linear variance per set of OHE, i.e. (a, b, c, d) -> (w*a, w*b, w*c, w*d)\n",
      "Plot below: old throughput (x-axis) vs new throughput (y-axis)\n",
      "WT1: weighted by 1 average per set of OHE, i.e. (a, b, c, d) -> (w*a, w*b, w*c, w*d)\n",
      "PC1: weighted by 1 average per set of OHE, i.e. (a, b, c, d) -> (w*a, w*b, w*c, w*d)\n",
      "TL2: weighted by 1 normalised number of words per set of OHE, i.e. (a, b, c, d) -> (w*a, w*b, w*c, w*d)\n",
      "SP1: weighted by average of TP1 and TP2 per set of OHE, i.e. (a, b, c, d) -> (w*a, w*b, w*c, w*d)\n",
      "#############################################################\n",
      "Class weights generated\n",
      "Popularity: {0: 0.6129088836271157, 1: 2.7141747572815533} \n",
      "Emo Disclosure: {0: 0.7872268528947961, 1: 1.370392156862745} \n",
      "Info Disclosure: {0: 0.9004122648801856, 1: 1.1243564993564994} \n",
      "Emo Support: {0: 0.562902706185567, 1: 4.474391805377721} \n",
      "Info Support: {0: 0.5711367165154858, 1: 4.01435956346927}\n",
      "#############################################################\n",
      "Metrics for Popularity individual model:\n",
      "Best validation metrics: F1 = 0.3158033490180969, Precision = 0.20009753108024597, Recall = 0.7741087079048157\n",
      "Macro validation metrics: F1 = 0.48426694342772403, Precision = 0.5122120142253376, Recall = 0.5196152706580017\n",
      "#############################################################\n",
      "Metrics for Emotional Disclosure individual model:\n",
      "Best validation metrics: F1 = 0.6061888933181763, Precision = 0.5286330580711365, Recall = 0.716067910194397\n",
      "Macro validation metrics: F1 = 0.6380619570688522, Precision = 0.6394818901415207, Recall = 0.6369611437883533\n",
      "#############################################################\n",
      "Metrics for Information Disclosure individual model:\n",
      "Best validation metrics: F1 = 0.6569510102272034, Precision = 0.6428426504135132, Recall = 0.6739707589149475\n",
      "Macro validation metrics: F1 = 0.6176606592233075, Precision = 0.6337929781581715, Recall = 0.6312231273855835\n",
      "#############################################################\n",
      "Metrics for Emotional Support individual model:\n",
      "Best validation metrics: F1 = 0.5682273507118225, Precision = 0.5208226442337036, Recall = 0.6526191830635071\n",
      "Macro validation metrics: F1 = 0.6665158609066176, Precision = 0.6470805797969099, Recall = 0.7876849988659997\n",
      "#############################################################\n",
      "Metrics for Information Support individual model:\n",
      "Best validation metrics: F1 = 0.4565313458442688, Precision = 0.4434874951839447, Recall = 0.4932609498500824\n",
      "Macro validation metrics: F1 = 0.5773533590542961, Precision = 0.6040019302731168, Recall = 0.7271481676523406\n",
      "#############################################################\n",
      "Weighted one-hot encodings generated\n",
      "#############################################################\n",
      "Metrics for Popularity joint model w/o weights:\n",
      "Best validation metrics: F1 = 0.2520492970943451, Precision = 0.1807313859462738, Recall = 0.44002795219421387\n",
      "Macro validation metrics: F1 = 0.45594562956433016, Precision = 0.49761129655947384, Recall = 0.4960635474966831\n",
      "#############################################################\n",
      "Metrics for Popularity joint model weighted by Throughput\n",
      "Best validation metrics: F1 = 0.2930608093738556, Precision = 0.1903543323278427, Recall = 0.6688171625137329\n",
      "Macro validation metrics: F1 = 0.39453871346225255, Precision = 0.5078984749641086, Recall = 0.5119079390254264\n",
      "#############################################################\n",
      "Metrics for Popularity joint model weighted by Worktime\n",
      "Best validation metrics: F1 = 0.2874719798564911, Precision = 0.18863096833229065, Recall = 0.642974853515625\n",
      "Macro validation metrics: F1 = 0.39713040942534333, Precision = 0.502708603875436, Recall = 0.5041714686576139\n",
      "#############################################################\n",
      "Metrics for Popularity joint model weighted by PC Agreement\n",
      "Best validation metrics: F1 = 0.2778396010398865, Precision = 0.19154830276966095, Recall = 0.5355862975120544\n",
      "Macro validation metrics: F1 = 0.4455111033535918, Precision = 0.5062638835783052, Recall = 0.5104036177782232\n",
      "#############################################################\n",
      "Metrics for Popularity joint model weighted by Text Length\n",
      "Best validation metrics: F1 = 0.287088006734848, Precision = 0.18643195927143097, Recall = 0.6622226238250732\n",
      "Macro validation metrics: F1 = 0.38912484924754864, Precision = 0.5031899472721013, Recall = 0.5047942750827322\n",
      "#############################################################\n",
      "Metrics for Popularity joint model weighted by Special\n",
      "Best validation metrics: F1 = 0.29687026143074036, Precision = 0.18458400666713715, Recall = 0.8096051812171936\n",
      "Macro validation metrics: F1 = 0.30690509986919046, Precision = 0.4978158163201831, Recall = 0.49770512035659276\n",
      "Done\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sampling_sizes = [17473]\n",
    "\n",
    "results_dict = dataset_sampling(dataframe=df, \n",
    "                                class_name=\"popularity_x\", \n",
    "                                sampling_size_list=sampling_sizes, \n",
    "                                metadata_options_list=metadata_options_choices, \n",
    "                                model_name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def translate_into_pandas(results_dictionary, metric_of_focus):\n",
    "#     def helper(metric_of_focus_number):\n",
    "#         new_dict = {}\n",
    "#         for each_key, each_values_list in results_dictionary.items():\n",
    "#             new_dict[each_key[4:]] = []\n",
    "#             for each in each_values_list:\n",
    "#                 new_dict[each_key[4:]].append(each[metric_of_focus_number])\n",
    "#         out_df = pd.DataFrame.from_dict(new_dict)\n",
    "#         return out_df\n",
    "    \n",
    "#     if metric_of_focus == 'F1':\n",
    "#         metric_of_focus_number = 0\n",
    "#     elif metric_of_focus == 'Precision':\n",
    "#         metric_of_focus_number = 1\n",
    "#     elif metric_of_focus == 'Recall':\n",
    "#         metric_of_focus_number = 2\n",
    "        \n",
    "#     return helper(metric_of_focus_number)\n",
    "\n",
    "# experiment_df = translate_into_pandas(results_dict, 'Precision')\n",
    "# results_name = \"./output/dataset_sampling_\" + str(len(sampling_sizes)) + \"pts\"\n",
    "# experiment_df.to_csv(results_name + \".csv\", index=False)\n",
    "# experiment_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp_plot_df = experiment_df.T.reset_index()\n",
    "# rename_col_names = {0: 'Deception w/o weights',\n",
    "#                     1: 'Rapport w/o weights',\n",
    "#                     2: 'Deception by TP',\n",
    "#                     3: 'Rapport by TP',\n",
    "#                     4: 'Deception by WT',\n",
    "#                     5: 'Rapport by WT',\n",
    "#                     6: 'Deception by PC',\n",
    "#                     7: 'Rapport by PC',\n",
    "#                     8: 'Deception by TL',\n",
    "#                     9: 'Rapport by TL',\n",
    "#                     10: 'Deception by SP',\n",
    "#                     11: 'Rapport by SP'}\n",
    "# exp_plot_df = exp_plot_df.rename(columns=rename_col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot = exp_plot_df.plot('index',list(exp_plot_df.columns)[1:],style='.-', figsize=(12,9))\n",
    "# plot.set_xlabel('Sample size', size=10)\n",
    "# plot.set_ylabel('F1 Scores', size=10)\n",
    "# lgd = plot.legend(loc='center left',bbox_to_anchor=(1.0, 0.5), borderaxespad=0.)\n",
    "# plot = plot.get_figure()\n",
    "# plot.savefig(results_name + '.jpg', bbox_extra_artists=(lgd,), bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
