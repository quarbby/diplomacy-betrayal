{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Input, InputLayer, Dropout, Dense, Flatten, Embedding\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.initializers import TruncatedNormal\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import CategoricalAccuracy\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.read_csv('politeness_strategies_merge.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(full_df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = full_df['Input.full_text'].to_list()\n",
    "y = full_df['affcon_rapport'].tolist()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForPreTraining.\n",
      "\n",
      "All the layers of TFBertForPreTraining were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForPreTraining for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "max_length = 100\n",
    "\n",
    "from transformers import AutoTokenizer, TFAutoModel, AutoConfig, TFAutoModelForPreTraining \n",
    "\n",
    "model_name = 'bert-base-uncased'\n",
    "config = AutoConfig.from_pretrained(model_name)\n",
    "#\"microsoft/deberta-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "auto_model = TFAutoModelForPreTraining.from_pretrained(model_name, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_class = to_categorical(train['affcon_rapport'].to_list())\n",
    "X_train_text = tokenizer(\n",
    "    text=train['Input.full_text'].to_list(),\n",
    "    add_special_tokens=True,\n",
    "    max_length=max_length,\n",
    "    truncation=True,\n",
    "    padding=True, \n",
    "    return_tensors='tf',\n",
    "    return_token_type_ids = False,\n",
    "    return_attention_mask = False,\n",
    "    verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_class = to_categorical(test['affcon_rapport'].to_list())\n",
    "X_test_text = tokenizer(\n",
    "    text=test['Input.full_text'].to_list(),\n",
    "    add_special_tokens=True,\n",
    "    max_length=max_length,\n",
    "    truncation=True,\n",
    "    padding=True, \n",
    "    return_tensors='tf',\n",
    "    return_token_type_ids = False,\n",
    "    return_attention_mask = False,\n",
    "    verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', min_delta=0, patience=0, verbose=0, mode='auto',\n",
    "    baseline=None, restore_best_weights=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM\n",
    "\n",
    "input_ids_in = tf.keras.layers.Input(shape=(100,), name='input_token', dtype='int32')\n",
    "input_masks_in = tf.keras.layers.Input(shape=(100,), name='masked_token', dtype='int32') \n",
    "\n",
    "embedding_layer = auto_model(input_ids_in)[0]\n",
    "#cls_token = embedding_layer[:,0,:]\n",
    "X = tf.keras.layers.BatchNormalization()(embedding_layer)\n",
    "X = tf.keras.layers.LSTM(64, return_sequences=True)(X)\n",
    "X = tf.keras.layers.LSTM(32, return_sequences=True)(X)\n",
    "X = tf.keras.layers.LSTM(16, return_sequences=True)(X)\n",
    "X = tf.keras.layers.LSTM(16)(X)\n",
    "X = tf.keras.layers.Dense(24, activation='relu')(X)\n",
    "X = tf.keras.layers.Dropout(0.2)(X)\n",
    "X = tf.keras.layers.Dense(24, activation='relu')(X)\n",
    "X = tf.keras.layers.Dense(2, activation='sigmoid')(X)\n",
    "text_model = tf.keras.Model(inputs=input_ids_in, outputs = X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical model\n",
    "numerical_train_x = train.drop(columns=['affcon_rapport', 'Input.full_text', 'Unnamed: 0',\n",
    "                                    'msg_id', 'Input.convo_id', 'Input.train_test_val',\n",
    "                                     'Input.msg_id', 'Input.timestamp', 'Input.full_text',\n",
    "                                     'affcon_gamemove', 'affcon_reasoning', 'affcon_rapport',\n",
    "                                     'affcon_shareinformation', 'Input.speaker', 'Input.reply_to',\n",
    "                                     'Input.speaker_intention', 'Input.reciever_perception',\n",
    "                                     'Input.reciever', 'Input.absolute_message_index', \n",
    "                                     'Input.relative_message_index', 'Input.year', 'Input.game_score_speaker',\n",
    "                                     'Input.game_score_receiver', 'Input.game_score_delta',\n",
    "                                     'Input.deception_quadrant', 'Input.num_words', \n",
    "                                     'Input.num_characters', 'Input.sno', 'Input.sno1'\n",
    "                                    ])\n",
    "numerical_train_y = to_categorical(train['affcon_rapport'].to_list())\n",
    "\n",
    "numerical_test_x = test.drop(columns=['affcon_rapport', 'Input.full_text', 'Unnamed: 0',\n",
    "                                    'msg_id', 'Input.convo_id', 'Input.train_test_val',\n",
    "                                     'Input.msg_id', 'Input.timestamp', 'Input.full_text',\n",
    "                                     'affcon_gamemove', 'affcon_reasoning', 'affcon_rapport',\n",
    "                                     'affcon_shareinformation', 'Input.speaker', 'Input.reply_to',\n",
    "                                     'Input.speaker_intention', 'Input.reciever_perception',\n",
    "                                     'Input.reciever', 'Input.absolute_message_index', \n",
    "                                     'Input.relative_message_index', 'Input.year', 'Input.game_score_speaker',\n",
    "                                     'Input.game_score_receiver', 'Input.game_score_delta',\n",
    "                                     'Input.deception_quadrant', 'Input.num_words', \n",
    "                                     'Input.num_characters', 'Input.sno', 'Input.sno1'\n",
    "                                    ])\n",
    "numerical_test_y = to_categorical(test['affcon_rapport'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputB = Input(shape=(numerical_df.shape[1],))\n",
    "c = Dense(len(full_df['affcon_rapport'].value_counts()), activation='relu')(inputB)\n",
    "c = Dense(4, activation='relu')(c)\n",
    "c = Dense(len(full_df['affcon_rapport'].value_counts()), activation='linear')(c)\n",
    "numeric_model = Model(inputs=inputB, outputs=c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "138/138 [==============================] - 1s 6ms/step - loss: 1.1921e-07 - acc: 0.3928 - f1_m: 1.3333 - precision_m: 1.0000 - recall_m: 2.0000 - val_loss: 1.1921e-07 - val_acc: 0.4061 - val_f1_m: 1.3333 - val_precision_m: 1.0000 - val_recall_m: 2.0000\n",
      "Epoch 2/32\n",
      "138/138 [==============================] - 1s 4ms/step - loss: 1.1921e-07 - acc: 0.3928 - f1_m: 1.3333 - precision_m: 1.0000 - recall_m: 2.0000 - val_loss: 1.1921e-07 - val_acc: 0.4061 - val_f1_m: 1.3333 - val_precision_m: 1.0000 - val_recall_m: 2.0000\n"
     ]
    }
   ],
   "source": [
    "numeric_model.compile(loss='categorical_crossentropy', optimizer=optimizer, \n",
    "                      metrics=['acc',f1_m,precision_m, recall_m])\n",
    "history = numeric_model.fit(x=numerical_train_x, y=numerical_train_y, epochs=32, \n",
    "                    batch_size=64, \n",
    "                    validation_split=0.3, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = concatenate([text_model.output, numeric_model.output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = Dense(len(full_df['affcon_rapport'].value_counts()), activation=\"relu\")(combined)\n",
    "z = Dense(1, activation=\"linear\")(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=[text_model.input, numeric_model.input], outputs=z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_13\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_token (InputLayer)        [(None, 100)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_bert_for_pre_training (TFBer ((None, 100, 30522), 110106428   input_token[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 100, 30522)   122088      tf_bert_for_pre_training[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 100, 64)      7830272     batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 100, 32)      12416       lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (None, 100, 16)      3136        lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   (None, 16)           2112        lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 24)           408         lstm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 114)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_37 (Dropout)            (None, 24)           0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 2)            230         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 24)           600         dropout_37[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 4)            12          dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 2)            50          dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 2)            10          dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 4)            0           dense_2[0][0]                    \n",
      "                                                                 dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 2)            10          concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 1)            3           dense_17[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 118,077,775\n",
      "Trainable params: 118,016,731\n",
      "Non-trainable params: 61,044\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "optimizer = Adam(\n",
    "    learning_rate=5e-05,\n",
    "    epsilon=1e-08,\n",
    "    decay=0.01,\n",
    "    clipnorm=1.0)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['acc',f1_m,precision_m, recall_m])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12590, 114)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([12590, 100])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_text['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12590, 2)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_class.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "551/551 [==============================] - 282s 513ms/step - loss: 7.7124 - acc: 0.5000 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: 7.7125 - val_acc: 0.5000 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 2/32\n",
      "551/551 [==============================] - 277s 503ms/step - loss: 7.7124 - acc: 0.5000 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: 7.7125 - val_acc: 0.5000 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "0.0 0.0 0.0\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=[X_train_text['input_ids'], numerical_train_x], y=Y_train_class, epochs=32, \n",
    "                    batch_size=16, validation_split=0.3, callbacks=[callback])\n",
    "loss, accuracy, f1_score, precision, recall = model.evaluate(\n",
    "                x=[X_test_text['input_ids'], numerical_test_x], y=Y_test_class, verbose=0)\n",
    "print(precision, recall, f1_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfgpu",
   "language": "python",
   "name": "tfgpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
